---
tags:
  - tutorial
  - getting_started
  - step_development
  - cursus
  - pipeline_development
keywords:
  - adding new step
  - step creation
  - pipeline step development
  - cursus step tutorial
  - step builder
  - script contract
  - step specification
topics:
  - Step development workflow
  - Cursus step creation
  - Pipeline step integration
  - ML workflow development
language: python
date of note: 2025-09-11
---

# Adding New Pipeline Step: Getting Started Tutorial

## Overview

This comprehensive tutorial walks you through the complete process of adding a new step to the Cursus pipeline system. You'll learn how to create a custom step from initial request to full integration, following Cursus's specification-driven design principles.

By the end of this tutorial, you'll have created a complete **Feature Selection Step** that integrates seamlessly with existing pipeline components and follows all Cursus best practices.

## Prerequisites

- Python 3.8+ environment with Cursus installed (`pip install cursus`)
- Basic understanding of machine learning workflows
- Familiarity with SageMaker concepts (Processing Jobs, Training Jobs)
- AWS account with SageMaker permissions (for testing)

## What You'll Build

We'll create a **Feature Selection Step** that:
- Takes preprocessed tabular data as input
- Applies feature selection using various methods (mutual information, correlation, tree-based)
- Outputs selected features and importance rankings
- Integrates with existing preprocessing and training steps
- Follows all Cursus standardization and alignment rules

## Tutorial Structure

This tutorial follows the complete step creation workflow:

1. **Developer Request & Design** - Define requirements and design decisions
2. **Script Contract Development** - Define the interface between script and container
3. **Processing Script Creation** - Implement the core business logic
4. **Step Specification Development** - Define inputs, outputs, and dependencies
5. **Configuration Class Creation** - Implement three-tier configuration design
6. **Step Builder Implementation** - Connect all components via SageMaker
7. **Registry Integration** - Register the step for discovery
8. **Validation & Testing** - Run comprehensive validation framework
9. **Pipeline Integration** - Add step to existing pipelines

## Phase 1: Developer Request & Design (10 minutes)

### Step 1.1: Initial Request

**Developer Request:**
> "I need a step that can automatically select the most important features from preprocessed tabular data to improve model performance and reduce training time. The step should support multiple selection methods and be configurable for different use cases."

### Step 1.2: Design Information Gathering

Based on the request, we need to gather additional design information:

**Task Description:** Feature selection for tabular data using configurable methods
**Step Name:** `FeatureSelection`
**SageMaker Step Type:** `ProcessingStep` (data transformation, not model training)
**Node Type:** `INTERNAL` (has both inputs and outputs)
**Pipeline Position:** Between preprocessing and training steps

**Key Design Decisions:**
- **Input:** Preprocessed tabular data from preprocessing steps
- **Output:** Reduced feature dataset and feature importance metadata
- **Methods:** Support mutual information, correlation, and tree-based selection
- **Configuration:** Number of features, selection method, importance thresholds

### Step 1.3: Refer to Design Principles

Before implementation, let's review key Cursus design principles:

```python
# Key principles from slipbox/0_developer_guide/design_principles.md:
# 1. Specification-Driven Design: Steps connect via input/output specifications
# 2. Contract Alignment: Scripts must align with their contracts
# 3. Three-Tier Configuration: Essential, System, and Derived fields
# 4. Unified Interface: All scripts use standardized main() function
# 5. Workspace Awareness: Support both main and isolated development
```

**Standardization Rules to Follow:**
- Use consistent naming conventions (from `slipbox/0_developer_guide/standardization_rules.md`)
- Implement proper error handling and logging
- Follow SageMaker container path conventions
- Ensure testability with unified main function interface

**Alignment Rules to Follow:**
- Script contract must match step specification logical names
- Environment variables must align between contract and script
- Container paths must follow SageMaker standards
- Property paths must be valid for SageMaker step types

## Phase 2: Script Contract Development (15 minutes)

### Step 2.1: Create the Script Contract

The script contract defines the interface between our processing script and the SageMaker container environment.

**File:** `src/cursus/steps/contracts/feature_selection_contract.py`

```python
"""
Feature Selection Script Contract

Defines the contract for the feature selection script that reduces feature dimensionality
from preprocessed tabular data using various selection methods.
"""

from ...core.base.contract_base import ScriptContract

FEATURE_SELECTION_CONTRACT = ScriptContract(
    entry_point="feature_selection.py",
    expected_input_paths={
        "input_data": "/opt/ml/processing/input/data",
        "config": "/opt/ml/processing/input/config"
    },
    expected_output_paths={
        "selected_features": "/opt/ml/processing/output/features",
        "feature_importance": "/opt/ml/processing/output/importance"
    },
    required_env_vars=[
        "SELECTION_METHOD",
        "N_FEATURES", 
        "TARGET_COLUMN"
    ],
    optional_env_vars={
        "MIN_IMPORTANCE": "0.01",
        "RANDOM_SEED": "42",
        "DEBUG_MODE": "False"
    },
    framework_requirements={
        "pandas": ">=1.2.0,<2.0.0",
        "scikit-learn": ">=0.23.2,<1.0.0",
        "numpy": ">=1.19.0",
        "pyarrow": ">=4.0.0,<6.0.0"
    },
    description="""
    Feature selection script for tabular data that:
    1. Loads preprocessed training data from input directory
    2. Applies feature selection using configurable methods (mutual_info, correlation, tree_based)
    3. Selects top N features based on importance scores
    4. Filters features by minimum importance threshold
    5. Outputs reduced feature set and importance rankings
    6. Supports both binary and multiclass classification scenarios
    
    Input Structure:
    - /opt/ml/processing/input/data: Preprocessed data files (.csv, .parquet, .json)
    - /opt/ml/processing/input/config: Optional configuration files (JSON format)
    
    Output Structure:
    - /opt/ml/processing/output/features: Selected features dataset
      - /opt/ml/processing/output/features/selected_features.parquet: Reduced dataset
      - /opt/ml/processing/output/features/feature_list.json: List of selected feature names
    - /opt/ml/processing/output/importance: Feature importance analysis
      - /opt/ml/processing/output/importance/feature_importance.csv: Importance scores
      - /opt/ml/processing/output/importance/importance_plot.json: Visualization data
    
    Contract aligned with step specification:
    - Inputs: input_data (required), config (optional)
    - Outputs: selected_features (primary), feature_importance (secondary)
    
    Environment Variables:
    - SELECTION_METHOD: Feature selection method (mutual_info, correlation, tree_based)
    - N_FEATURES: Number of top features to select
    - TARGET_COLUMN: Name of the target/label column in the dataset
    - MIN_IMPORTANCE: Minimum importance threshold for feature filtering (optional)
    - RANDOM_SEED: Random seed for reproducible results (optional)
    - DEBUG_MODE: Enable debug logging (optional)
    """
)
```

### Step 2.2: Contract Design Validation

Let's validate our contract design against Cursus standards:

**‚úÖ Container Path Standards:**
- Processing input: `/opt/ml/processing/input/` ‚úì
- Processing output: `/opt/ml/processing/output/` ‚úì

**‚úÖ Logical Name Consistency:**
- `input_data` and `config` for inputs ‚úì
- `selected_features` and `feature_importance` for outputs ‚úì

**‚úÖ Environment Variable Naming:**
- Use UPPER_CASE with underscores ‚úì
- Clear, descriptive names ‚úì
- Required vs optional clearly defined ‚úì

## Phase 3: Processing Script Creation (25 minutes)

### Step 3.1: Create the Processing Script

Now we'll implement the core business logic using Cursus's unified main function interface.

**File:** `src/cursus/steps/scripts/feature_selection.py`

```python
#!/usr/bin/env python3
"""
Processing script for Feature Selection Step.

This script implements the business logic for feature selection using the unified
main function interface for testability and SageMaker container compatibility.
"""
import os
import sys
import argparse
import logging
import traceback
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, Any, List, Tuple
from sklearn.feature_selection import (
    mutual_info_classif, 
    f_classif, 
    SelectKBest,
    SelectFromModel
)
from sklearn.ensemble import RandomForestClassifier

# Container path constants (aligned with contract)
CONTAINER_PATHS = {
    "PROCESSING_INPUT_BASE": "/opt/ml/processing/input",
    "PROCESSING_OUTPUT_BASE": "/opt/ml/processing/output",
    "DATA_INPUT": "/opt/ml/processing/input/data",
    "CONFIG_INPUT": "/opt/ml/processing/input/config",
    "FEATURES_OUTPUT": "/opt/ml/processing/output/features",
    "IMPORTANCE_OUTPUT": "/opt/ml/processing/output/importance"
}

def setup_logging() -> logging.Logger:
    """Configure logging for CloudWatch compatibility."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[logging.StreamHandler(sys.stdout)]
    )
    logger = logging.getLogger(__name__)
    sys.stdout.flush()
    return logger

def read_input_data(input_path: str, logger) -> pd.DataFrame:
    """Read input data from the specified path."""
    try:
        logger(f"Reading input data from {input_path}")
        
        # Check if directory exists
        if not os.path.exists(input_path):
            raise ValueError(f"Input path does not exist: {input_path}")
            
        # List files in directory
        files = [os.path.join(input_path, f) for f in os.listdir(input_path) 
                if f.endswith('.csv') or f.endswith('.parquet')]
        
        if not files:
            raise ValueError(f"No CSV or Parquet files found in {input_path}")
        
        # Read the first file
        file_path = files[0]
        logger(f"Reading file: {file_path}")
        
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        elif file_path.endswith('.parquet'):
            df = pd.read_parquet(file_path)
        else:
            raise ValueError(f"Unsupported file format: {file_path}")
        
        logger(f"Read {len(df)} rows and {len(df.columns)} columns")
        return df
        
    except Exception as e:
        logger(f"Error reading input data: {str(e)}")
        raise

def select_features_mutual_info(
    X: pd.DataFrame, 
    y: pd.Series, 
    n_features: int, 
    random_state: int,
    logger
) -> Tuple[List[str], pd.DataFrame]:
    """Select features using mutual information."""
    logger(f"Selecting {n_features} features using mutual information")
    
    # Handle categorical features
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    X_processed = X.copy()
    
    for col in categorical_cols:
        X_processed[col] = X_processed[col].astype('category').cat.codes
    
    # Apply mutual information
    selector = SelectKBest(mutual_info_classif, k=min(n_features, X.shape[1]))
    selector.fit(X_processed, y)
    
    # Get selected features and importance scores
    feature_idx = selector.get_support(indices=True)
    feature_names = X.columns[feature_idx].tolist()
    importance_scores = selector.scores_[feature_idx]
    
    # Create importance DataFrame
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': importance_scores
    }).sort_values('importance', ascending=False)
    
    logger(f"Selected {len(feature_names)} features")
    return feature_names, importance_df

def select_features_correlation(
    X: pd.DataFrame, 
    y: pd.Series, 
    n_features: int, 
    random_state: int,
    logger
) -> Tuple[List[str], pd.DataFrame]:
    """Select features using correlation with target."""
    logger(f"Selecting {n_features} features using correlation")
    
    # Calculate correlation with target
    correlations = X.corrwith(y).abs().sort_values(ascending=False)
    
    # Select top N features
    selected_features = correlations.head(n_features).index.tolist()
    importance_scores = correlations.head(n_features).values
    
    # Create importance DataFrame
    importance_df = pd.DataFrame({
        'feature': selected_features,
        'importance': importance_scores
    })
    
    logger(f"Selected {len(selected_features)} features")
    return selected_features, importance_df

def select_features_tree_based(
    X: pd.DataFrame, 
    y: pd.Series, 
    n_features: int, 
    random_state: int,
    logger
) -> Tuple[List[str], pd.DataFrame]:
    """Select features using tree-based feature importance."""
    logger(f"Selecting {n_features} features using tree-based method")
    
    # Handle categorical features
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    X_processed = X.copy()
    
    for col in categorical_cols:
        X_processed[col] = X_processed[col].astype('category').cat.codes
    
    # Train random forest for feature importance
    rf = RandomForestClassifier(n_estimators=100, random_state=random_state)
    rf.fit(X_processed, y)
    
    # Get feature importance
    importance_scores = rf.feature_importances_
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': importance_scores
    }).sort_values('importance', ascending=False)
    
    # Select top N features
    selected_features = feature_importance.head(n_features)['feature'].tolist()
    
    logger(f"Selected {len(selected_features)} features")
    return selected_features, feature_importance.head(n_features)

def main(
    input_paths: Dict[str, str],
    output_paths: Dict[str, str],
    environ_vars: Dict[str, str],
    job_args: argparse.Namespace,
    logger=None
) -> Dict[str, Any]:
    """
    Main processing function with unified interface.
    
    Args:
        input_paths: Dictionary of input paths with logical names
        output_paths: Dictionary of output paths with logical names
        environ_vars: Dictionary of environment variables
        job_args: Command line arguments
        logger: Optional logger function
    
    Returns:
        Processing results dictionary
    """
    log = logger or print
    
    # Extract parameters from environment variables (aligned with contract)
    selection_method = environ_vars.get("SELECTION_METHOD")
    n_features = int(environ_vars.get("N_FEATURES", "10"))
    target_column = environ_vars.get("TARGET_COLUMN")
    min_importance = float(environ_vars.get("MIN_IMPORTANCE", "0.01"))
    random_seed = int(environ_vars.get("RANDOM_SEED", "42"))
    debug_mode = environ_vars.get("DEBUG_MODE", "False").lower() == "true"
    
    # Extract paths (aligned with contract)
    input_data_dir = input_paths.get("input_data")
    config_dir = input_paths.get("config")
    output_features_dir = output_paths.get("selected_features")
    output_importance_dir = output_paths.get("feature_importance")
    
    log(f"Starting feature selection with parameters:")
    log(f"  Selection method: {selection_method}")
    log(f"  Number of features: {n_features}")
    log(f"  Target column: {target_column}")
    log(f"  Input data directory: {input_data_dir}")
    log(f"  Output features directory: {output_features_dir}")
    log(f"  Output importance directory: {output_importance_dir}")
    
    # Validate required parameters
    if not selection_method:
        raise ValueError("SELECTION_METHOD environment variable is required")
    if not target_column:
        raise ValueError("TARGET_COLUMN environment variable is required")
    
    # Create output directories
    Path(output_features_dir).mkdir(parents=True, exist_ok=True)
    Path(output_importance_dir).mkdir(parents=True, exist_ok=True)
    
    try:
        log("Starting feature selection processing...")
        
        # Read input data
        df = read_input_data(input_data_dir, log)
        
        # Validate target column exists
        if target_column not in df.columns:
            raise ValueError(f"Target column '{target_column}' not found in data columns: {list(df.columns)}")
        
        # Prepare features and target
        X = df.drop(columns=[target_column])
        y = df[target_column]
        
        log(f"Dataset shape: {X.shape}, Target distribution: {y.value_counts().to_dict()}")
        
        # Select features based on method
        if selection_method == "mutual_info":
            feature_names, importance_df = select_features_mutual_info(X, y, n_features, random_seed, log)
        elif selection_method == "correlation":
            feature_names, importance_df = select_features_correlation(X, y, n_features, random_seed, log)
        elif selection_method == "tree_based":
            feature_names, importance_df = select_features_tree_based(X, y, n_features, random_seed, log)
        else:
            raise ValueError(f"Unsupported selection method: {selection_method}. Supported: mutual_info, correlation, tree_based")
        
        # Filter by importance threshold if specified
        if min_importance > 0:
            filtered_df = importance_df[importance_df['importance'] >= min_importance]
            if len(filtered_df) > 0:
                feature_names = filtered_df['feature'].tolist()
                importance_df = filtered_df
                log(f"Filtered to {len(feature_names)} features with importance >= {min_importance}")
            else:
                log(f"Warning: No features meet minimum importance threshold {min_importance}, keeping top features")
        
        # Create selected features dataset
        selected_df = df[feature_names + [target_column]]
        
        # Write selected features
        features_file = Path(output_features_dir) / "selected_features.parquet"
        selected_df.to_parquet(features_file, index=False)
        log(f"Saved selected features to: {features_file}")
        
        # Write feature list
        feature_list_file = Path(output_features_dir) / "feature_list.json"
        with open(feature_list_file, "w") as f:
            json.dump(feature_names, f, indent=2)
        
        # Write importance scores
        importance_file = Path(output_importance_dir) / "feature_importance.csv"
        importance_df.to_csv(importance_file, index=False)
        log(f"Saved importance scores to: {importance_file}")
        
        # Write visualization data
        viz_file = Path(output_importance_dir) / "importance_plot.json"
        viz_data = {
            'features': importance_df['feature'].tolist(),
            'importance': importance_df['importance'].tolist(),
            'method': selection_method,
            'n_features_selected': len(feature_names),
            'original_feature_count': X.shape[1]
        }
        with open(viz_file, "w") as f:
            json.dump(viz_data, f, indent=2)
        
        log(f"Feature selection completed successfully. Selected {len(feature_names)} features from {X.shape[1]} original features.")
        
        return {
            "status": "success",
            "selected_features_count": len(feature_names),
            "original_features_count": X.shape[1],
            "selection_method": selection_method,
            "features_file": str(features_file),
            "importance_file": str(importance_file),
            "selected_features": feature_names
        }
        
    except Exception as e:
        log(f"Error during feature selection: {str(e)}")
        raise

if __name__ == "__main__":
    try:
        # Set up logging
        logger = setup_logging()
        
        # Parse command line arguments
        parser = argparse.ArgumentParser(description="Feature Selection processing script")
        parser.add_argument('--debug', action='store_true', help='Enable debug mode')
        args = parser.parse_args()
        
        # Set up paths using container defaults (aligned with contract)
        input_paths = {
            "input_data": CONTAINER_PATHS["DATA_INPUT"],
            "config": CONTAINER_PATHS["CONFIG_INPUT"]
        }
        
        output_paths = {
            "selected_features": CONTAINER_PATHS["FEATURES_OUTPUT"],
            "feature_importance": CONTAINER_PATHS["IMPORTANCE_OUTPUT"]
        }
        
        # Collect environment variables (aligned with contract)
        environ_vars = {
            "SELECTION_METHOD": os.environ.get("SELECTION_METHOD"),
            "N_FEATURES": os.environ.get("N_FEATURES"),
            "TARGET_COLUMN": os.environ.get("TARGET_COLUMN"),
            "MIN_IMPORTANCE": os.environ.get("MIN_IMPORTANCE", "0.01"),
            "RANDOM_SEED": os.environ.get("RANDOM_SEED", "42"),
            "DEBUG_MODE": os.environ.get("DEBUG_MODE", "False")
        }
        
        # Validate required environment variables
        required_vars = ["SELECTION_METHOD", "TARGET_COLUMN"]
        missing_vars = [var for var in required_vars if not environ_vars.get(var)]
        if missing_vars:
            raise ValueError(f"Missing required environment variables: {missing_vars}")
        
        # Set debug mode if requested
        if args.debug or environ_vars.get("DEBUG_MODE", "False").lower() == "true":
            logging.getLogger().setLevel(logging.DEBUG)
            logger.debug("Debug mode enabled")
        
        # Log startup information
        logger.info("Starting Feature Selection processing script")
        logger.info(f"Input paths: {input_paths}")
        logger.info(f"Output paths: {output_paths}")
        logger.info(f"Environment variables: {list(environ_vars.keys())}")
        
        # Execute main processing
        result = main(input_paths, output_paths, environ_vars, args, logger.info)
        
        # Create success marker
        success_path = Path(output_paths["selected_features"]) / "_SUCCESS"
        success_path.touch()
        logger.info(f"Created success marker: {success_path}")
        
        logger.info("Script completed successfully")
        logger.info(f"Processing result: {result}")
        sys.exit(0)
        
    except Exception as e:
        logging.error(f"Script failed with error: {e}")
        logging.error(traceback.format_exc())
        
        # Create failure marker
        try:
            failure_path = Path(output_paths.get("selected_features", "/tmp")) / "_FAILURE"
            with open(failure_path, "w") as f:
                f.write(f"Error: {str(e)}")
            logging.error(f"Created failure marker: {failure_path}")
        except:
            pass
        
        sys.exit(1)
```

### Step 3.2: Script Design Validation

Let's validate our script against Cursus standards:

**‚úÖ Unified Main Function Interface:**
- Standardized signature with input_paths, output_paths, environ_vars, job_args ‚úì
- Returns structured result dictionary ‚úì

**‚úÖ Container Compatibility:**
- Uses SageMaker standard paths ‚úì
- Handles environment variables properly ‚úì
- Creates success/failure markers ‚úì

**‚úÖ Error Handling:**
- Comprehensive try-catch blocks ‚úì
- Informative error messages ‚úì
- Proper logging throughout ‚úì

## Phase 4: Step Specification Development (20 minutes)

### Step 4.1: Create the Step Specification

The step specification defines how our step connects with other steps in the pipeline through logical input/output names.

**File:** `src/cursus/steps/specs/feature_selection_spec.py`

```python
"""
Feature Selection Step Specification.

This module defines the declarative specification for feature selection steps,
including their dependencies and outputs based on the actual implementation.
"""

from ...core.base.specification_base import StepSpecification, DependencySpec, OutputSpec, DependencyType, NodeType
from ...registry.step_names import get_spec_step_type

# Import the contract at runtime to avoid circular imports
def _get_feature_selection_contract():
    from ..contracts.feature_selection_contract import FEATURE_SELECTION_CONTRACT
    return FEATURE_SELECTION_CONTRACT

# Feature Selection Step Specification
FEATURE_SELECTION_SPEC = StepSpecification(
    step_type=get_spec_step_type("FeatureSelection"),
    node_type=NodeType.INTERNAL,
    script_contract=_get_feature_selection_contract(),
    dependencies={
        "input_data": DependencySpec(
            logical_name="input_data",
            dependency_type=DependencyType.PROCESSING_OUTPUT,
            required=True,
            compatible_sources=["TabularPreprocessing", "ProcessingStep", "CradleDataLoading"],
            semantic_keywords=["data", "processed", "tabular", "features", "preprocessing", "input"],
            data_type="S3Uri",
            description="Preprocessed tabular data for feature selection"
        ),
        "config": DependencySpec(
            logical_name="config",
            dependency_type=DependencyType.PROCESSING_OUTPUT,
            required=False,
            compatible_sources=["ProcessingStep", "ConfigGeneration"],
            semantic_keywords=["config", "parameters", "settings", "hyperparameters"],
            data_type="S3Uri",
            description="Optional configuration parameters for feature selection"
        )
    },
    outputs={
        "selected_features": OutputSpec(
            logical_name="selected_features",
            aliases=["features", "reduced_features", "feature_subset", "processed_features"],
            output_type=DependencyType.PROCESSING_OUTPUT,
            property_path="properties.ProcessingOutputConfig.Outputs['selected_features'].S3Output.S3Uri",
            data_type="S3Uri",
            description="Selected subset of features with reduced dimensionality"
        ),
        "feature_importance": OutputSpec(
            logical_name="feature_importance",
            aliases=["importance", "feature_rankings", "feature_scores"],
            output_type=DependencyType.PROCESSING_OUTPUT,
            property_path="properties.ProcessingOutputConfig.Outputs['feature_importance'].S3Output.S3Uri",
            data_type="S3Uri",
            description="Feature importance scores and rankings from selection process"
        )
    }
)
```

### Step 4.2: Specification Design Validation

Let's validate our specification against Cursus alignment rules:

**‚úÖ Logical Name Consistency:**
- Contract inputs: `input_data`, `config` ‚úì
- Specification dependencies: `input_data`, `config` ‚úì
- Contract outputs: `selected_features`, `feature_importance` ‚úì
- Specification outputs: `selected_features`, `feature_importance` ‚úì

**‚úÖ Property Path Validation:**
- Uses valid SageMaker ProcessingStep property paths ‚úì
- Follows ProcessingOutputConfig.Outputs pattern ‚úì

**‚úÖ Semantic Compatibility:**
- Compatible sources include preprocessing steps ‚úì
- Semantic keywords enable automatic dependency resolution ‚úì

## Phase 5: Configuration Class Creation (20 minutes)

### Step 5.1: Create the Configuration Class

We'll implement the three-tier configuration design with proper field categorization.

**File:** `src/cursus/steps/configs/config_feature_selection.py`

```python
from pydantic import BaseModel, Field, field_validator, PrivateAttr
from typing import Dict, Any, Optional
from ...core.base.config_base import BasePipelineConfig

class FeatureSelectionConfig(BasePipelineConfig):
    """
    Configuration for Feature Selection step using three-tier field classification.
    
    Tier 1: Essential fields (required user inputs)
    Tier 2: System fields (with defaults, can be overridden)
    Tier 3: Derived fields (private with property access)
    """
    
    # Tier 1: Essential user inputs (required, no defaults)
    selection_method: str = Field(..., description="Method for feature selection (mutual_info, correlation, tree_based)")
    n_features: int = Field(..., ge=1, description="Number of features to select")
    target_column: str = Field(..., description="Name of the target/label column")
    
    # Tier 2: System inputs with defaults (can be overridden)
    min_importance: float = Field(default=0.01, ge=0.0, description="Minimum importance threshold for features")
    instance_type: str = Field(default="ml.m5.xlarge", description="SageMaker instance type")
    instance_count: int = Field(default=1, ge=1, description="Number of instances")
    volume_size_gb: int = Field(default=30, ge=1, description="EBS volume size in GB")
    max_runtime_seconds: int = Field(default=3600, ge=1, description="Maximum runtime in seconds")
    debug_mode: bool = Field(default=False, description="Enable debug mode")
    random_seed: int = Field(default=42, description="Random seed for reproducibility")
    
    # Tier 3: Derived fields (private with property access)
    _script_path: Optional[str] = PrivateAttr(default=None)
    _output_path: Optional[str] = PrivateAttr(default=None)
    
    @field_validator('selection_method')
    @classmethod
    def validate_selection_method(cls, v: str) -> str:
        """Validate selection method is supported."""
        valid_methods = ["mutual_info", "correlation", "tree_based"]
        if v not in valid_methods:
            raise ValueError(f"Selection method must be one of: {valid_methods}")
        return v
    
    @field_validator('instance_type')
    @classmethod
    def validate_instance_type(cls, v: str) -> str:
        """Validate SageMaker instance type."""
        valid_instances = [
            "ml.m5.large", "ml.m5.xlarge", "ml.m5.2xlarge", "ml.m5.4xlarge",
            "ml.c5.large", "ml.c5.xlarge", "ml.c5.2xlarge", "ml.c5.4xlarge"
        ]
        if v not in valid_instances:
            raise ValueError(f"Invalid instance type: {v}. Must be one of: {valid_instances}")
        return v
    
    # Public properties for derived fields
    @property
    def script_path(self) -> str:
        """Get script path."""
        if self._script_path is None:
            self._script_path = "feature_selection.py"
        return self._script_path
    
    @property
    def output_path(self) -> str:
        """Get output path."""
        if self._output_path is None:
            self._output_path = f"{self.pipeline_s3_loc}/feature_selection/{self.region}"
        return self._output_path
    
    # Custom model_dump method to include derived properties
    def model_dump(self, **kwargs) -> Dict[str, Any]:
        """Override model_dump to include derived properties."""
        data = super().model_dump(**kwargs)
        # Add derived properties to output
        data["script_path"] = self.script_path
        data["output_path"] = self.output_path
        return data
    
    def get_script_contract(self):
        """Return the script contract for this step."""
        from ..contracts.feature_selection_contract import FEATURE_SELECTION_CONTRACT
        return FEATURE_SELECTION_CONTRACT
```

### Step 5.2: Configuration Design Validation

Let's validate our configuration against Cursus three-tier design:

**‚úÖ Tier 1 (Essential Fields):**
- `selection_method`, `n_features`, `target_column` - Required user inputs ‚úì

**‚úÖ Tier 2 (System Fields):**
- Instance configuration, runtime settings with sensible defaults ‚úì
- All can be overridden by users ‚úì

**‚úÖ Tier 3 (Derived Fields):**
- Private attributes with property access ‚úì
- Computed from other configuration values ‚úì

## Phase 6: Step Builder Implementation (25 minutes)

### Step 6.1: Create the Step Builder

The step builder connects all our components and creates the actual SageMaker step.

**File:** `src/cursus/steps/builders/builder_feature_selection.py`

```python
from typing import Dict, List, Any, Optional
from pathlib import Path

from sagemaker.processing import ProcessingInput, ProcessingOutput
from sagemaker.workflow.steps import ProcessingStep

from ...core.base.builder_base import StepBuilderBase
from ..configs.config_feature_selection import FeatureSelectionConfig
from ..specs.feature_selection_spec import FEATURE_SELECTION_SPEC
from ...registry.hybrid.manager import UnifiedRegistryManager

class FeatureSelectionStepBuilder(StepBuilderBase):
    """
    Builder for Feature Selection Processing Step.
    This class is responsible for configuring and creating a SageMaker ProcessingStep
    that performs feature selection on preprocessed data.
    """

    def __init__(
        self,
        config: FeatureSelectionConfig,
        sagemaker_session=None,
        role: Optional[str] = None,
        notebook_root: Optional[Path] = None,
        registry_manager: Optional["RegistryManager"] = None,
        dependency_resolver: Optional["UnifiedDependencyResolver"] = None
    ):
        """
        Initializes the builder with a specific configuration for the processing step.

        Args:
            config: A FeatureSelectionConfig instance containing all necessary settings.
            sagemaker_session: The SageMaker session object to manage interactions with AWS.
            role: The IAM role ARN to be used by the SageMaker Processing Job.
            notebook_root: The root directory of the notebook environment, used for resolving
                         local paths if necessary.
            registry_manager: Optional registry manager for dependency injection
            dependency_resolver: Optional dependency resolver for dependency injection
        """
        if not isinstance(config, FeatureSelectionConfig):
            raise ValueError("FeatureSelectionStepBuilder requires a FeatureSelectionConfig instance.")
            
        # Initialize with specification
        super().__init__(
            config=config,
            spec=FEATURE_SELECTION_SPEC,
            sagemaker_session=sagemaker_session,
            role=role,
            notebook_root=notebook_root,
            registry_manager=registry_manager,
            dependency_resolver=dependency_resolver
        )
        self.config: FeatureSelectionConfig = config

    def validate_configuration(self) -> None:
        """Validate the provided configuration."""
        required_attrs = [
            'selection_method', 'n_features', 'target_column',
            'instance_type', 'instance_count'
        ]
        
        for attr in required_attrs:
            if not hasattr(self.config, attr) or getattr(self.config, attr) in [None, ""]:
                raise ValueError(f"FeatureSelectionConfig missing required attribute: {attr}")

    def _create_processor(self):
        """Create and return a SageMaker processor."""
        from sagemaker.sklearn import SKLearnProcessor
        
        return SKLearnProcessor(
            framework_version="0.23-1",
            role=self.role,
            instance_type=self.config.instance_type,
            instance_count=self.config.instance_count,
            volume_size_in_gb=self.config.volume_size_gb,
            max_runtime_in_seconds=self.config.max_runtime_seconds,
            base_job_name=self._generate_job_name(),
            sagemaker_session=self.session,
            env=self._get_environment_variables()
        )

    def _get_environment_variables(self) -> Dict[str, str]:
        """Get environment variables for the processor."""
        # Get base environment variables from contract
        env_vars = super()._get_environment_variables()
        
        # Add step-specific environment variables
        step_env_vars = {
            "SELECTION_METHOD": self.config.selection_method,
            "N_FEATURES": str(self.config.n_features),
            "TARGET_COLUMN": self.config.target_column,
            "MIN_IMPORTANCE": str(self.config.min_importance),
            "RANDOM_SEED": str(self.config.random_seed),
            "DEBUG_MODE": str(self.config.debug_mode).lower()
        }
        
        env_vars.update(step_env_vars)
        return env_vars

    def _get_inputs(self, inputs: Dict[str, Any]) -> List[ProcessingInput]:
        """Get inputs for the step using specification and contract."""
        if not self.spec or not self.contract:
            raise ValueError("Step specification and contract are required")
            
        processing_inputs = []
        
        # Process each dependency in the specification
        for logical_name, dependency_spec in self.spec.dependencies.items():
            # Skip if optional and not provided
            if not dependency_spec.required and logical_name not in inputs:
                continue
                
            # Make sure required inputs are present
            if dependency_spec.required and logical_name not in inputs:
                raise ValueError(f"Required input '{logical_name}' not provided")
            
            # Get container path from contract
            if logical_name in self.contract.expected_input_paths:
                container_path = self.contract.expected_input_paths[logical_name]
                processing_inputs.append(ProcessingInput(
                    input_name=logical_name,
                    source=inputs[logical_name],
                    destination=container_path
                ))
            else:
                raise ValueError(f"No container path found for input: {logical_name}")
                
        return processing_inputs

    def _get_outputs(self, outputs: Dict[str, Any]) -> List[ProcessingOutput]:
        """Get outputs for the step using specification and contract."""
        if not self.spec or not self.contract:
            raise ValueError("Step specification and contract are required")
            
        processing_outputs = []
        
        # Process each output in the specification
        for logical_name, output_spec in self.spec.outputs.items():
            # Get container path from contract
            if logical_name in self.contract.expected_output_paths:
                container_path = self.contract.expected_output_paths[logical_name]
                
                # Generate destination from config or use provided
                if logical_name in outputs:
                    destination = outputs[logical_name]
                else:
                    destination = f"{self.config.output_path}/{logical_name}/"
                
                processing_outputs.append(ProcessingOutput(
                    output_name=logical_name,
                    source=container_path,
                    destination=destination
                ))
            else:
                raise ValueError(f"No container path found for output: {logical_name}")
                
        return processing_outputs

    def create_step(self, **kwargs) -> ProcessingStep:
        """Create the ProcessingStep."""
        # Extract parameters
        inputs_raw = kwargs.get('inputs', {})
        outputs = kwargs.get('outputs', {})
        dependencies = kwargs.get('dependencies', [])
        enable_caching = kwargs.get('enable_caching', True)
        
        # Handle inputs
        inputs = {}
        
        # If dependencies are provided, extract inputs from them
        if dependencies:
            try:
                extracted_inputs = self.extract_inputs_from_dependencies(dependencies)
                inputs.update(extracted_inputs)
            except Exception as e:
                self.log_warning("Failed to extract inputs from dependencies: %s", e)
                
        # Add explicitly provided inputs
        inputs.update(inputs_raw)
        
        # Create processor and get inputs/outputs
        processor = self._create_processor()
        proc_inputs = self._get_inputs(inputs)
        proc_outputs = self._get_outputs(outputs)
        
        # Get step name and script path
        step_name = self._get_step_name()
        script_path = self.config.script_path
        
        # Create step
        step = ProcessingStep(
            name=step_name,
            processor=processor,
            inputs=proc_inputs,
            outputs=proc_outputs,
            code=script_path,
            depends_on=dependencies,
            cache_config=self._get_cache_config(enable_caching)
        )
        
        # Attach specification to the step for future reference
        setattr(step, '_spec', self.spec)
        
        return step
```

### Step 6.2: Builder Design Validation

Let's validate our builder against Cursus patterns:

**‚úÖ Specification-Driven Design:**
- Uses specification to drive input/output generation ‚úì
- Aligns with contract for container paths ‚úì

**‚úÖ Configuration Integration:**
- Properly uses configuration for all settings ‚úì
- Environment variables align with contract ‚úì

**‚úÖ Error Handling:**
- Validates required inputs and configuration ‚úì
- Provides clear error messages ‚úì

## Phase 7: Registry Integration (10 minutes)

### Step 7.1: Automatic Registration

With Cursus's modern hybrid registry system, our step will be automatically discovered and registered if we follow the naming conventions:

**‚úÖ File Naming Convention:**
- Builder file: `builder_feature_selection.py` ‚úì
- Class name: `FeatureSelectionStepBuilder` ‚úì
- Location: `src/cursus/steps/builders/` ‚úì

### Step 7.2: Verify Registration

Let's verify our step will be properly registered:

```python
# Test registration discovery
from cursus.registry.hybrid.manager import UnifiedRegistryManager

# Get registry instance
registry = UnifiedRegistryManager()

# Set workspace context (main workspace)
registry.set_workspace_context("main")

# The registry will automatically discover our step builder
# based on the naming convention and file location
print("Step will be automatically registered as: FeatureSelection")
```

### Step 7.3: Manual Registration (Optional)

If you need explicit control over registration:

```python
from cursus.registry.step_names import add_new_step_with_validation

# Register your step with validation
warnings = add_new_step_with_validation(
    step_name="FeatureSelection",
    config_class="FeatureSelectionConfig", 
    builder_name="FeatureSelectionStepBuilder",
    sagemaker_type="Processing",  # Based on create_step() return type
    description="Feature selection step for dimensionality reduction",
    validation_mode="warn",  # Options: "warn", "strict", "auto_correct"
    workspace_id=None  # Use current workspace context
)

# Check for any validation warnings
if warnings:
    for warning in warnings:
        print(f"‚ö†Ô∏è {warning}")
```

## Phase 8: Validation & Testing (20 minutes)

### Step 8.1: Run Alignment Validation

Execute the **Unified Alignment Tester** to perform 4-tier validation:

```bash
# Validate our feature selection step with detailed output
python -m cursus.cli.alignment_cli validate feature_selection --verbose --show-scoring

# Generate visualization and scoring reports
python -m cursus.cli.alignment_cli visualize feature_selection --output-dir ./validation_reports --verbose
```

**Expected Output:**
```
üîç Validating feature_selection step...

‚úÖ Tier 1 - Script-Contract Alignment: PASS (Score: 95/100)
   - Entry point alignment: ‚úì
   - Input paths alignment: ‚úì
   - Output paths alignment: ‚úì
   - Environment variables alignment: ‚úì

‚úÖ Tier 2 - Contract-Specification Alignment: PASS (Score: 98/100)
   - Logical names consistency: ‚úì
   - Input/output mapping: ‚úì
   - Dependency types: ‚úì

‚úÖ Tier 3 - Builder-Config Alignment: PASS (Score: 92/100)
   - Configuration usage: ‚úì
   - Environment variable mapping: ‚úì
   - SageMaker integration: ‚úì

‚úÖ Tier 4 - Specification-Dependency Alignment: PASS (Score: 90/100)
   - Property path validation: ‚úì
   - Semantic compatibility: ‚úì
   - Dependency resolution: ‚úì

üéâ Overall Alignment Score: 94/100 - EXCELLENT
```

### Step 8.2: Run Step Builder Tests

Execute the **Universal Step Builder Test**:

```bash
# Run all tests for our builder with scoring
python -m cursus.cli.builder_test_cli all src.cursus.steps.builders.builder_feature_selection.FeatureSelectionStepBuilder --scoring --verbose

# Test all builders of Processing type
python -m cursus.cli.builder_test_cli test-by-type Processing --verbose --scoring
```

**Expected Output:**
```
üß™ Testing FeatureSelectionStepBuilder...

‚úÖ Interface Tests: PASS (8/8)
   - Constructor validation: ‚úì
   - Configuration validation: ‚úì
   - Method signatures: ‚úì
   - Error handling: ‚úì

‚úÖ Specification Tests: PASS (6/6)
   - Specification attachment: ‚úì
   - Input/output alignment: ‚úì
   - Dependency handling: ‚úì

‚úÖ Integration Tests: PASS (10/10)
   - SageMaker step creation: ‚úì
   - Environment variables: ‚úì
   - Input/output processing: ‚úì
   - Cache configuration: ‚úì

‚úÖ Step Creation Tests: PASS (5/5)
   - ProcessingStep creation: ‚úì
   - Processor configuration: ‚úì
   - Step properties: ‚úì

üéâ Builder Test Score: 29/29 - PERFECT
```

### Step 8.3: Run Script Runtime Testing

Execute the **Script Runtime Tester**:

```bash
# Test single script functionality
cursus runtime test-script feature_selection --workspace-dir ./test_workspace --verbose

# Test data compatibility between connected scripts
cursus runtime test-compatibility tabular_preprocessing feature_selection --workspace-dir ./test_workspace --verbose
```

**Expected Output:**
```
üöÄ Testing feature_selection script runtime...

‚úÖ Script Discovery: PASS
   - Script file found: ‚úì
   - Entry point valid: ‚úì
   - Import successful: ‚úì

‚úÖ Interface Validation: PASS
   - Main function signature: ‚úì
   - Parameter handling: ‚úì
   - Return value structure: ‚úì

‚úÖ Container Simulation: PASS
   - Input path creation: ‚úì
   - Output path creation: ‚úì
   - Environment variables: ‚úì
   - Mock data processing: ‚úì

‚úÖ Data Compatibility: PASS
   - Input format validation: ‚úì
   - Output format validation: ‚úì
   - Schema consistency: ‚úì

üéâ Runtime Test Score: 100% - All tests passed
```

## Phase 9: Pipeline Integration (15 minutes)

### Step 9.1: Create a Pipeline with Feature Selection

Now let's integrate our new step into an existing pipeline:

```python
from cursus.api.dag.base_dag import PipelineDAG
from cursus.core.compiler.dag_compiler import PipelineDAGCompiler

def create_feature_selection_pipeline_dag() -> PipelineDAG:
    """
    Create a pipeline DAG that includes our new feature selection step.
    """
    dag = PipelineDAG()
    
    # Add nodes including our new feature selection step
    dag.add_node("CradleDataLoading_training")       # Data loading
    dag.add_node("TabularPreprocessing_training")    # Preprocessing
    dag.add_node("FeatureSelection")                 # Our new step!
    dag.add_node("XGBoostTraining")                  # Training
    
    # Create pipeline flow
    dag.add_edge("CradleDataLoading_training", "TabularPreprocessing_training")
    dag.add_edge("TabularPreprocessing_training", "FeatureSelection")  # Connect to our step
    dag.add_edge("FeatureSelection", "XGBoostTraining")                # Our step feeds training
    
    print(f"‚úÖ Created pipeline DAG with {len(dag.nodes)} nodes and {len(dag.edges)} edges")
    print(f"üéØ Feature selection step integrated between preprocessing and training")
    return dag

# Create and compile the pipeline
dag = create_feature_selection_pipeline_dag()

# Compile with your configuration
compiler = PipelineDAGCompiler(
    config_path="path/to/your/config.json",
    sagemaker_session=pipeline_session,
    role=role
)

# Validate the DAG
validation = compiler.validate_dag_compatibility(dag)
if validation.is_valid:
    print("‚úÖ Pipeline validation passed!")
    
    # Compile the pipeline
    pipeline, report = compiler.compile_with_report(dag=dag)
    print(f"‚úÖ Pipeline compiled successfully with {len(pipeline.steps)} steps")
else:
    print("‚ùå Pipeline validation failed:")
    for issue in validation.issues:
        print(f"  - {issue}")
```

### Step 9.2: Test Pipeline Execution

```python
# Create execution parameters
execution_params = {
    "training_data_s3_uri": "s3://your-bucket/training-data/",
    "selection_method": "mutual_info",
    "n_features": "20",
    "target_column": "target"
}

# Create execution document
execution_doc = compiler.create_execution_document(execution_params)

# Deploy and execute (optional)
pipeline.upsert()
execution = pipeline.start(execution_input=execution_doc)

print(f"‚úÖ Pipeline deployed and execution started!")
print(f"üìä Monitor at: https://console.aws.amazon.com/sagemaker/home#/pipelines")
```

## Summary & Next Steps

Congratulations! You've successfully created a complete Feature Selection step following Cursus best practices. Here's what you accomplished:

### ‚úÖ What You Built

1. **Script Contract** - Defined the interface between script and container
2. **Processing Script** - Implemented business logic with unified main function
3. **Step Specification** - Defined inputs, outputs, and dependencies
4. **Configuration Class** - Implemented three-tier configuration design
5. **Step Builder** - Connected all components via SageMaker integration
6. **Registry Integration** - Enabled automatic step discovery
7. **Comprehensive Validation** - Passed all alignment and builder tests
8. **Pipeline Integration** - Successfully integrated into existing pipelines

### ‚úÖ Key Features Implemented

- **Multiple Selection Methods**: Mutual information, correlation, tree-based
- **Configurable Parameters**: Number of features, importance thresholds
- **Robust Error Handling**: Comprehensive validation and logging
- **Container Compatibility**: Full SageMaker container support
- **Specification-Driven**: Automatic dependency resolution
- **Three-Tier Configuration**: Proper field categorization
- **Testable Design**: Unified main function interface

### üöÄ Next Steps

1. **Advanced Features**:
   - Add support for regression tasks
   - Implement additional selection methods (LASSO, RFE)
   - Add feature visualization capabilities

2. **Production Deployment**:
   - Create comprehensive unit tests
   - Set up CI/CD pipeline integration
   - Add monitoring and alerting

3. **Team Collaboration**:
   - Use workspace-aware development for team projects
   - Create reusable pipeline templates
   - Document usage patterns and best practices

### üìö Additional Resources

- **[API Reference](api_reference.md)** - Detailed API documentation for step development
- **[Developer Guide](../../0_developer_guide/README.md)** - Complete development documentation
- **[Validation Framework](../../0_developer_guide/validation_framework_guide.md)** - Advanced validation patterns
- **[Best Practices](../../0_developer_guide/best_practices.md)** - Development best practices
- **[Pipeline Catalog](../../../src/cursus/pipeline_catalog/)** - Example pipeline implementations

### üí° Key Takeaways

1. **Follow the Process**: The structured approach ensures all components align properly
2. **Validate Early and Often**: Use Cursus validation tools throughout development
3. **Leverage Specifications**: Let specifications drive your implementation
4. **Test Thoroughly**: Use all three validation levels (alignment, builder, runtime)
5. **Document Well**: Clear documentation helps with maintenance and collaboration

You now have the knowledge and tools to create any custom pipeline step in Cursus. The same process applies whether you're building data processing, model training, or deployment steps. Happy pipeline building! üéâ

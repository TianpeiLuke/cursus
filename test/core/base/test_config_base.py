import pytest
from unittest.mock import Mock, patch, MagicMock
from pathlib import Path
from typing import Dict, Any
import logging
from datetime import datetime

from cursus.core.base.config_base import BasePipelineConfig


class TestBasePipelineConfig:
    """Test cases for BasePipelineConfig class."""

    @pytest.fixture
    def valid_config_data(self):
        """Set up test fixtures."""
        return {
            "author": "test_author",
            "bucket": "test-bucket",
            "role": "arn:aws:iam::123456789012:role/TestRole",
            "region": "NA",
            "service_name": "test_service",
            "pipeline_version": "1.0.0",
            "project_root_folder": "cursus",
        }

    def test_init_with_required_fields(self, valid_config_data):
        """Test initialization with all required fields."""
        config = BasePipelineConfig(**valid_config_data)

        # Verify required fields
        assert config.author == "test_author"
        assert config.bucket == "test-bucket"
        assert config.role == "arn:aws:iam::123456789012:role/TestRole"
        assert config.region == "NA"
        assert config.service_name == "test_service"
        assert config.pipeline_version == "1.0.0"

        # Verify default fields
        assert config.model_class == "xgboost"
        assert config.framework_version == "2.1.0"
        assert config.py_version == "py310"
        assert config.source_dir is None

        # Verify current_date is set
        assert isinstance(config.current_date, str)
        assert len(config.current_date) > 0

    def test_init_with_optional_fields(self, valid_config_data):
        """Test initialization with optional fields."""
        config_data = valid_config_data.copy()
        config_data.update(
            {
                "model_class": "pytorch",
                "framework_version": "1.8.0",
                "py_version": "py39",
                "source_dir": "/test/source",
            }
        )

        with patch("pathlib.Path.exists", return_value=True), patch(
            "pathlib.Path.is_dir", return_value=True
        ):
            config = BasePipelineConfig(**config_data)

            assert config.model_class == "pytorch"
            assert config.framework_version == "1.8.0"
            assert config.py_version == "py39"
            assert config.source_dir == "/test/source"

    def test_derived_properties(self, valid_config_data):
        """Test derived properties are calculated correctly."""
        config = BasePipelineConfig(**valid_config_data)

        # Test aws_region
        assert config.aws_region == "us-east-1"

        # Test pipeline_name
        expected_name = "test_author-test_service-xgboost-NA"
        assert config.pipeline_name == expected_name

        # Test pipeline_description
        expected_desc = "test_service xgboost Model NA"
        assert config.pipeline_description == expected_desc

        # Test pipeline_s3_loc
        expected_s3_loc = (
            "s3://test-bucket/MODS/test_author-test_service-xgboost-NA_1.0.0"
        )
        assert config.pipeline_s3_loc == expected_s3_loc

    def test_region_validation(self, valid_config_data):
        """Test region validation."""
        # Test valid regions
        for region in ["NA", "EU", "FE"]:
            config_data = valid_config_data.copy()
            config_data["region"] = region
            config = BasePipelineConfig(**config_data)
            assert config.region == region

        # Test invalid region
        config_data = valid_config_data.copy()
        config_data["region"] = "INVALID"

        with pytest.raises(ValueError) as exc_info:
            BasePipelineConfig(**config_data)

        assert "Invalid custom region code" in str(exc_info.value)

    def test_source_dir_validation(self, valid_config_data):
        """Test source_dir validation - now removed for portability."""
        config_data = valid_config_data.copy()
        config_data["source_dir"] = "/nonexistent/path"

        # Source dir validation has been removed for improved configuration portability
        # Path validation should happen at execution time in builders, not at config creation time
        config = BasePipelineConfig(**config_data)
        assert config.source_dir == "/nonexistent/path"

        # Test S3 path (should work fine)
        config_data["source_dir"] = "s3://bucket/path"
        config = BasePipelineConfig(**config_data)
        assert config.source_dir == "s3://bucket/path"

    def test_model_dump_includes_derived_properties(self, valid_config_data):
        """Test that model_dump includes derived properties."""
        config = BasePipelineConfig(**valid_config_data)
        data = config.model_dump()

        # Check that derived properties are included
        assert "aws_region" in data
        assert "pipeline_name" in data
        assert "pipeline_description" in data
        assert "pipeline_s3_loc" in data

        # Verify values
        assert data["aws_region"] == "us-east-1"
        assert data["pipeline_name"] == "test_author-test_service-xgboost-NA"

    def test_categorize_fields(self, valid_config_data):
        """Test field categorization."""
        config = BasePipelineConfig(**valid_config_data)
        categories = config.categorize_fields()

        # Check that all categories exist
        assert "essential" in categories
        assert "system" in categories
        assert "derived" in categories

        # Check essential fields (required, no defaults)
        essential_fields = set(categories["essential"])
        expected_essential = {
            "author",
            "bucket",
            "role",
            "region",
            "service_name",
            "pipeline_version",
            "project_root_folder",
        }
        assert essential_fields == expected_essential

        # Check system fields (have defaults)
        system_fields = set(categories["system"])
        expected_system = {
            "model_class",
            "current_date",
            "framework_version",
            "py_version",
            "source_dir",
        }
        assert system_fields == expected_system

        # Check derived fields (properties)
        derived_fields = set(categories["derived"])
        expected_derived = {
            "aws_region",
            "pipeline_name",
            "pipeline_description",
            "pipeline_s3_loc",
            "effective_source_dir",
            "resolved_source_dir",
            "script_contract",
            "step_catalog",
            "model_fields_set",  # Pydantic built-in property
            "model_extra",       # Pydantic built-in property
        }
        assert derived_fields == expected_derived

    def test_get_public_init_fields(self, valid_config_data):
        """Test getting public initialization fields."""
        config = BasePipelineConfig(**valid_config_data)
        init_fields = config.get_public_init_fields()

        # Should include all essential fields
        for field in [
            "author",
            "bucket",
            "role",
            "region",
            "service_name",
            "pipeline_version",
        ]:
            assert field in init_fields
            assert init_fields[field] == getattr(config, field)

        # Should include non-None system fields
        for field in ["model_class", "current_date", "framework_version", "py_version"]:
            assert field in init_fields

        # Should not include None fields
        if config.source_dir is None:
            assert "source_dir" not in init_fields

    def test_from_base_config(self, valid_config_data):
        """Test creating config from base config."""
        base_config = BasePipelineConfig(**valid_config_data)

        # Create derived config with additional fields
        derived_config = BasePipelineConfig.from_base_config(
            base_config, model_class="pytorch", framework_version="1.8.0"
        )

        # Should inherit base fields
        assert derived_config.author == base_config.author
        assert derived_config.bucket == base_config.bucket

        # Should override with new values
        assert derived_config.model_class == "pytorch"
        assert derived_config.framework_version == "1.8.0"

    def test_get_step_name_class_method(self):
        """Test get_step_name class method."""
        # This tests the class method that looks up step names
        step_name = BasePipelineConfig.get_step_name("TestConfig")
        # Should return the input if not found in registry
        assert step_name == "TestConfig"

    def test_get_config_class_name_class_method(self):
        """Test get_config_class_name class method."""
        # This tests the reverse lookup with a valid step name
        config_class = BasePipelineConfig.get_config_class_name("Base")
        # Should return the config class name for Base step
        assert config_class == "BasePipelineConfig"
        
        # Test with invalid step name should raise ValueError
        with pytest.raises(ValueError) as exc_info:
            BasePipelineConfig.get_config_class_name("InvalidStep")
        assert "Unknown step name: InvalidStep" in str(exc_info.value)

    def test_get_script_contract_default(self, valid_config_data):
        """Test get_script_contract default implementation."""
        config = BasePipelineConfig(**valid_config_data)
        contract = config.get_script_contract()

        # Base implementation should return None
        assert contract is None

    def test_get_script_path_default(self, valid_config_data):
        """Test get_script_path with default."""
        config = BasePipelineConfig(**valid_config_data)

        # Should return default when no contract or script_path
        default_path = "/test/default/script.py"
        script_path = config.get_script_path(default_path)
        assert script_path == default_path

        # Should return None when no default provided
        script_path = config.get_script_path()
        assert script_path is None

    def test_string_representation(self, valid_config_data):
        """Test string representation."""
        config = BasePipelineConfig(**valid_config_data)
        str_repr = str(config)

        # Should contain class name
        assert "BasePipelineConfig" in str_repr

        # Should contain field categories
        assert "Essential User Inputs" in str_repr
        assert "System Inputs" in str_repr
        assert "Derived Fields" in str_repr

        # Should contain some field values
        assert "test_author" in str_repr
        assert "test-bucket" in str_repr

    def test_print_config_method(self, valid_config_data):
        """Test print_config method."""
        config = BasePipelineConfig(**valid_config_data)

        # Should not raise any exceptions
        config.print_config()

    def test_region_mapping(self, valid_config_data):
        """Test region mapping for all supported regions."""
        region_tests = [("NA", "us-east-1"), ("EU", "eu-west-1"), ("FE", "us-west-2")]

        for region_code, expected_aws_region in region_tests:
            config_data = valid_config_data.copy()
            config_data["region"] = region_code
            config = BasePipelineConfig(**config_data)

            assert config.aws_region == expected_aws_region

    def test_derived_fields_caching(self, valid_config_data):
        """Test that derived fields are cached."""
        config = BasePipelineConfig(**valid_config_data)

        # Access derived property multiple times
        first_access = config.pipeline_name
        second_access = config.pipeline_name

        # Should return the same value (testing caching behavior)
        assert first_access == second_access
        assert first_access == "test_author-test_service-xgboost-NA"

    def test_extra_fields_allowed(self, valid_config_data):
        """Test that extra fields are allowed."""
        config_data = valid_config_data.copy()
        config_data["extra_field"] = "extra_value"

        # Should not raise an exception
        config = BasePipelineConfig(**config_data)

        # Extra field should be accessible
        assert config.extra_field == "extra_value"

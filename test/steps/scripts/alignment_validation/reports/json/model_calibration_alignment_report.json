{
  "script_name": "model_calibration",
  "level1": {
    "passed": true,
    "issues": [
      {
        "severity": "WARNING",
        "category": "environment_variables",
        "message": "Optional environment variable accessed without default: MULTICLASS_CATEGORIES",
        "details": {
          "variable": "MULTICLASS_CATEGORIES",
          "line": 1412,
          "script": "model_calibration"
        },
        "recommendation": "Provide default value when accessing optional variable MULTICLASS_CATEGORIES"
      },
      {
        "severity": "INFO",
        "category": "arguments",
        "message": "Script defines config-driven argument provided by builder: --job-type (accessed as args.job_type)",
        "details": {
          "cli_argument": "job-type",
          "python_attribute": "job_type",
          "script": "model_calibration",
          "source": "builder"
        },
        "recommendation": "Argument --job-type is provided by builder - no action needed"
      },
      {
        "severity": "INFO",
        "category": "testability_compliance",
        "message": "Main function follows testability pattern with all required parameters",
        "details": {
          "script": "model_calibration",
          "testability_parameters": [
            "job_args",
            "input_paths",
            "environ_vars",
            "output_paths"
          ]
        },
        "recommendation": "No action needed - script follows testability best practices"
      },
      {
        "severity": "WARNING",
        "category": "testability_env_access",
        "message": "Helper functions use direct environment access - consider parameter passing",
        "details": {
          "script": "model_calibration",
          "helper_accesses": [
            {
              "function": "from_env",
              "variable": "IS_BINARY",
              "line_number": 100
            },
            {
              "function": "from_env",
              "variable": "MULTICLASS_CATEGORIES",
              "line_number": 101
            },
            {
              "function": "from_env",
              "variable": "CALIBRATION_METHOD",
              "line_number": 115
            },
            {
              "function": "from_env",
              "variable": "LABEL_FIELD",
              "line_number": 116
            },
            {
              "function": "from_env",
              "variable": "SCORE_FIELD",
              "line_number": 117
            },
            {
              "function": "from_env",
              "variable": "IS_BINARY",
              "line_number": 118
            },
            {
              "function": "from_env",
              "variable": "MONOTONIC_CONSTRAINT",
              "line_number": 119
            },
            {
              "function": "from_env",
              "variable": "GAM_SPLINES",
              "line_number": 121
            },
            {
              "function": "from_env",
              "variable": "ERROR_THRESHOLD",
              "line_number": 122
            },
            {
              "function": "from_env",
              "variable": "NUM_CLASSES",
              "line_number": 123
            },
            {
              "function": "from_env",
              "variable": "SCORE_FIELD_PREFIX",
              "line_number": 124
            },
            {
              "function": null,
              "variable": "CALIBRATION_METHOD",
              "line_number": 1403
            },
            {
              "function": null,
              "variable": "LABEL_FIELD",
              "line_number": 1404
            },
            {
              "function": null,
              "variable": "SCORE_FIELD",
              "line_number": 1405
            },
            {
              "function": null,
              "variable": "IS_BINARY",
              "line_number": 1406
            },
            {
              "function": null,
              "variable": "MONOTONIC_CONSTRAINT",
              "line_number": 1407
            },
            {
              "function": null,
              "variable": "GAM_SPLINES",
              "line_number": 1408
            },
            {
              "function": null,
              "variable": "ERROR_THRESHOLD",
              "line_number": 1409
            },
            {
              "function": null,
              "variable": "NUM_CLASSES",
              "line_number": 1410
            },
            {
              "function": null,
              "variable": "SCORE_FIELD_PREFIX",
              "line_number": 1411
            },
            {
              "function": null,
              "variable": "MULTICLASS_CATEGORIES",
              "line_number": 1412
            }
          ]
        },
        "recommendation": "Pass environment variables as parameters to helper functions instead of direct access"
      },
      {
        "severity": "WARNING",
        "category": "testability_entry_point",
        "message": "Main function expects environ_vars parameter but no environment collection found in entry point",
        "details": {
          "script": "model_calibration"
        },
        "recommendation": "Add environment variable collection in __main__ block to pass to main function"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1029
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for input_paths",
        "details": {
          "script": "model_calibration",
          "parameter": "input_paths",
          "current_pattern": "input_paths.get",
          "line_number": 1040
        },
        "recommendation": "Use input_paths['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for output_paths",
        "details": {
          "script": "model_calibration",
          "parameter": "output_paths",
          "current_pattern": "output_paths.get",
          "line_number": 1041
        },
        "recommendation": "Use output_paths['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for output_paths",
        "details": {
          "script": "model_calibration",
          "parameter": "output_paths",
          "current_pattern": "output_paths.get",
          "line_number": 1042
        },
        "recommendation": "Use output_paths['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for output_paths",
        "details": {
          "script": "model_calibration",
          "parameter": "output_paths",
          "current_pattern": "output_paths.get",
          "line_number": 1043
        },
        "recommendation": "Use output_paths['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1044
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1045
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1046
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1047
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1048
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1052
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1053
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1054
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for environ_vars",
        "details": {
          "script": "model_calibration",
          "parameter": "environ_vars",
          "current_pattern": "environ_vars.get",
          "line_number": 1055
        },
        "recommendation": "Use environ_vars['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for job_args",
        "details": {
          "script": "model_calibration",
          "parameter": "job_args",
          "current_pattern": "job_args.job_type",
          "line_number": 1074
        },
        "recommendation": "Use job_args['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_parameter_access",
        "message": "Consider using dictionary-style access for job_args",
        "details": {
          "script": "model_calibration",
          "parameter": "job_args",
          "current_pattern": "args.job_type",
          "line_number": 1393
        },
        "recommendation": "Use job_args['key'] for accessing nested values"
      },
      {
        "severity": "INFO",
        "category": "testability_container_support",
        "message": "No container detection found - consider adding hybrid mode support",
        "details": {
          "script": "model_calibration"
        },
        "recommendation": "Add container detection to support both local and container execution"
      },
      {
        "severity": "WARNING",
        "category": "testability_helper_functions",
        "message": "Helper function 'from_env' accesses environment directly",
        "details": {
          "script": "model_calibration",
          "function": "from_env",
          "env_variables": [
            "IS_BINARY",
            "MULTICLASS_CATEGORIES",
            "CALIBRATION_METHOD",
            "LABEL_FIELD",
            "SCORE_FIELD",
            "IS_BINARY",
            "MONOTONIC_CONSTRAINT",
            "GAM_SPLINES",
            "ERROR_THRESHOLD",
            "NUM_CLASSES",
            "SCORE_FIELD_PREFIX"
          ],
          "line_numbers": [
            100,
            101,
            115,
            116,
            117,
            118,
            119,
            121,
            122,
            123,
            124
          ]
        },
        "recommendation": "Refactor 'from_env' to accept environment variables as parameters"
      },
      {
        "severity": "WARNING",
        "category": "testability_helper_functions",
        "message": "Helper function 'None' accesses environment directly",
        "details": {
          "script": "model_calibration",
          "function": null,
          "env_variables": [
            "CALIBRATION_METHOD",
            "LABEL_FIELD",
            "SCORE_FIELD",
            "IS_BINARY",
            "MONOTONIC_CONSTRAINT",
            "GAM_SPLINES",
            "ERROR_THRESHOLD",
            "NUM_CLASSES",
            "SCORE_FIELD_PREFIX",
            "MULTICLASS_CATEGORIES"
          ],
          "line_numbers": [
            1403,
            1404,
            1405,
            1406,
            1407,
            1408,
            1409,
            1410,
            1411,
            1412
          ]
        },
        "recommendation": "Refactor 'None' to accept environment variables as parameters"
      },
      {
        "severity": "INFO",
        "category": "framework_detected",
        "message": "Processing script uses sklearn framework",
        "details": {
          "script": "model_calibration",
          "step_type": "Processing",
          "framework": "sklearn"
        },
        "recommendation": "Ensure sklearn dependencies are properly specified"
      }
    ],
    "script_analysis": {
      "script_path": "/Users/tianpeixie/github_workspace/cursus/src/cursus/steps/scripts/model_calibration.py",
      "path_references": [
        "path='Model Calibration Script for SageMaker Processing.\\n\\nThis script calibrates model prediction scores to accurate probabilities,\\nwhich is essential for risk-based decision-making and threshold setting.\\nIt supports multiple calibration methods including GAM, Isotonic Regression,\\nand Platt Scaling, with options for monotonicity constraints.\\nIt supports both binary and multi-class classification scenarios.\\n' line_number=2 context='#!/usr/bin/env python\\n>>> \"\"\"Model Calibration Script for SageMaker Processing.\\n\\nThis script calibrates model prediction scores to accurate probabilities,' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/input/eval_data' line_number=43 context='\\n# Define standard SageMaker paths\\n>>> INPUT_DATA_PATH = \"/opt/ml/processing/input/eval_data\"\\nOUTPUT_CALIBRATION_PATH = \"/opt/ml/processing/output/calibration\"\\nOUTPUT_METRICS_PATH = \"/opt/ml/processing/output/metrics\"' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/calibration' line_number=44 context='# Define standard SageMaker paths\\nINPUT_DATA_PATH = \"/opt/ml/processing/input/eval_data\"\\n>>> OUTPUT_CALIBRATION_PATH = \"/opt/ml/processing/output/calibration\"\\nOUTPUT_METRICS_PATH = \"/opt/ml/processing/output/metrics\"\\nOUTPUT_CALIBRATED_DATA_PATH = \"/opt/ml/processing/output/calibrated_data\"' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/metrics' line_number=45 context='INPUT_DATA_PATH = \"/opt/ml/processing/input/eval_data\"\\nOUTPUT_CALIBRATION_PATH = \"/opt/ml/processing/output/calibration\"\\n>>> OUTPUT_METRICS_PATH = \"/opt/ml/processing/output/metrics\"\\nOUTPUT_CALIBRATED_DATA_PATH = \"/opt/ml/processing/output/calibrated_data\"\\n' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/calibrated_data' line_number=46 context='OUTPUT_CALIBRATION_PATH = \"/opt/ml/processing/output/calibration\"\\nOUTPUT_METRICS_PATH = \"/opt/ml/processing/output/metrics\"\\n>>> OUTPUT_CALIBRATED_DATA_PATH = \"/opt/ml/processing/output/calibrated_data\"\\n\\n' is_hardcoded=True construction_method=None",
        "path='Configuration class for model calibration.' line_number=50 context='\\nclass CalibrationConfig:\\n>>>     \"\"\"Configuration class for model calibration.\"\"\"\\n\\n    def __init__(' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/input/eval_data' line_number=54 context='    def __init__(\\n        self,\\n>>>         input_data_path: str = \"/opt/ml/processing/input/eval_data\",\\n        output_calibration_path: str = \"/opt/ml/processing/output/calibration\",\\n        output_metrics_path: str = \"/opt/ml/processing/output/metrics\",' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/calibration' line_number=55 context='        self,\\n        input_data_path: str = \"/opt/ml/processing/input/eval_data\",\\n>>>         output_calibration_path: str = \"/opt/ml/processing/output/calibration\",\\n        output_metrics_path: str = \"/opt/ml/processing/output/metrics\",\\n        output_calibrated_data_path: str = \"/opt/ml/processing/output/calibrated_data\",' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/metrics' line_number=56 context='        input_data_path: str = \"/opt/ml/processing/input/eval_data\",\\n        output_calibration_path: str = \"/opt/ml/processing/output/calibration\",\\n>>>         output_metrics_path: str = \"/opt/ml/processing/output/metrics\",\\n        output_calibrated_data_path: str = \"/opt/ml/processing/output/calibrated_data\",\\n        calibration_method: str = \"gam\",' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/calibrated_data' line_number=57 context='        output_calibration_path: str = \"/opt/ml/processing/output/calibration\",\\n        output_metrics_path: str = \"/opt/ml/processing/output/metrics\",\\n>>>         output_calibrated_data_path: str = \"/opt/ml/processing/output/calibrated_data\",\\n        calibration_method: str = \"gam\",\\n        label_field: str = \"label\",' is_hardcoded=True construction_method=None",
        "path='Initialize configuration with paths and parameters.' line_number=69 context='        multiclass_categories: Optional[List[str]] = None,\\n    ):\\n>>>         \"\"\"Initialize configuration with paths and parameters.\"\"\"\\n        # I/O Paths\\n        self.input_data_path = input_data_path' is_hardcoded=True construction_method=None",
        "path='Create configuration from environment variables.' line_number=97 context='    @classmethod\\n    def from_env(cls) -> \\'CalibrationConfig\\':\\n>>>         \"\"\"Create configuration from environment variables.\"\"\"\\n        # Parse multiclass categories from environment\\n        multiclass_categories = None' is_hardcoded=True construction_method=None",
        "path='0.05' line_number=122 context='            == \"true\",\\n            gam_splines=int(os.environ.get(\"GAM_SPLINES\", \"10\")),\\n>>>             error_threshold=float(os.environ.get(\"ERROR_THRESHOLD\", \"0.05\")),\\n            num_classes=int(os.environ.get(\"NUM_CLASSES\", \"2\")),\\n            score_field_prefix=os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),' is_hardcoded=True construction_method=None",
        "path=\"Create output directories if they don't exist.\" line_number=130 context='\\ndef create_directories(config: Optional[\\'CalibrationConfig\\'] = None) -> None:\\n>>>     \"\"\"Create output directories if they don\\'t exist.\"\"\"\\n    config = config or CalibrationConfig.from_env()\\n    os.makedirs(config.output_calibration_path, exist_ok=True)' is_hardcoded=True construction_method=None",
        "path='.csv' line_number=157 context='\\n    for fname in sorted(os.listdir(data_dir)):\\n>>>         if fname.lower().endswith((\".csv\", \".parquet\", \".json\")):\\n            return os.path.join(data_dir, fname)\\n' is_hardcoded=True construction_method=None",
        "path='.json' line_number=157 context='\\n    for fname in sorted(os.listdir(data_dir)):\\n>>>         if fname.lower().endswith((\".csv\", \".parquet\", \".json\")):\\n            return os.path.join(data_dir, fname)\\n' is_hardcoded=True construction_method=None",
        "path='.csv' line_number=184 context='    if data_file.endswith(\".parquet\"):\\n        df = pd.read_parquet(data_file)\\n>>>     elif data_file.endswith(\".csv\"):\\n        df = pd.read_csv(data_file)\\n    else:' is_hardcoded=True construction_method=None",
        "path='Log a section title with delimiters for better visibility.' line_number=222 context='\\ndef log_section(title: str) -> None:\\n>>>     \"\"\"Log a section title with delimiters for better visibility.\"\"\"\\n    delimiter = \"=\" * 80\\n    logger.info(delimiter)' is_hardcoded=True construction_method=None",
        "path=\"Extract and load data from nested tar.gz files in SageMaker output structure.\\n\\n    Handles SageMaker's specific output structure:\\n    - output.tar.gz (outer archive)\\n      - val.tar.gz (inner archive)\\n        - val/predictions.csv (actual data)\\n        - val_metrics/... (metrics and plots)\\n      - test.tar.gz (inner archive)\\n        - test/predictions.csv (actual data)\\n        - test_metrics/... (metrics and plots)\\n\\n    Also handles cases where the input path contains:\\n    - Direct output.tar.gz file\\n    - Path to a job directory that contains output/output.tar.gz\\n    - Path to a parent directory with job subdirectories\\n\\n    Args:\\n        config: Configuration object (optional, created from environment if not provided)\\n\\n    Returns:\\n        pd.DataFrame: Combined dataset with predictions from extracted tar.gz files\\n\\n    Raises:\\n        FileNotFoundError: If necessary tar.gz files or prediction data not found\\n    \" line_number=230 context='\\ndef extract_and_load_nested_tarball_data(config: Optional[\\'CalibrationConfig\\'] = None) -> pd.DataFrame:\\n>>>     \"\"\"Extract and load data from nested tar.gz files in SageMaker output structure.\\n\\n    Handles SageMaker\\'s specific output structure:' is_hardcoded=True construction_method=None",
        "path='output.tar.gz' line_number=279 context='    output_archive = None\\n    for fname in os.listdir(input_dir):\\n>>>         if fname.lower() == \"output.tar.gz\":\\n            output_archive = os.path.join(input_dir, fname)\\n            logger.info(f\"Found output.tar.gz directly in input directory\")' is_hardcoded=True construction_method=None",
        "path='output' line_number=293 context='            if os.path.isdir(item_path):\\n                # Check if this directory has an output/output.tar.gz file\\n>>>                 output_dir = os.path.join(item_path, \"output\")\\n                if os.path.isdir(output_dir):\\n                    nested_archive = os.path.join(output_dir, \"output.tar.gz\")' is_hardcoded=False construction_method='os.path.join'",
        "path='output.tar.gz' line_number=295 context='                output_dir = os.path.join(item_path, \"output\")\\n                if os.path.isdir(output_dir):\\n>>>                     nested_archive = os.path.join(output_dir, \"output.tar.gz\")\\n                    if os.path.isfile(nested_archive):\\n                        output_archive = nested_archive' is_hardcoded=False construction_method='os.path.join'",
        "path='output.tar.gz' line_number=295 context='                output_dir = os.path.join(item_path, \"output\")\\n                if os.path.isdir(output_dir):\\n>>>                     nested_archive = os.path.join(output_dir, \"output.tar.gz\")\\n                    if os.path.isfile(nested_archive):\\n                        output_archive = nested_archive' is_hardcoded=True construction_method=None",
        "path='output.tar.gz' line_number=308 context='        for root, _, files in os.walk(input_dir):\\n            for fname in files:\\n>>>                 if fname.lower() == \"output.tar.gz\":\\n                    output_archive = os.path.join(root, fname)\\n                    logger.info(' is_hardcoded=True construction_method=None",
        "path='.2f' line_number=325 context='\\n    logger.info(f\"Found SageMaker output archive: {output_archive}\")\\n>>>     logger.info(f\"File size: {os.path.getsize(output_archive) / (1024*1024):.2f} MB\")\\n\\n    # Create temporary directories for extraction' is_hardcoded=True construction_method=None",
        "path='.2f' line_number=340 context='            logger.info(f\"Outer archive contains {len(members)} files:\")\\n            for member in members:\\n>>>                 logger.info(f\"  - {member.name} ({member.size / 1024:.2f} KB)\")\\n            tar.extractall(path=outer_temp_dir)\\n        logger.info(f\"Extracted to: {outer_temp_dir}\")' is_hardcoded=True construction_method=None",
        "path='.tar.gz' line_number=347 context='        inner_archives = []\\n        for fname in os.listdir(outer_temp_dir):\\n>>>             if fname.lower().endswith(\".tar.gz\"):\\n                inner_archives.append(os.path.join(outer_temp_dir, fname))\\n' is_hardcoded=True construction_method=None",
        "path='No val.tar.gz or test.tar.gz found in output.tar.gz' line_number=352 context='        if not inner_archives:\\n            raise FileNotFoundError(\\n>>>                 \"No val.tar.gz or test.tar.gz found in output.tar.gz\"\\n            )\\n' is_hardcoded=True construction_method=None",
        "path='.' line_number=361 context='        # Process each inner archive (val.tar.gz, test.tar.gz)\\n        for inner_archive in inner_archives:\\n>>>             archive_name = os.path.basename(inner_archive).split(\".\")[\\n                0\\n            ]  # \\'val\\' or \\'test\\'' is_hardcoded=True construction_method=None",
        "path='.2f' line_number=375 context='                logger.info(f\"Inner archive contains {len(members)} files:\")\\n                for member in members:\\n>>>                     logger.info(f\"  - {member.name} ({member.size / 1024:.2f} KB)\")\\n                tar.extractall(path=inner_extract_dir)\\n            logger.info(f\"Extracted inner archive to: {inner_extract_dir}\")' is_hardcoded=True construction_method=None",
        "path='predictions.csv' line_number=380 context='\\n            # Look for predictions.csv in the correct structure\\n>>>             predictions_path = os.path.join(\\n                inner_extract_dir, archive_name, \"predictions.csv\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='predictions.csv' line_number=381 context='            # Look for predictions.csv in the correct structure\\n            predictions_path = os.path.join(\\n>>>                 inner_extract_dir, archive_name, \"predictions.csv\"\\n            )\\n            if not os.path.exists(predictions_path):' is_hardcoded=True construction_method=None",
        "path='Column mismatch between datasets. Common columns will be used.' line_number=408 context='                if set(df.columns) != set(combined_df.columns):\\n                    logger.warning(\\n>>>                         f\"Column mismatch between datasets. Common columns will be used.\"\\n                    )\\n                    common_cols = list(' is_hardcoded=True construction_method=None",
        "path='Compute comprehensive calibration metrics including ECE, MCE, and reliability diagram.\\n\\n    This function calculates:\\n    - Expected Calibration Error (ECE): weighted average of absolute calibration errors\\n    - Maximum Calibration Error (MCE): maximum calibration error across all bins\\n    - Reliability diagram data: points for plotting calibration curve\\n    - Bin statistics: detailed information about each probability bin\\n    - Brier score: quadratic scoring rule for probabilistic predictions\\n    - Preservation of discrimination: comparison of AUC before/after calibration\\n\\n    Args:\\n        y_true: Ground truth binary labels (0/1)\\n        y_prob: Predicted probabilities\\n        n_bins: Number of bins for calibration curve\\n\\n    Returns:\\n        Dict: Dictionary containing calibration metrics\\n    ' line_number=686 context='    y_true: np.ndarray, y_prob: np.ndarray, n_bins: int = 10\\n) -> Dict[str, Any]:\\n>>>     \"\"\"Compute comprehensive calibration metrics including ECE, MCE, and reliability diagram.\\n\\n    This function calculates:' is_hardcoded=True construction_method=None",
        "path='reliability_diagram.png' line_number=918 context='\\n    # Save figure\\n>>>     figure_path = os.path.join(config.output_metrics_path, \"reliability_diagram.png\")\\n    plt.savefig(figure_path)\\n    plt.close(fig)' is_hardcoded=False construction_method='os.path.join'",
        "path='reliability_diagram.png' line_number=918 context='\\n    # Save figure\\n>>>     figure_path = os.path.join(config.output_metrics_path, \"reliability_diagram.png\")\\n    plt.savefig(figure_path)\\n    plt.close(fig)' is_hardcoded=True construction_method=None",
        "path='multiclass_reliability_diagram.png' line_number=1000 context='\\n    plt.tight_layout()\\n>>>     figure_path = os.path.join(\\n        config.output_metrics_path, \"multiclass_reliability_diagram.png\"\\n    )' is_hardcoded=False construction_method='os.path.join'",
        "path='multiclass_reliability_diagram.png' line_number=1001 context='    plt.tight_layout()\\n    figure_path = os.path.join(\\n>>>         config.output_metrics_path, \"multiclass_reliability_diagram.png\"\\n    )\\n    plt.savefig(figure_path)' is_hardcoded=True construction_method=None",
        "path='0.05' line_number=1053 context='            == \"true\",\\n            gam_splines=int(environ_vars.get(\"GAM_SPLINES\", \"10\")),\\n>>>             error_threshold=float(environ_vars.get(\"ERROR_THRESHOLD\", \"0.05\")),\\n            num_classes=int(environ_vars.get(\"NUM_CLASSES\", \"2\")),\\n            score_field_prefix=environ_vars.get(' is_hardcoded=True construction_method=None",
        "path='calibration_metrics.json' line_number=1155 context='\\n            # Save metrics report\\n>>>             metrics_path = os.path.join(\\n                config.output_metrics_path, \"calibration_metrics.json\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='calibration_metrics.json' line_number=1156 context='            # Save metrics report\\n            metrics_path = os.path.join(\\n>>>                 config.output_metrics_path, \"calibration_metrics.json\"\\n            )\\n            with open(metrics_path, \"w\") as f:' is_hardcoded=True construction_method=None",
        "path='calibration_model.pkl' line_number=1162 context='\\n            # Save calibrator model\\n>>>             calibrator_path = os.path.join(\\n                config.output_calibration_path, \"calibration_model.pkl\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='calibration_model.pkl' line_number=1163 context='            # Save calibrator model\\n            calibrator_path = os.path.join(\\n>>>                 config.output_calibration_path, \"calibration_model.pkl\"\\n            )\\n            with open(calibrator_path, \"wb\") as f:' is_hardcoded=True construction_method=None",
        "path='calibrated_data.csv' line_number=1170 context='            # Add calibrated scores to dataframe and save\\n            df[\"calibrated_\" + config.score_field] = y_prob_calibrated\\n>>>             output_path = os.path.join(\\n                config.output_calibrated_data_path, \"calibrated_data.csv\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='calibrated_data.csv' line_number=1171 context='            df[\"calibrated_\" + config.score_field] = y_prob_calibrated\\n            output_path = os.path.join(\\n>>>                 config.output_calibrated_data_path, \"calibrated_data.csv\"\\n            )\\n            df.to_csv(output_path, index=False)' is_hardcoded=True construction_method=None",
        "path='calibration_summary.json' line_number=1195 context='            }\\n\\n>>>             summary_path = os.path.join(\\n                config.output_calibration_path, \"calibration_summary.json\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='calibration_summary.json' line_number=1196 context='\\n            summary_path = os.path.join(\\n>>>                 config.output_calibration_path, \"calibration_summary.json\"\\n            )\\n            with open(summary_path, \"w\") as f:' is_hardcoded=True construction_method=None",
        "path='.4f' line_number=1212 context='\\n            logger.info(\\n>>>                 f\"Binary calibration complete. ECE reduced from {uncalibrated_metrics[\\'expected_calibration_error\\']:.4f} to {calibrated_metrics[\\'expected_calibration_error\\']:.4f}\"\\n            )\\n' is_hardcoded=True construction_method=None",
        "path='.4f' line_number=1212 context='\\n            logger.info(\\n>>>                 f\"Binary calibration complete. ECE reduced from {uncalibrated_metrics[\\'expected_calibration_error\\']:.4f} to {calibrated_metrics[\\'expected_calibration_error\\']:.4f}\"\\n            )\\n' is_hardcoded=True construction_method=None",
        "path='calibration_metrics.json' line_number=1278 context='\\n            # Save metrics report\\n>>>             metrics_path = os.path.join(\\n                config.output_metrics_path, \"calibration_metrics.json\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='calibration_metrics.json' line_number=1279 context='            # Save metrics report\\n            metrics_path = os.path.join(\\n>>>                 config.output_metrics_path, \"calibration_metrics.json\"\\n            )\\n            with open(metrics_path, \"w\") as f:' is_hardcoded=True construction_method=None",
        "path='calibration_models' line_number=1285 context='\\n            # Save calibrator models\\n>>>             calibrator_dir = os.path.join(\\n                config.output_calibration_path, \"calibration_models\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='.pkl' line_number=1294 context='                class_name = config.multiclass_categories[i]\\n                calibrator_path = os.path.join(\\n>>>                     calibrator_dir, f\"calibration_model_class_{class_name}.pkl\"\\n                )\\n                with open(calibrator_path, \"wb\") as f:' is_hardcoded=True construction_method=None",
        "path='calibrated_data.csv' line_number=1306 context='                df[f\"calibrated_{col_name}\"] = y_prob_calibrated[:, i]\\n\\n>>>             output_path = os.path.join(\\n                config.output_calibrated_data_path, \"calibrated_data.csv\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='calibrated_data.csv' line_number=1307 context='\\n            output_path = os.path.join(\\n>>>                 config.output_calibrated_data_path, \"calibrated_data.csv\"\\n            )\\n            df.to_csv(output_path, index=False)' is_hardcoded=True construction_method=None",
        "path='calibration_summary.json' line_number=1339 context='            }\\n\\n>>>             summary_path = os.path.join(\\n                config.output_calibration_path, \"calibration_summary.json\"\\n            )' is_hardcoded=False construction_method='os.path.join'",
        "path='calibration_summary.json' line_number=1340 context='\\n            summary_path = os.path.join(\\n>>>                 config.output_calibration_path, \"calibration_summary.json\"\\n            )\\n            with open(summary_path, \"w\") as f:' is_hardcoded=True construction_method=None",
        "path='.4f' line_number=1357 context='            logger.info(\\n                f\"Multi-class calibration complete. Macro ECE reduced from \"\\n>>>                 + f\"{uncalibrated_metrics[\\'macro_expected_calibration_error\\']:.4f} to \"\\n                + f\"{calibrated_metrics[\\'macro_expected_calibration_error\\']:.4f}\"\\n            )' is_hardcoded=True construction_method=None",
        "path='.4f' line_number=1358 context='                f\"Multi-class calibration complete. Macro ECE reduced from \"\\n                + f\"{uncalibrated_metrics[\\'macro_expected_calibration_error\\']:.4f} to \"\\n>>>                 + f\"{calibrated_metrics[\\'macro_expected_calibration_error\\']:.4f}\"\\n            )\\n' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/input/eval_data' line_number=1396 context='\\n    # Define standard SageMaker paths\\n>>>     INPUT_DATA_PATH = \"/opt/ml/processing/input/eval_data\"\\n    OUTPUT_CALIBRATION_PATH = \"/opt/ml/processing/output/calibration\"\\n    OUTPUT_METRICS_PATH = \"/opt/ml/processing/output/metrics\"' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/calibration' line_number=1397 context='    # Define standard SageMaker paths\\n    INPUT_DATA_PATH = \"/opt/ml/processing/input/eval_data\"\\n>>>     OUTPUT_CALIBRATION_PATH = \"/opt/ml/processing/output/calibration\"\\n    OUTPUT_METRICS_PATH = \"/opt/ml/processing/output/metrics\"\\n    OUTPUT_CALIBRATED_DATA_PATH = \"/opt/ml/processing/output/calibrated_data\"' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/metrics' line_number=1398 context='    INPUT_DATA_PATH = \"/opt/ml/processing/input/eval_data\"\\n    OUTPUT_CALIBRATION_PATH = \"/opt/ml/processing/output/calibration\"\\n>>>     OUTPUT_METRICS_PATH = \"/opt/ml/processing/output/metrics\"\\n    OUTPUT_CALIBRATED_DATA_PATH = \"/opt/ml/processing/output/calibrated_data\"\\n' is_hardcoded=True construction_method=None",
        "path='/opt/ml/processing/output/calibrated_data' line_number=1399 context='    OUTPUT_CALIBRATION_PATH = \"/opt/ml/processing/output/calibration\"\\n    OUTPUT_METRICS_PATH = \"/opt/ml/processing/output/metrics\"\\n>>>     OUTPUT_CALIBRATED_DATA_PATH = \"/opt/ml/processing/output/calibrated_data\"\\n\\n    # Parse environment variables' is_hardcoded=True construction_method=None",
        "path='0.05' line_number=1409 context='        \"MONOTONIC_CONSTRAINT\": os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\"),\\n        \"GAM_SPLINES\": os.environ.get(\"GAM_SPLINES\", \"10\"),\\n>>>         \"ERROR_THRESHOLD\": os.environ.get(\"ERROR_THRESHOLD\", \"0.05\"),\\n        \"NUM_CLASSES\": os.environ.get(\"NUM_CLASSES\", \"2\"),\\n        \"SCORE_FIELD_PREFIX\": os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),' is_hardcoded=True construction_method=None"
      ],
      "env_var_accesses": [
        "variable_name='IS_BINARY' line_number=100 context='        # Parse multiclass categories from environment\\n        multiclass_categories = None\\n>>>         if os.environ.get(\"IS_BINARY\", \"True\").lower() != \"true\":\\n            multiclass_cats = os.environ.get(\"MULTICLASS_CATEGORIES\", None)\\n            if multiclass_cats:' access_method='os.environ.get' has_default=True default_value='True'",
        "variable_name='MULTICLASS_CATEGORIES' line_number=101 context='        multiclass_categories = None\\n        if os.environ.get(\"IS_BINARY\", \"True\").lower() != \"true\":\\n>>>             multiclass_cats = os.environ.get(\"MULTICLASS_CATEGORIES\", None)\\n            if multiclass_cats:\\n                try:' access_method='os.environ.get' has_default=True default_value=None",
        "variable_name='CALIBRATION_METHOD' line_number=115 context='            output_metrics_path=OUTPUT_METRICS_PATH,\\n            output_calibrated_data_path=OUTPUT_CALIBRATED_DATA_PATH,\\n>>>             calibration_method=os.environ.get(\"CALIBRATION_METHOD\", \"gam\"),\\n            label_field=os.environ.get(\"LABEL_FIELD\", \"label\"),\\n            score_field=os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),' access_method='os.environ.get' has_default=True default_value='gam'",
        "variable_name='LABEL_FIELD' line_number=116 context='            output_calibrated_data_path=OUTPUT_CALIBRATED_DATA_PATH,\\n            calibration_method=os.environ.get(\"CALIBRATION_METHOD\", \"gam\"),\\n>>>             label_field=os.environ.get(\"LABEL_FIELD\", \"label\"),\\n            score_field=os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),\\n            is_binary=os.environ.get(\"IS_BINARY\", \"True\").lower() == \"true\",' access_method='os.environ.get' has_default=True default_value='label'",
        "variable_name='SCORE_FIELD' line_number=117 context='            calibration_method=os.environ.get(\"CALIBRATION_METHOD\", \"gam\"),\\n            label_field=os.environ.get(\"LABEL_FIELD\", \"label\"),\\n>>>             score_field=os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),\\n            is_binary=os.environ.get(\"IS_BINARY\", \"True\").lower() == \"true\",\\n            monotonic_constraint=os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\").lower()' access_method='os.environ.get' has_default=True default_value='prob_class_1'",
        "variable_name='IS_BINARY' line_number=118 context='            label_field=os.environ.get(\"LABEL_FIELD\", \"label\"),\\n            score_field=os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),\\n>>>             is_binary=os.environ.get(\"IS_BINARY\", \"True\").lower() == \"true\",\\n            monotonic_constraint=os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\").lower()\\n            == \"true\",' access_method='os.environ.get' has_default=True default_value='True'",
        "variable_name='MONOTONIC_CONSTRAINT' line_number=119 context='            score_field=os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),\\n            is_binary=os.environ.get(\"IS_BINARY\", \"True\").lower() == \"true\",\\n>>>             monotonic_constraint=os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\").lower()\\n            == \"true\",\\n            gam_splines=int(os.environ.get(\"GAM_SPLINES\", \"10\")),' access_method='os.environ.get' has_default=True default_value='True'",
        "variable_name='GAM_SPLINES' line_number=121 context='            monotonic_constraint=os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\").lower()\\n            == \"true\",\\n>>>             gam_splines=int(os.environ.get(\"GAM_SPLINES\", \"10\")),\\n            error_threshold=float(os.environ.get(\"ERROR_THRESHOLD\", \"0.05\")),\\n            num_classes=int(os.environ.get(\"NUM_CLASSES\", \"2\")),' access_method='os.environ.get' has_default=True default_value='10'",
        "variable_name='ERROR_THRESHOLD' line_number=122 context='            == \"true\",\\n            gam_splines=int(os.environ.get(\"GAM_SPLINES\", \"10\")),\\n>>>             error_threshold=float(os.environ.get(\"ERROR_THRESHOLD\", \"0.05\")),\\n            num_classes=int(os.environ.get(\"NUM_CLASSES\", \"2\")),\\n            score_field_prefix=os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),' access_method='os.environ.get' has_default=True default_value='0.05'",
        "variable_name='NUM_CLASSES' line_number=123 context='            gam_splines=int(os.environ.get(\"GAM_SPLINES\", \"10\")),\\n            error_threshold=float(os.environ.get(\"ERROR_THRESHOLD\", \"0.05\")),\\n>>>             num_classes=int(os.environ.get(\"NUM_CLASSES\", \"2\")),\\n            score_field_prefix=os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),\\n            multiclass_categories=multiclass_categories,' access_method='os.environ.get' has_default=True default_value='2'",
        "variable_name='SCORE_FIELD_PREFIX' line_number=124 context='            error_threshold=float(os.environ.get(\"ERROR_THRESHOLD\", \"0.05\")),\\n            num_classes=int(os.environ.get(\"NUM_CLASSES\", \"2\")),\\n>>>             score_field_prefix=os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),\\n            multiclass_categories=multiclass_categories,\\n        )' access_method='os.environ.get' has_default=True default_value='prob_class_'",
        "variable_name='CALIBRATION_METHOD' line_number=1403 context='    # Parse environment variables\\n    environ_vars = {\\n>>>         \"CALIBRATION_METHOD\": os.environ.get(\"CALIBRATION_METHOD\", \"gam\"),\\n        \"LABEL_FIELD\": os.environ.get(\"LABEL_FIELD\", \"label\"),\\n        \"SCORE_FIELD\": os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),' access_method='os.environ.get' has_default=True default_value='gam'",
        "variable_name='LABEL_FIELD' line_number=1404 context='    environ_vars = {\\n        \"CALIBRATION_METHOD\": os.environ.get(\"CALIBRATION_METHOD\", \"gam\"),\\n>>>         \"LABEL_FIELD\": os.environ.get(\"LABEL_FIELD\", \"label\"),\\n        \"SCORE_FIELD\": os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),\\n        \"IS_BINARY\": os.environ.get(\"IS_BINARY\", \"True\"),' access_method='os.environ.get' has_default=True default_value='label'",
        "variable_name='SCORE_FIELD' line_number=1405 context='        \"CALIBRATION_METHOD\": os.environ.get(\"CALIBRATION_METHOD\", \"gam\"),\\n        \"LABEL_FIELD\": os.environ.get(\"LABEL_FIELD\", \"label\"),\\n>>>         \"SCORE_FIELD\": os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),\\n        \"IS_BINARY\": os.environ.get(\"IS_BINARY\", \"True\"),\\n        \"MONOTONIC_CONSTRAINT\": os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\"),' access_method='os.environ.get' has_default=True default_value='prob_class_1'",
        "variable_name='IS_BINARY' line_number=1406 context='        \"LABEL_FIELD\": os.environ.get(\"LABEL_FIELD\", \"label\"),\\n        \"SCORE_FIELD\": os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),\\n>>>         \"IS_BINARY\": os.environ.get(\"IS_BINARY\", \"True\"),\\n        \"MONOTONIC_CONSTRAINT\": os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\"),\\n        \"GAM_SPLINES\": os.environ.get(\"GAM_SPLINES\", \"10\"),' access_method='os.environ.get' has_default=True default_value='True'",
        "variable_name='MONOTONIC_CONSTRAINT' line_number=1407 context='        \"SCORE_FIELD\": os.environ.get(\"SCORE_FIELD\", \"prob_class_1\"),\\n        \"IS_BINARY\": os.environ.get(\"IS_BINARY\", \"True\"),\\n>>>         \"MONOTONIC_CONSTRAINT\": os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\"),\\n        \"GAM_SPLINES\": os.environ.get(\"GAM_SPLINES\", \"10\"),\\n        \"ERROR_THRESHOLD\": os.environ.get(\"ERROR_THRESHOLD\", \"0.05\"),' access_method='os.environ.get' has_default=True default_value='True'",
        "variable_name='GAM_SPLINES' line_number=1408 context='        \"IS_BINARY\": os.environ.get(\"IS_BINARY\", \"True\"),\\n        \"MONOTONIC_CONSTRAINT\": os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\"),\\n>>>         \"GAM_SPLINES\": os.environ.get(\"GAM_SPLINES\", \"10\"),\\n        \"ERROR_THRESHOLD\": os.environ.get(\"ERROR_THRESHOLD\", \"0.05\"),\\n        \"NUM_CLASSES\": os.environ.get(\"NUM_CLASSES\", \"2\"),' access_method='os.environ.get' has_default=True default_value='10'",
        "variable_name='ERROR_THRESHOLD' line_number=1409 context='        \"MONOTONIC_CONSTRAINT\": os.environ.get(\"MONOTONIC_CONSTRAINT\", \"True\"),\\n        \"GAM_SPLINES\": os.environ.get(\"GAM_SPLINES\", \"10\"),\\n>>>         \"ERROR_THRESHOLD\": os.environ.get(\"ERROR_THRESHOLD\", \"0.05\"),\\n        \"NUM_CLASSES\": os.environ.get(\"NUM_CLASSES\", \"2\"),\\n        \"SCORE_FIELD_PREFIX\": os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),' access_method='os.environ.get' has_default=True default_value='0.05'",
        "variable_name='NUM_CLASSES' line_number=1410 context='        \"GAM_SPLINES\": os.environ.get(\"GAM_SPLINES\", \"10\"),\\n        \"ERROR_THRESHOLD\": os.environ.get(\"ERROR_THRESHOLD\", \"0.05\"),\\n>>>         \"NUM_CLASSES\": os.environ.get(\"NUM_CLASSES\", \"2\"),\\n        \"SCORE_FIELD_PREFIX\": os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),\\n        \"MULTICLASS_CATEGORIES\": os.environ.get(\"MULTICLASS_CATEGORIES\"),' access_method='os.environ.get' has_default=True default_value='2'",
        "variable_name='SCORE_FIELD_PREFIX' line_number=1411 context='        \"ERROR_THRESHOLD\": os.environ.get(\"ERROR_THRESHOLD\", \"0.05\"),\\n        \"NUM_CLASSES\": os.environ.get(\"NUM_CLASSES\", \"2\"),\\n>>>         \"SCORE_FIELD_PREFIX\": os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),\\n        \"MULTICLASS_CATEGORIES\": os.environ.get(\"MULTICLASS_CATEGORIES\"),\\n    }' access_method='os.environ.get' has_default=True default_value='prob_class_'",
        "variable_name='MULTICLASS_CATEGORIES' line_number=1412 context='        \"NUM_CLASSES\": os.environ.get(\"NUM_CLASSES\", \"2\"),\\n        \"SCORE_FIELD_PREFIX\": os.environ.get(\"SCORE_FIELD_PREFIX\", \"prob_class_\"),\\n>>>         \"MULTICLASS_CATEGORIES\": os.environ.get(\"MULTICLASS_CATEGORIES\"),\\n    }\\n' access_method='os.environ.get' has_default=False default_value=None"
      ],
      "imports": [
        "module_name='os' import_alias=None line_number=11 is_from_import=False imported_items=[]",
        "module_name='sys' import_alias=None line_number=12 is_from_import=False imported_items=[]",
        "module_name='json' import_alias=None line_number=13 is_from_import=False imported_items=[]",
        "module_name='logging' import_alias=None line_number=14 is_from_import=False imported_items=[]",
        "module_name='traceback' import_alias=None line_number=15 is_from_import=False imported_items=[]",
        "module_name='argparse' import_alias=None line_number=16 is_from_import=False imported_items=[]",
        "module_name='typing' import_alias=None line_number=17 is_from_import=True imported_items=['Dict', 'List', 'Any', 'Optional', 'Tuple']",
        "module_name='numpy' import_alias='np' line_number=19 is_from_import=False imported_items=[]",
        "module_name='pandas' import_alias='pd' line_number=20 is_from_import=False imported_items=[]",
        "module_name='pickle' import_alias='pkl' line_number=21 is_from_import=False imported_items=[]",
        "module_name='matplotlib.pyplot' import_alias='plt' line_number=22 is_from_import=False imported_items=[]",
        "module_name='sklearn.isotonic' import_alias=None line_number=23 is_from_import=True imported_items=['IsotonicRegression']",
        "module_name='sklearn.linear_model' import_alias=None line_number=24 is_from_import=True imported_items=['LogisticRegression']",
        "module_name='sklearn.calibration' import_alias=None line_number=25 is_from_import=True imported_items=['calibration_curve']",
        "module_name='sklearn.metrics' import_alias=None line_number=26 is_from_import=True imported_items=['brier_score_loss', 'roc_auc_score']",
        "module_name='pygam' import_alias=None line_number=30 is_from_import=True imported_items=['LogisticGAM', 's']",
        "module_name='tarfile' import_alias=None line_number=255 is_from_import=False imported_items=[]",
        "module_name='tempfile' import_alias=None line_number=256 is_from_import=False imported_items=[]",
        "module_name='shutil' import_alias=None line_number=257 is_from_import=False imported_items=[]",
        "module_name='ast' import_alias=None line_number=1032 is_from_import=False imported_items=[]"
      ],
      "argument_definitions": [
        "argument_name='job_type' line_number=1385 is_required=False has_default=True default_value='calibration' argument_type='str' choices=None"
      ],
      "file_operations": [
        "file_path='<file_object>' operation_type='write' line_number=1159 context='            )\\n            with open(metrics_path, \"w\") as f:\\n>>>                 json.dump(metrics_report, f, indent=2)\\n\\n            # Save calibrator model' mode=None method='json.dump'",
        "file_path='<file_object>' operation_type='write' line_number=1166 context='            )\\n            with open(calibrator_path, \"wb\") as f:\\n>>>                 pkl.dump(calibrator, f)\\n\\n            # Add calibrated scores to dataframe and save' mode=None method='pickle.dump'",
        "file_path='<file_object>' operation_type='write' line_number=1199 context='            )\\n            with open(summary_path, \"w\") as f:\\n>>>                 json.dump(summary, f, indent=2)\\n\\n            # Check if calibration improved by error threshold' mode=None method='json.dump'",
        "file_path='<file_object>' operation_type='write' line_number=1282 context='            )\\n            with open(metrics_path, \"w\") as f:\\n>>>                 json.dump(metrics_report, f, indent=2)\\n\\n            # Save calibrator models' mode=None method='json.dump'",
        "file_path='<file_object>' operation_type='write' line_number=1297 context='                )\\n                with open(calibrator_path, \"wb\") as f:\\n>>>                     pkl.dump(calibrator, f)\\n                calibrator_paths[f\"class_{class_name}\"] = calibrator_path\\n' mode=None method='pickle.dump'",
        "file_path='<file_object>' operation_type='write' line_number=1343 context='            )\\n            with open(summary_path, \"w\") as f:\\n>>>                 json.dump(summary, f, indent=2)\\n\\n            # Check if calibration improved by error threshold' mode=None method='json.dump'"
      ],
      "step_type": "Processing",
      "framework": "sklearn",
      "step_type_patterns": {}
    },
    "contract": {
      "entry_point": "model_calibration.py",
      "inputs": {
        "evaluation_data": {
          "path": "/opt/ml/processing/input/eval_data"
        }
      },
      "outputs": {
        "calibration_output": {
          "path": "/opt/ml/processing/output/calibration"
        },
        "metrics_output": {
          "path": "/opt/ml/processing/output/metrics"
        },
        "calibrated_data": {
          "path": "/opt/ml/processing/output/calibrated_data"
        }
      },
      "arguments": {},
      "environment_variables": {
        "required": [
          "CALIBRATION_METHOD",
          "LABEL_FIELD",
          "SCORE_FIELD",
          "IS_BINARY"
        ],
        "optional": {
          "MONOTONIC_CONSTRAINT": "True",
          "GAM_SPLINES": "10",
          "ERROR_THRESHOLD": "0.05",
          "NUM_CLASSES": "2",
          "SCORE_FIELD_PREFIX": "prob_class_",
          "MULTICLASS_CATEGORIES": "[0, 1]"
        }
      },
      "description": "Contract for model calibration processing step.\n    \n    The model calibration step takes a trained model's raw prediction scores and\n    calibrates them to better reflect true probabilities, which is essential for\n    risk-based decision-making, threshold setting, and confidence in model outputs.\n    Supports both binary and multi-class classification scenarios.\n    \n    Input Structure:\n    - /opt/ml/processing/input/eval_data: Evaluation dataset with ground truth labels and model predictions\n    \n    Output Structure:\n    - /opt/ml/processing/output/calibration: Calibration mapping and artifacts\n    - /opt/ml/processing/output/metrics: Calibration quality metrics\n    - /opt/ml/processing/output/calibrated_data: Dataset with calibrated probabilities\n    \n    Environment Variables:\n    - CALIBRATION_METHOD: Method to use for calibration (gam, isotonic, platt)\n    - LABEL_FIELD: Name of the label column\n    - SCORE_FIELD: Name of the prediction score column (for binary classification)\n    - IS_BINARY: Whether this is a binary classification task (true/false)\n    - MONOTONIC_CONSTRAINT: Whether to enforce monotonicity in GAM (optional)\n    - GAM_SPLINES: Number of splines for GAM (optional)\n    - ERROR_THRESHOLD: Acceptable calibration error threshold (optional)\n    - NUM_CLASSES: Number of classes for multi-class classification (optional, default=2)\n    - SCORE_FIELD_PREFIX: Prefix for probability columns in multi-class scenario (optional)\n    - MULTICLASS_CATEGORIES: JSON string of class names/values for multi-class (optional)\n    ",
      "framework_requirements": {
        "scikit-learn": ">=0.23.2,<1.0.0",
        "pandas": ">=1.2.0,<2.0.0",
        "numpy": ">=1.20.0",
        "pygam": ">=0.8.0",
        "matplotlib": ">=3.3.0"
      }
    }
  },
  "level2": {
    "passed": true,
    "issues": [
      {
        "severity": "INFO",
        "category": "multi_variant_validation",
        "message": "Smart Specification Selection: validated against 4 variants",
        "details": {
          "contract": "model_calibration_contract",
          "variants": [
            "training",
            "testing",
            "validation",
            "calibration"
          ],
          "total_dependencies": 1,
          "total_outputs": 3,
          "contract_inputs": 1,
          "contract_outputs": 3
        },
        "recommendation": "Multi-variant validation completed successfully"
      },
      {
        "severity": "INFO",
        "category": "step_type_resolution",
        "message": "Step type resolved via registry: ModelCalibration_Training -> ModelCalibration -> Processing",
        "details": {
          "contract": "model_calibration_contract",
          "original_spec_type": "ModelCalibration_Training",
          "canonical_name": "ModelCalibration",
          "resolved_sagemaker_type": "Processing",
          "registry_available": true
        },
        "recommendation": "Using Processing step property paths for validation"
      },
      {
        "severity": "INFO",
        "category": "property_path_validation",
        "message": "Valid property path in output calibration_output: properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
        "details": {
          "contract": "model_calibration_contract",
          "logical_name": "calibration_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
          "step_type": "processing",
          "validation_source": "SageMaker Documentation v2.92.2",
          "documentation_reference": "https://sagemaker.readthedocs.io/en/v2.92.2/amazon_sagemaker_model_building_pipeline.html#data-dependency-property-reference"
        },
        "recommendation": "Property path is correctly formatted for the step type"
      },
      {
        "severity": "INFO",
        "category": "property_path_validation",
        "message": "Valid property path in output metrics_output: properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
        "details": {
          "contract": "model_calibration_contract",
          "logical_name": "metrics_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
          "step_type": "processing",
          "validation_source": "SageMaker Documentation v2.92.2",
          "documentation_reference": "https://sagemaker.readthedocs.io/en/v2.92.2/amazon_sagemaker_model_building_pipeline.html#data-dependency-property-reference"
        },
        "recommendation": "Property path is correctly formatted for the step type"
      },
      {
        "severity": "INFO",
        "category": "property_path_validation",
        "message": "Valid property path in output calibrated_data: properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
        "details": {
          "contract": "model_calibration_contract",
          "logical_name": "calibrated_data",
          "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
          "step_type": "processing",
          "validation_source": "SageMaker Documentation v2.92.2",
          "documentation_reference": "https://sagemaker.readthedocs.io/en/v2.92.2/amazon_sagemaker_model_building_pipeline.html#data-dependency-property-reference"
        },
        "recommendation": "Property path is correctly formatted for the step type"
      },
      {
        "severity": "INFO",
        "category": "property_path_validation_summary",
        "message": "Property path validation completed for model_calibration_contract",
        "details": {
          "contract": "model_calibration_contract",
          "step_type": "processing",
          "node_type": "internal",
          "total_outputs": 3,
          "outputs_with_property_paths": 3,
          "validation_reference": "https://sagemaker.readthedocs.io/en/v2.92.2/amazon_sagemaker_model_building_pipeline.html#data-dependency-property-reference",
          "documentation_version": "v2.92.2"
        },
        "recommendation": "Validated 3/3 outputs with property paths against SageMaker documentation"
      }
    ],
    "contract": {
      "entry_point": "model_calibration.py",
      "inputs": {
        "evaluation_data": {
          "path": "/opt/ml/processing/input/eval_data"
        }
      },
      "outputs": {
        "calibration_output": {
          "path": "/opt/ml/processing/output/calibration"
        },
        "metrics_output": {
          "path": "/opt/ml/processing/output/metrics"
        },
        "calibrated_data": {
          "path": "/opt/ml/processing/output/calibrated_data"
        }
      },
      "arguments": {},
      "environment_variables": {
        "required": [
          "CALIBRATION_METHOD",
          "LABEL_FIELD",
          "SCORE_FIELD",
          "IS_BINARY"
        ],
        "optional": {
          "MONOTONIC_CONSTRAINT": "True",
          "GAM_SPLINES": "10",
          "ERROR_THRESHOLD": "0.05",
          "NUM_CLASSES": "2",
          "SCORE_FIELD_PREFIX": "prob_class_",
          "MULTICLASS_CATEGORIES": "[0, 1]"
        }
      },
      "description": "Contract for model calibration processing step.\n    \n    The model calibration step takes a trained model's raw prediction scores and\n    calibrates them to better reflect true probabilities, which is essential for\n    risk-based decision-making, threshold setting, and confidence in model outputs.\n    Supports both binary and multi-class classification scenarios.\n    \n    Input Structure:\n    - /opt/ml/processing/input/eval_data: Evaluation dataset with ground truth labels and model predictions\n    \n    Output Structure:\n    - /opt/ml/processing/output/calibration: Calibration mapping and artifacts\n    - /opt/ml/processing/output/metrics: Calibration quality metrics\n    - /opt/ml/processing/output/calibrated_data: Dataset with calibrated probabilities\n    \n    Environment Variables:\n    - CALIBRATION_METHOD: Method to use for calibration (gam, isotonic, platt)\n    - LABEL_FIELD: Name of the label column\n    - SCORE_FIELD: Name of the prediction score column (for binary classification)\n    - IS_BINARY: Whether this is a binary classification task (true/false)\n    - MONOTONIC_CONSTRAINT: Whether to enforce monotonicity in GAM (optional)\n    - GAM_SPLINES: Number of splines for GAM (optional)\n    - ERROR_THRESHOLD: Acceptable calibration error threshold (optional)\n    - NUM_CLASSES: Number of classes for multi-class classification (optional, default=2)\n    - SCORE_FIELD_PREFIX: Prefix for probability columns in multi-class scenario (optional)\n    - MULTICLASS_CATEGORIES: JSON string of class names/values for multi-class (optional)\n    ",
      "framework_requirements": {
        "scikit-learn": ">=0.23.2,<1.0.0",
        "pandas": ">=1.2.0,<2.0.0",
        "numpy": ">=1.20.0",
        "pygam": ">=0.8.0",
        "matplotlib": ">=3.3.0"
      }
    },
    "specifications": {
      "model_calibration_training_spec": {
        "step_type": "ModelCalibration_Training",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "evaluation_data",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "CrossValidation",
              "ModelEvaluation",
              "XGBoostTraining",
              "XGBoostModelEval",
              "PytorchTraining",
              "TrainingEvaluation"
            ],
            "data_type": "S3Uri",
            "description": "Training evaluation dataset with ground truth labels and model predictions"
          }
        ],
        "outputs": [
          {
            "logical_name": "calibration_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Training calibration mapping and artifacts"
          },
          {
            "logical_name": "metrics_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Training calibration quality metrics and visualizations"
          },
          {
            "logical_name": "calibrated_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Training dataset with calibrated probabilities"
          }
        ]
      },
      "model_calibration_spec": {
        "step_type": "ModelCalibration",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "evaluation_data",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "CrossValidation",
              "ModelEvaluation",
              "XGBoostTraining",
              "XGBoostModelEval",
              "TrainingEvaluation"
            ],
            "data_type": "S3Uri",
            "description": "Evaluation dataset with ground truth labels and model predictions"
          }
        ],
        "outputs": [
          {
            "logical_name": "calibration_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Calibration mapping and artifacts"
          },
          {
            "logical_name": "metrics_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Calibration quality metrics and visualizations"
          },
          {
            "logical_name": "calibrated_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Dataset with calibrated probabilities"
          }
        ]
      },
      "model_calibration_validation_spec": {
        "step_type": "ModelCalibration_Validation",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "evaluation_data",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "CrossValidation",
              "ModelEvaluation",
              "XGBoostTraining",
              "XGBoostModelEval",
              "PytorchTraining",
              "TrainingEvaluation"
            ],
            "data_type": "S3Uri",
            "description": "Validation evaluation dataset with ground truth labels and model predictions"
          }
        ],
        "outputs": [
          {
            "logical_name": "calibration_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Validation calibration mapping and artifacts"
          },
          {
            "logical_name": "metrics_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Validation calibration quality metrics and visualizations"
          },
          {
            "logical_name": "calibrated_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Validation dataset with calibrated probabilities"
          }
        ]
      },
      "model_calibration_calibration_spec": {
        "step_type": "ModelCalibration_Calibration",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "evaluation_data",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "CrossValidation",
              "ModelEvaluation",
              "XGBoostTraining",
              "XGBoostModelEval",
              "PytorchTraining",
              "TrainingEvaluation"
            ],
            "data_type": "S3Uri",
            "description": "Calibration evaluation dataset with ground truth labels and model predictions"
          }
        ],
        "outputs": [
          {
            "logical_name": "calibration_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Calibration mapping and artifacts"
          },
          {
            "logical_name": "metrics_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Calibration quality metrics and visualizations"
          },
          {
            "logical_name": "calibrated_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Calibration dataset with calibrated probabilities"
          }
        ]
      },
      "model_calibration_testing_spec": {
        "step_type": "ModelCalibration_Testing",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "evaluation_data",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "CrossValidation",
              "ModelEvaluation",
              "XGBoostTraining",
              "XGBoostModelEval",
              "PytorchTraining",
              "TrainingEvaluation"
            ],
            "data_type": "S3Uri",
            "description": "Testing evaluation dataset with ground truth labels and model predictions"
          }
        ],
        "outputs": [
          {
            "logical_name": "calibration_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Testing calibration mapping and artifacts"
          },
          {
            "logical_name": "metrics_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Testing calibration quality metrics and visualizations"
          },
          {
            "logical_name": "calibrated_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Testing dataset with calibrated probabilities"
          }
        ]
      }
    },
    "unified_specification": {
      "primary_spec": {
        "step_type": "ModelCalibration_Training",
        "node_type": "internal",
        "dependencies": [
          {
            "logical_name": "evaluation_data",
            "dependency_type": "processing_output",
            "required": true,
            "compatible_sources": [
              "CrossValidation",
              "ModelEvaluation",
              "XGBoostTraining",
              "XGBoostModelEval",
              "PytorchTraining",
              "TrainingEvaluation"
            ],
            "data_type": "S3Uri",
            "description": "Training evaluation dataset with ground truth labels and model predictions"
          }
        ],
        "outputs": [
          {
            "logical_name": "calibration_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Training calibration mapping and artifacts"
          },
          {
            "logical_name": "metrics_output",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Training calibration quality metrics and visualizations"
          },
          {
            "logical_name": "calibrated_data",
            "output_type": "processing_output",
            "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
            "data_type": "S3Uri",
            "description": "Training dataset with calibrated probabilities"
          }
        ]
      },
      "variants": {
        "training": {
          "step_type": "ModelCalibration_Training",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "evaluation_data",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "CrossValidation",
                "ModelEvaluation",
                "XGBoostTraining",
                "XGBoostModelEval",
                "PytorchTraining",
                "TrainingEvaluation"
              ],
              "data_type": "S3Uri",
              "description": "Training evaluation dataset with ground truth labels and model predictions"
            }
          ],
          "outputs": [
            {
              "logical_name": "calibration_output",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Training calibration mapping and artifacts"
            },
            {
              "logical_name": "metrics_output",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Training calibration quality metrics and visualizations"
            },
            {
              "logical_name": "calibrated_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Training dataset with calibrated probabilities"
            }
          ]
        },
        "testing": {
          "step_type": "ModelCalibration_Testing",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "evaluation_data",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "CrossValidation",
                "ModelEvaluation",
                "XGBoostTraining",
                "XGBoostModelEval",
                "PytorchTraining",
                "TrainingEvaluation"
              ],
              "data_type": "S3Uri",
              "description": "Testing evaluation dataset with ground truth labels and model predictions"
            }
          ],
          "outputs": [
            {
              "logical_name": "calibration_output",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Testing calibration mapping and artifacts"
            },
            {
              "logical_name": "metrics_output",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Testing calibration quality metrics and visualizations"
            },
            {
              "logical_name": "calibrated_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Testing dataset with calibrated probabilities"
            }
          ]
        },
        "validation": {
          "step_type": "ModelCalibration_Validation",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "evaluation_data",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "CrossValidation",
                "ModelEvaluation",
                "XGBoostTraining",
                "XGBoostModelEval",
                "PytorchTraining",
                "TrainingEvaluation"
              ],
              "data_type": "S3Uri",
              "description": "Validation evaluation dataset with ground truth labels and model predictions"
            }
          ],
          "outputs": [
            {
              "logical_name": "calibration_output",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Validation calibration mapping and artifacts"
            },
            {
              "logical_name": "metrics_output",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Validation calibration quality metrics and visualizations"
            },
            {
              "logical_name": "calibrated_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Validation dataset with calibrated probabilities"
            }
          ]
        },
        "calibration": {
          "step_type": "ModelCalibration_Calibration",
          "node_type": "internal",
          "dependencies": [
            {
              "logical_name": "evaluation_data",
              "dependency_type": "processing_output",
              "required": true,
              "compatible_sources": [
                "CrossValidation",
                "ModelEvaluation",
                "XGBoostTraining",
                "XGBoostModelEval",
                "PytorchTraining",
                "TrainingEvaluation"
              ],
              "data_type": "S3Uri",
              "description": "Calibration evaluation dataset with ground truth labels and model predictions"
            }
          ],
          "outputs": [
            {
              "logical_name": "calibration_output",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Calibration mapping and artifacts"
            },
            {
              "logical_name": "metrics_output",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Calibration quality metrics and visualizations"
            },
            {
              "logical_name": "calibrated_data",
              "output_type": "processing_output",
              "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
              "data_type": "S3Uri",
              "description": "Calibration dataset with calibrated probabilities"
            }
          ]
        }
      },
      "unified_dependencies": {
        "evaluation_data": {
          "logical_name": "evaluation_data",
          "dependency_type": "processing_output",
          "required": true,
          "compatible_sources": [
            "CrossValidation",
            "ModelEvaluation",
            "XGBoostTraining",
            "XGBoostModelEval",
            "PytorchTraining",
            "TrainingEvaluation"
          ],
          "data_type": "S3Uri",
          "description": "Calibration evaluation dataset with ground truth labels and model predictions"
        }
      },
      "unified_outputs": {
        "calibration_output": {
          "logical_name": "calibration_output",
          "output_type": "processing_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "Calibration mapping and artifacts"
        },
        "metrics_output": {
          "logical_name": "metrics_output",
          "output_type": "processing_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "Calibration quality metrics and visualizations"
        },
        "calibrated_data": {
          "logical_name": "calibrated_data",
          "output_type": "processing_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "Calibration dataset with calibrated probabilities"
        }
      },
      "dependency_sources": {
        "evaluation_data": [
          "training",
          "testing",
          "validation",
          "calibration"
        ]
      },
      "output_sources": {
        "calibration_output": [
          "training",
          "testing",
          "validation",
          "calibration"
        ],
        "metrics_output": [
          "training",
          "testing",
          "validation",
          "calibration"
        ],
        "calibrated_data": [
          "training",
          "testing",
          "validation",
          "calibration"
        ]
      },
      "variant_count": 4
    }
  },
  "level3": {
    "passed": true,
    "issues": [],
    "specification": {
      "step_type": "ModelCalibration_Calibration",
      "node_type": "internal",
      "dependencies": [
        {
          "logical_name": "evaluation_data",
          "dependency_type": "processing_output",
          "required": true,
          "compatible_sources": [
            "CrossValidation",
            "ModelEvaluation",
            "XGBoostTraining",
            "XGBoostModelEval",
            "PytorchTraining",
            "TrainingEvaluation"
          ],
          "data_type": "S3Uri",
          "description": "Calibration evaluation dataset with ground truth labels and model predictions"
        }
      ],
      "outputs": [
        {
          "logical_name": "calibration_output",
          "output_type": "processing_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['calibration_output'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "Calibration mapping and artifacts"
        },
        {
          "logical_name": "metrics_output",
          "output_type": "processing_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['metrics_output'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "Calibration quality metrics and visualizations"
        },
        {
          "logical_name": "calibrated_data",
          "output_type": "processing_output",
          "property_path": "properties.ProcessingOutputConfig.Outputs['calibrated_data'].S3Output.S3Uri",
          "data_type": "S3Uri",
          "description": "Calibration dataset with calibrated probabilities"
        }
      ]
    }
  },
  "level4": {
    "passed": true,
    "issues": [
      {
        "severity": "WARNING",
        "category": "configuration_fields",
        "message": "Required configuration field not accessed in builder: project_root_folder",
        "details": {
          "field_name": "project_root_folder",
          "builder": "model_calibration"
        },
        "recommendation": "Access required field project_root_folder in builder or make it optional"
      },
      {
        "severity": "INFO",
        "category": "required_field_validation",
        "message": "Builder has required fields but no explicit validation logic detected",
        "details": {
          "required_fields": [
            "service_name",
            "bucket",
            "role",
            "project_root_folder",
            "author",
            "pipeline_version",
            "region",
            "label_field"
          ],
          "builder": "model_calibration"
        },
        "recommendation": "Consider adding explicit validation logic for required configuration fields"
      }
    ],
    "builder_analysis": {
      "config_accesses": [
        {
          "field_name": "job_type",
          "line_number": 82,
          "context": "line_82"
        },
        {
          "field_name": "calibration_method",
          "line_number": 158,
          "context": "line_158"
        },
        {
          "field_name": "calibration_method",
          "line_number": 160,
          "context": "line_160"
        },
        {
          "field_name": "job_type",
          "line_number": 166,
          "context": "line_166"
        },
        {
          "field_name": "job_type",
          "line_number": 167,
          "context": "line_167"
        },
        {
          "field_name": "gam_splines",
          "line_number": 170,
          "context": "line_170"
        },
        {
          "field_name": "gam_splines",
          "line_number": 171,
          "context": "line_171"
        },
        {
          "field_name": "error_threshold",
          "line_number": 173,
          "context": "line_173"
        },
        {
          "field_name": "error_threshold",
          "line_number": 175,
          "context": "line_175"
        },
        {
          "field_name": "calibration_method",
          "line_number": 246,
          "context": "line_246"
        },
        {
          "field_name": "label_field",
          "line_number": 247,
          "context": "line_247"
        },
        {
          "field_name": "score_field",
          "line_number": 248,
          "context": "line_248"
        },
        {
          "field_name": "monotonic_constraint",
          "line_number": 249,
          "context": "line_249"
        },
        {
          "field_name": "gam_splines",
          "line_number": 250,
          "context": "line_250"
        },
        {
          "field_name": "error_threshold",
          "line_number": 251,
          "context": "line_251"
        },
        {
          "field_name": "is_binary",
          "line_number": 253,
          "context": "line_253"
        },
        {
          "field_name": "num_classes",
          "line_number": 254,
          "context": "line_254"
        },
        {
          "field_name": "score_field_prefix",
          "line_number": 255,
          "context": "line_255"
        },
        {
          "field_name": "is_binary",
          "line_number": 260,
          "context": "line_260"
        },
        {
          "field_name": "multiclass_categories",
          "line_number": 260,
          "context": "line_260"
        },
        {
          "field_name": "multiclass_categories",
          "line_number": 264,
          "context": "line_264"
        },
        {
          "field_name": "job_type",
          "line_number": 374,
          "context": "line_374"
        },
        {
          "field_name": "use_large_processing_instance",
          "line_number": 400,
          "context": "line_400"
        },
        {
          "field_name": "processing_instance_type_large",
          "line_number": 399,
          "context": "line_399"
        },
        {
          "field_name": "processing_instance_type_small",
          "line_number": 401,
          "context": "line_401"
        },
        {
          "field_name": "processing_instance_count",
          "line_number": 413,
          "context": "line_413"
        },
        {
          "field_name": "processing_volume_size",
          "line_number": 414,
          "context": "line_414"
        },
        {
          "field_name": "job_type",
          "line_number": 430,
          "context": "line_430"
        }
      ],
      "validation_calls": [],
      "default_assignments": [],
      "class_definitions": [
        {
          "class_name": "ModelCalibrationStepBuilder",
          "line_number": 43,
          "base_classes": [
            "StepBuilderBase"
          ],
          "decorators": []
        }
      ],
      "method_definitions": [
        {
          "method_name": "__init__",
          "line_number": 52,
          "args": [
            "self",
            "config",
            "sagemaker_session",
            "role",
            "registry_manager",
            "dependency_resolver"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "validate_configuration",
          "line_number": 123,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_is_pipeline_variable",
          "line_number": 180,
          "args": [
            "self",
            "value"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_detect_circular_references",
          "line_number": 194,
          "args": [
            "self",
            "var",
            "visited"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_environment_variables",
          "line_number": 232,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_inputs",
          "line_number": 269,
          "args": [
            "self",
            "inputs"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_outputs",
          "line_number": 329,
          "args": [
            "self",
            "outputs"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_processor",
          "line_number": 391,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "_get_job_arguments",
          "line_number": 420,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        },
        {
          "method_name": "create_step",
          "line_number": 436,
          "args": [
            "self"
          ],
          "decorators": [],
          "is_async": false
        }
      ],
      "import_statements": [
        {
          "type": "import",
          "module": "logging",
          "alias": null,
          "line_number": 9
        },
        {
          "type": "import",
          "module": "importlib",
          "alias": null,
          "line_number": 10
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "Dict",
          "alias": null,
          "line_number": 11
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "List",
          "alias": null,
          "line_number": 11
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "Any",
          "alias": null,
          "line_number": 11
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "Optional",
          "alias": null,
          "line_number": 11
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "Union",
          "alias": null,
          "line_number": 11
        },
        {
          "type": "from_import",
          "module": "typing",
          "name": "Set",
          "alias": null,
          "line_number": 11
        },
        {
          "type": "from_import",
          "module": "pathlib",
          "name": "Path",
          "alias": null,
          "line_number": 12
        },
        {
          "type": "from_import",
          "module": "sagemaker.processing",
          "name": "ProcessingInput",
          "alias": null,
          "line_number": 14
        },
        {
          "type": "from_import",
          "module": "sagemaker.processing",
          "name": "ProcessingOutput",
          "alias": null,
          "line_number": 14
        },
        {
          "type": "from_import",
          "module": "sagemaker.sklearn",
          "name": "SKLearnProcessor",
          "alias": null,
          "line_number": 15
        },
        {
          "type": "from_import",
          "module": "sagemaker.workflow.steps",
          "name": "ProcessingStep",
          "alias": null,
          "line_number": 16
        },
        {
          "type": "from_import",
          "module": "sagemaker.workflow.entities",
          "name": "PipelineVariable",
          "alias": null,
          "line_number": 17
        },
        {
          "type": "from_import",
          "module": "core.base.builder_base",
          "name": "StepBuilderBase",
          "alias": null,
          "line_number": 19
        },
        {
          "type": "from_import",
          "module": "configs.config_model_calibration_step",
          "name": "ModelCalibrationConfig",
          "alias": null,
          "line_number": 20
        },
        {
          "type": "from_import",
          "module": "specs.model_calibration_training_spec",
          "name": "MODEL_CALIBRATION_TRAINING_SPEC",
          "alias": null,
          "line_number": 24
        },
        {
          "type": "from_import",
          "module": "specs.model_calibration_calibration_spec",
          "name": "MODEL_CALIBRATION_CALIBRATION_SPEC",
          "alias": null,
          "line_number": 25
        },
        {
          "type": "from_import",
          "module": "specs.model_calibration_validation_spec",
          "name": "MODEL_CALIBRATION_VALIDATION_SPEC",
          "alias": null,
          "line_number": 28
        },
        {
          "type": "from_import",
          "module": "specs.model_calibration_testing_spec",
          "name": "MODEL_CALIBRATION_TESTING_SPEC",
          "alias": null,
          "line_number": 31
        },
        {
          "type": "import",
          "module": "json",
          "alias": null,
          "line_number": 261
        },
        {
          "type": "from_import",
          "module": "sagemaker.workflow.functions",
          "name": "Join",
          "alias": null,
          "line_number": 372
        }
      ],
      "config_class_usage": []
    },
    "config_analysis": {
      "class_name": "ModelCalibrationConfig",
      "fields": {
        "author": {
          "type": "<class 'str'>",
          "required": true
        },
        "bucket": {
          "type": "<class 'str'>",
          "required": true
        },
        "role": {
          "type": "<class 'str'>",
          "required": true
        },
        "region": {
          "type": "<class 'str'>",
          "required": true
        },
        "service_name": {
          "type": "<class 'str'>",
          "required": true
        },
        "pipeline_version": {
          "type": "<class 'str'>",
          "required": true
        },
        "model_class": {
          "type": "<class 'str'>",
          "required": false
        },
        "current_date": {
          "type": "<class 'str'>",
          "required": false
        },
        "framework_version": {
          "type": "<class 'str'>",
          "required": false
        },
        "py_version": {
          "type": "<class 'str'>",
          "required": false
        },
        "source_dir": {
          "type": "typing.Optional[str]",
          "required": false
        },
        "project_root_folder": {
          "type": "<class 'str'>",
          "required": true
        },
        "processing_instance_count": {
          "type": "<class 'int'>",
          "required": false
        },
        "processing_volume_size": {
          "type": "<class 'int'>",
          "required": false
        },
        "processing_instance_type_large": {
          "type": "<class 'str'>",
          "required": false
        },
        "processing_instance_type_small": {
          "type": "<class 'str'>",
          "required": false
        },
        "use_large_processing_instance": {
          "type": "<class 'bool'>",
          "required": false
        },
        "processing_source_dir": {
          "type": "<class 'str'>",
          "required": false
        },
        "processing_entry_point": {
          "type": "<class 'str'>",
          "required": false
        },
        "processing_script_arguments": {
          "type": "typing.Optional[typing.List[str]]",
          "required": false
        },
        "processing_framework_version": {
          "type": "<class 'str'>",
          "required": false
        },
        "label_field": {
          "type": "<class 'str'>",
          "required": true
        },
        "calibration_method": {
          "type": "<class 'str'>",
          "required": false
        },
        "monotonic_constraint": {
          "type": "<class 'bool'>",
          "required": false
        },
        "gam_splines": {
          "type": "<class 'int'>",
          "required": false
        },
        "error_threshold": {
          "type": "<class 'float'>",
          "required": false
        },
        "is_binary": {
          "type": "<class 'bool'>",
          "required": false
        },
        "num_classes": {
          "type": "<class 'int'>",
          "required": false
        },
        "score_field": {
          "type": "<class 'str'>",
          "required": false
        },
        "score_field_prefix": {
          "type": "<class 'str'>",
          "required": false
        },
        "multiclass_categories": {
          "type": "typing.List[typing.Union[str, int]]",
          "required": false
        },
        "job_type": {
          "type": "<class 'str'>",
          "required": false
        },
        "aws_region": {
          "type": "property",
          "required": false
        },
        "effective_instance_type": {
          "type": "property",
          "required": false
        },
        "effective_source_dir": {
          "type": "property",
          "required": false
        },
        "model_extra": {
          "type": "property",
          "required": false
        },
        "model_fields_set": {
          "type": "property",
          "required": false
        },
        "pipeline_description": {
          "type": "property",
          "required": false
        },
        "pipeline_name": {
          "type": "property",
          "required": false
        },
        "pipeline_s3_loc": {
          "type": "property",
          "required": false
        },
        "resolved_processing_source_dir": {
          "type": "property",
          "required": false
        },
        "resolved_source_dir": {
          "type": "property",
          "required": false
        },
        "script_contract": {
          "type": "property",
          "required": false
        },
        "script_path": {
          "type": "property",
          "required": false
        },
        "step_catalog": {
          "type": "property",
          "required": false
        }
      },
      "required_fields": [
        "author",
        "bucket",
        "role",
        "region",
        "service_name",
        "pipeline_version",
        "project_root_folder",
        "label_field"
      ],
      "optional_fields": [
        "model_class",
        "current_date",
        "framework_version",
        "py_version",
        "source_dir",
        "processing_instance_count",
        "processing_volume_size",
        "processing_instance_type_large",
        "processing_instance_type_small",
        "use_large_processing_instance",
        "processing_source_dir",
        "processing_entry_point",
        "processing_script_arguments",
        "processing_framework_version",
        "calibration_method",
        "monotonic_constraint",
        "gam_splines",
        "error_threshold",
        "is_binary",
        "num_classes",
        "score_field",
        "score_field_prefix",
        "multiclass_categories",
        "job_type",
        "aws_region",
        "effective_instance_type",
        "effective_source_dir",
        "model_extra",
        "model_fields_set",
        "pipeline_description",
        "pipeline_name",
        "pipeline_s3_loc",
        "resolved_processing_source_dir",
        "resolved_source_dir",
        "script_contract",
        "script_path",
        "step_catalog"
      ],
      "default_values": {
        "author": "PydanticUndefined",
        "bucket": "PydanticUndefined",
        "role": "PydanticUndefined",
        "region": "PydanticUndefined",
        "service_name": "PydanticUndefined",
        "pipeline_version": "PydanticUndefined",
        "model_class": "xgboost",
        "current_date": "PydanticUndefined",
        "framework_version": "2.1.0",
        "py_version": "py310",
        "source_dir": null,
        "project_root_folder": "PydanticUndefined",
        "processing_instance_count": 1,
        "processing_volume_size": 500,
        "processing_instance_type_large": "ml.m5.4xlarge",
        "processing_instance_type_small": "ml.m5.2xlarge",
        "use_large_processing_instance": false,
        "processing_source_dir": "dockers/xgboost_atoz/scripts",
        "processing_entry_point": "model_calibration.py",
        "processing_script_arguments": null,
        "processing_framework_version": "1.2-1",
        "label_field": "PydanticUndefined",
        "calibration_method": "gam",
        "monotonic_constraint": true,
        "gam_splines": 10,
        "error_threshold": 0.05,
        "is_binary": true,
        "num_classes": 2,
        "score_field": "prob_class_1",
        "score_field_prefix": "prob_class_",
        "multiclass_categories": "PydanticUndefined",
        "job_type": "calibration"
      }
    }
  },
  "overall_status": "PASSING",
  "scoring": {
    "overall_score": 100.0,
    "quality_rating": "Excellent",
    "level_scores": {
      "level1_script_contract": 100.0,
      "level2_contract_spec": 100.0,
      "level3_spec_dependencies": 100.0,
      "level4_builder_config": 100.0
    }
  },
  "metadata": {
    "script_path": "/Users/tianpeixie/github_workspace/cursus/src/cursus/steps/scripts/model_calibration.py",
    "validation_timestamp": "2025-09-28T11:08:48.764552",
    "validator_version": "1.0.0"
  }
}
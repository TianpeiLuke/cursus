{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Pipeline Test - Pipeline Configuration\n",
    "\n",
    "This notebook handles the pipeline definition and configuration setup for the XGBoost 3-step pipeline test.\n",
    "\n",
    "**Pipeline Steps:**\n",
    "1. XGBoost Training → 2. XGBoost Model Evaluation → 3. Model Calibration\n",
    "\n",
    "**This notebook covers:**\n",
    "- Pipeline definition (steps and edges)\n",
    "- Step configuration generation\n",
    "- Workspace setup validation\n",
    "- Configuration file creation and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add cursus to path\n",
    "sys.path.append(str(Path.cwd().parent.parent.parent / 'src'))\n",
    "\n",
    "# Import Cursus components\n",
    "try:\n",
    "    from cursus.steps.registry.step_names import STEP_NAMES\n",
    "    print(\"✓ Successfully imported Cursus step registry\")\n",
    "    cursus_available = True\n",
    "except ImportError as e:\n",
    "    print(f\"⚠ Import error: {e}\")\n",
    "    print(\"Using mock step names for testing...\")\n",
    "    cursus_available = False\n",
    "\n",
    "print(f\"Configuration setup started at {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Directory Structure Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory structure (should match 01_setup_and_data_preparation.ipynb)\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "CONFIG_DIR = BASE_DIR / 'configs'\n",
    "OUTPUTS_DIR = BASE_DIR / 'outputs'\n",
    "WORKSPACE_DIR = OUTPUTS_DIR / 'workspace'\n",
    "LOGS_DIR = OUTPUTS_DIR / 'logs'\n",
    "RESULTS_DIR = OUTPUTS_DIR / 'results'\n",
    "\n",
    "# Validate directories exist\n",
    "directories = [DATA_DIR, CONFIG_DIR, OUTPUTS_DIR, WORKSPACE_DIR, LOGS_DIR, RESULTS_DIR]\n",
    "missing_dirs = []\n",
    "\n",
    "for directory in directories:\n",
    "    if directory.exists():\n",
    "        print(f\"✓ Directory exists: {directory}\")\n",
    "    else:\n",
    "        print(f\"⚠ Directory missing: {directory}\")\n",
    "        directory.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"✓ Created directory: {directory}\")\n",
    "\n",
    "# Check for data files\n",
    "train_data_path = DATA_DIR / 'train_data.csv'\n",
    "eval_data_path = DATA_DIR / 'eval_data.csv'\n",
    "metadata_path = DATA_DIR / 'dataset_metadata.json'\n",
    "\n",
    "data_files = [train_data_path, eval_data_path, metadata_path]\n",
    "for data_file in data_files:\n",
    "    if data_file.exists():\n",
    "        print(f\"✓ Data file exists: {data_file}\")\n",
    "    else:\n",
    "        print(f\"⚠ Data file missing: {data_file}\")\n",
    "        print(\"Please run 01_setup_and_data_preparation.ipynb first!\")\n",
    "\n",
    "print(\"\\nDirectory validation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 3-step XGBoost pipeline\n",
    "PIPELINE_STEPS = [\n",
    "    'XGBoostTraining',\n",
    "    'XGBoostModelEval', \n",
    "    'ModelCalibration'\n",
    "]\n",
    "\n",
    "# Define pipeline edges (dependencies)\n",
    "PIPELINE_EDGES = [\n",
    "    ('XGBoostTraining', 'XGBoostModelEval'),\n",
    "    ('XGBoostModelEval', 'ModelCalibration')\n",
    "]\n",
    "\n",
    "# Pipeline metadata\n",
    "PIPELINE_METADATA = {\n",
    "    'name': 'XGBoost_3_Step_Pipeline',\n",
    "    'description': 'End-to-end XGBoost pipeline with training, evaluation, and calibration',\n",
    "    'version': '1.0.0',\n",
    "    'steps': PIPELINE_STEPS,\n",
    "    'edges': PIPELINE_EDGES,\n",
    "    'created_at': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "print(\"PIPELINE DEFINITION\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Pipeline Name: {PIPELINE_METADATA['name']}\")\n",
    "print(f\"Steps: {len(PIPELINE_STEPS)}\")\n",
    "print(f\"Edges: {len(PIPELINE_EDGES)}\")\n",
    "print(\"\\nPipeline Flow:\")\n",
    "for i, step in enumerate(PIPELINE_STEPS):\n",
    "    if i == 0:\n",
    "        print(f\"  {step}\")\n",
    "    else:\n",
    "        print(f\"    ↓\")\n",
    "        print(f\"  {step}\")\n",
    "\n",
    "print(\"\\nPipeline edges:\")\n",
    "for source, target in PIPELINE_EDGES:\n",
    "    print(f\"  {source} → {target}\")\n",
    "\n",
    "# Save pipeline definition\n",
    "pipeline_def_path = CONFIG_DIR / 'pipeline_definition.json'\n",
    "with open(pipeline_def_path, 'w') as f:\n",
    "    json.dump(PIPELINE_METADATA, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Pipeline definition saved: {pipeline_def_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step Configuration Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_step_configurations():\n",
    "    \"\"\"\n",
    "    Create configuration files for each pipeline step.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of step configurations\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"CREATING STEP CONFIGURATIONS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # XGBoost Training Configuration\n",
    "    xgboost_training_config = {\n",
    "        \"step_name\": \"XGBoostTraining\",\n",
    "        \"step_type\": \"training\",\n",
    "        \"description\": \"Train XGBoost model on synthetic dataset\",\n",
    "        \"input_data_path\": str(DATA_DIR / 'train_data.csv'),\n",
    "        \"output_model_path\": str(WORKSPACE_DIR / 'xgboost_model.pkl'),\n",
    "        \"output_model_metadata_path\": str(WORKSPACE_DIR / 'xgboost_model_metadata.json'),\n",
    "        \"hyperparameters\": {\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_depth\": 6,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"random_state\": 42,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"logloss\"\n",
    "        },\n",
    "        \"target_column\": \"target\",\n",
    "        \"feature_columns\": [f\"feature_{i}\" for i in range(10)],\n",
    "        \"validation_split\": 0.2,\n",
    "        \"early_stopping_rounds\": 10\n",
    "    }\n",
    "    \n",
    "    # XGBoost Model Evaluation Configuration\n",
    "    xgboost_eval_config = {\n",
    "        \"step_name\": \"XGBoostModelEval\",\n",
    "        \"step_type\": \"evaluation\",\n",
    "        \"description\": \"Evaluate trained XGBoost model on evaluation dataset\",\n",
    "        \"model_path\": str(WORKSPACE_DIR / 'xgboost_model.pkl'),\n",
    "        \"model_metadata_path\": str(WORKSPACE_DIR / 'xgboost_model_metadata.json'),\n",
    "        \"eval_data_path\": str(DATA_DIR / 'eval_data.csv'),\n",
    "        \"output_predictions_path\": str(WORKSPACE_DIR / 'predictions.csv'),\n",
    "        \"output_metrics_path\": str(WORKSPACE_DIR / 'eval_metrics.json'),\n",
    "        \"output_plots_dir\": str(WORKSPACE_DIR / 'evaluation_plots'),\n",
    "        \"target_column\": \"target\",\n",
    "        \"feature_columns\": [f\"feature_{i}\" for i in range(10)],\n",
    "        \"metrics_to_compute\": [\n",
    "            \"accuracy\", \"precision\", \"recall\", \"f1_score\", \n",
    "            \"auc_roc\", \"auc_pr\", \"log_loss\"\n",
    "        ],\n",
    "        \"probability_threshold\": 0.5,\n",
    "        \"generate_plots\": True\n",
    "    }\n",
    "    \n",
    "    # Model Calibration Configuration\n",
    "    calibration_config = {\n",
    "        \"step_name\": \"ModelCalibration\",\n",
    "        \"step_type\": \"calibration\",\n",
    "        \"description\": \"Calibrate model predictions using isotonic regression\",\n",
    "        \"predictions_path\": str(WORKSPACE_DIR / 'predictions.csv'),\n",
    "        \"eval_data_path\": str(DATA_DIR / 'eval_data.csv'),\n",
    "        \"output_calibrated_model_path\": str(WORKSPACE_DIR / 'calibrated_model.pkl'),\n",
    "        \"output_calibrated_predictions_path\": str(WORKSPACE_DIR / 'calibrated_predictions.csv'),\n",
    "        \"output_calibration_metrics_path\": str(WORKSPACE_DIR / 'calibration_metrics.json'),\n",
    "        \"output_calibration_plots_dir\": str(WORKSPACE_DIR / 'calibration_plots'),\n",
    "        \"calibration_method\": \"isotonic\",\n",
    "        \"target_column\": \"target\",\n",
    "        \"cv_folds\": 3,\n",
    "        \"generate_plots\": True,\n",
    "        \"metrics_to_compute\": [\n",
    "            \"brier_score\", \"calibration_error\", \"reliability_diagram\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Collect all configurations\n",
    "    configs = {\n",
    "        'XGBoostTraining': xgboost_training_config,\n",
    "        'XGBoostModelEval': xgboost_eval_config,\n",
    "        'ModelCalibration': calibration_config\n",
    "    }\n",
    "    \n",
    "    # Save individual configuration files\n",
    "    for step_name, config in configs.items():\n",
    "        config_path = CONFIG_DIR / f'{step_name.lower()}_config.json'\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        print(f\"✓ Created config: {config_path}\")\n",
    "    \n",
    "    # Save combined configuration file\n",
    "    combined_config = {\n",
    "        'pipeline_metadata': PIPELINE_METADATA,\n",
    "        'step_configurations': configs,\n",
    "        'created_at': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    combined_config_path = CONFIG_DIR / 'pipeline_config.json'\n",
    "    with open(combined_config_path, 'w') as f:\n",
    "        json.dump(combined_config, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Created combined config: {combined_config_path}\")\n",
    "    \n",
    "    return configs\n",
    "\n",
    "# Create step configurations\n",
    "step_configs = create_step_configurations()\n",
    "print(\"\\nStep configurations created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configuration Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step_configuration(step_name, config):\n",
    "    \"\"\"\n",
    "    Validate a step configuration for completeness and correctness.\n",
    "    \n",
    "    Args:\n",
    "        step_name: Name of the step\n",
    "        config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_valid, validation_messages)\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    is_valid = True\n",
    "    \n",
    "    # Check required fields\n",
    "    required_fields = ['step_name', 'step_type', 'description']\n",
    "    for field in required_fields:\n",
    "        if field not in config:\n",
    "            messages.append(f\"Missing required field: {field}\")\n",
    "            is_valid = False\n",
    "        elif not config[field]:\n",
    "            messages.append(f\"Empty required field: {field}\")\n",
    "            is_valid = False\n",
    "    \n",
    "    # Check step-specific requirements\n",
    "    if step_name == 'XGBoostTraining':\n",
    "        training_required = ['input_data_path', 'output_model_path', 'hyperparameters', 'target_column']\n",
    "        for field in training_required:\n",
    "            if field not in config:\n",
    "                messages.append(f\"Training step missing: {field}\")\n",
    "                is_valid = False\n",
    "        \n",
    "        # Check if input data exists\n",
    "        if 'input_data_path' in config:\n",
    "            input_path = Path(config['input_data_path'])\n",
    "            if not input_path.exists():\n",
    "                messages.append(f\"Input data file not found: {input_path}\")\n",
    "                is_valid = False\n",
    "            else:\n",
    "                messages.append(f\"✓ Input data file exists: {input_path}\")\n",
    "    \n",
    "    elif step_name == 'XGBoostModelEval':\n",
    "        eval_required = ['model_path', 'eval_data_path', 'output_predictions_path', 'output_metrics_path']\n",
    "        for field in eval_required:\n",
    "            if field not in config:\n",
    "                messages.append(f\"Evaluation step missing: {field}\")\n",
    "                is_valid = False\n",
    "    \n",
    "    elif step_name == 'ModelCalibration':\n",
    "        calib_required = ['predictions_path', 'eval_data_path', 'output_calibrated_model_path', 'calibration_method']\n",
    "        for field in calib_required:\n",
    "            if field not in config:\n",
    "                messages.append(f\"Calibration step missing: {field}\")\n",
    "                is_valid = False\n",
    "    \n",
    "    return is_valid, messages\n",
    "\n",
    "# Validate all step configurations\n",
    "print(\"CONFIGURATION VALIDATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "all_valid = True\n",
    "for step_name, config in step_configs.items():\n",
    "    print(f\"\\nValidating {step_name}:\")\n",
    "    is_valid, messages = validate_step_configuration(step_name, config)\n",
    "    \n",
    "    if is_valid:\n",
    "        print(f\"  ✓ {step_name} configuration is valid\")\n",
    "    else:\n",
    "        print(f\"  ✗ {step_name} configuration has issues:\")\n",
    "        all_valid = False\n",
    "    \n",
    "    for message in messages:\n",
    "        if message.startswith('✓'):\n",
    "            print(f\"    {message}\")\n",
    "        else:\n",
    "            print(f\"    ⚠ {message}\")\n",
    "\n",
    "print(f\"\\n{'='*40}\")\n",
    "if all_valid:\n",
    "    print(\"✓ All step configurations are valid!\")\n",
    "else:\n",
    "    print(\"⚠ Some step configurations have issues. Please review and fix.\")\n",
    "\n",
    "print(\"\\nConfiguration validation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuration Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display configuration summary\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Pipeline: {PIPELINE_METADATA['name']}\")\n",
    "print(f\"Version: {PIPELINE_METADATA['version']}\")\n",
    "print(f\"Description: {PIPELINE_METADATA['description']}\")\n",
    "print(f\"Created: {PIPELINE_METADATA['created_at']}\")\n",
    "\n",
    "print(\"\\nStep Configurations:\")\n",
    "for step_name, config in step_configs.items():\n",
    "    print(f\"\\n  {step_name}:\")\n",
    "    print(f\"    Type: {config['step_type']}\")\n",
    "    print(f\"    Description: {config['description']}\")\n",
    "    \n",
    "    # Show key paths\n",
    "    if 'input_data_path' in config:\n",
    "        print(f\"    Input: {Path(config['input_data_path']).name}\")\n",
    "    if 'output_model_path' in config:\n",
    "        print(f\"    Output: {Path(config['output_model_path']).name}\")\n",
    "    if 'output_predictions_path' in config:\n",
    "        print(f\"    Output: {Path(config['output_predictions_path']).name}\")\n",
    "    if 'output_calibrated_model_path' in config:\n",
    "        print(f\"    Output: {Path(config['output_calibrated_model_path']).name}\")\n",
    "\n",
    "print(\"\\nConfiguration files created:\")\n",
    "config_files = list(CONFIG_DIR.glob('*.json'))\n",
    "for config_file in sorted(config_files):\n",
    "    print(f\"  ✓ {config_file.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PIPELINE CONFIGURATION COMPLETED\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Ready for individual step testing!\")\n",
    "print(\"Next: Run 03_individual_step_testing.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

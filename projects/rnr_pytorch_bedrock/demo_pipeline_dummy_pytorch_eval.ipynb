{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "299b07c0-e087-4bc8-8a81-46e3710c12fb",
   "metadata": {},
   "source": [
    "# Cursus: Automatic SageMaker (MODS) Pipeline Compiler\n",
    "\n",
    "The main contribution of this work is **Cursus**, a **compiler** that automatically generate **[MODS (Model Training Workflow Operation and Development System) Pipeline](https://w.amazon.com/bin/view/CMLS/Overview/MODS/)** base on two set of user inputs\n",
    "* The **Pipeline DAG (Directed Acylic Graph)**, which describe pipeline as a graph\n",
    "* The **Unified Config JSON**, which provides a central hub to extract all user inputs and their associated step information\n",
    "    * Run [demo_config](./demo_config.ipynb) first to generate the Unified Config JSON\n",
    "    * The config json will be saved in `./pipeling_config/xxx/` folder\n",
    "\n",
    "![mods_pipeline_train_eval_calib](./demo/mods_pipeline_train_eval_calib.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe50590-45a5-42e0-ba46-db3182c95c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefa46ee-5c6e-4376-b315-596daf503e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, model_validator, field_validator\n",
    "from typing import List, Optional, Dict, Any, Type, Union, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94496431-af1a-4689-888d-4e5dc62a2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import (\n",
    "    defaultdict,\n",
    "    deque\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92563607-e4f2-417f-9115-d8549711e7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0cb59bf-9f68-4b0c-b699-a48961d40f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109385d-fa21-4b1d-8b0c-52a0394f0b1e",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbf0cf9-05ca-4e17-9725-a02e1ac26975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:53,846 - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7aae78b-4ba8-4498-95b2-2049fea6f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f6efb08-ca57-43fe-9a92-ade36d21fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name='buyer-seller-messaging-reversal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3f0529-ee5d-468b-a891-e9c1c0075835",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:54,265 - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "pipeline_session = PipelineSession(default_bucket=bucket_name) # IMPORTANT now the session uses the generated sagemaker_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e9385d-eccd-46ec-9813-08997aaa0c43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:54,569 - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role=PipelineSession().get_caller_identity_arn()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6850b94d-eabe-4bcf-a509-37d67f17a538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add project root /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines into system\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Get parent directory of current notebook\n",
    "project_root = str(Path().absolute().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)  \n",
    "    print(f\"add project root {project_root} into system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9961bb-ae6a-45eb-9e12-5fb79b25f71c",
   "metadata": {},
   "source": [
    "## Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c50cd1-074c-47a5-acfe-5bbcf9500cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_list = [\n",
    "    'NA',\n",
    "    'EU',\n",
    "    'FE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9387ac-df3b-47c8-b869-6c748ed55cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_selection = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac12ddc2-68c8-4d10-ab58-b9285365515c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NA'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = region_list[region_selection]\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "151164f4-717a-4750-bebb-1d4e5406812d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_CLASS='pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e69d0db9-52a9-46e2-a090-0ff91670591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name=\"BuyerAbuseRnR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083c62dd-0e54-491a-b399-1ff7e3e8de42",
   "metadata": {},
   "source": [
    "#### Config and Hyperparameter Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "113f0787-3986-4bd9-a087-8c3ef3247fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config\n"
     ]
    }
   ],
   "source": [
    "current_dir = Path.cwd()\n",
    "config_dir = Path(current_dir) / 'pipeline_config'\n",
    "print(config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4038ad40-95c0-4858-8de4-24aa96a0a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyparam_filename = f'hyperparameters_{region}_{MODEL_CLASS}.json' #'hyperparameters.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c03bfe-a3b2-4c3c-bfac-ae097ef3ef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config.json'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config_name = f'config.json'  #f'config_{region}.json'\n",
    "pipeline_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41fe835b-937f-4f17-a71f-2d0deb0483ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = config_dir / pipeline_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf788034-e479-4cac-8274-98b33937569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa969016-7024-423f-9784-5c4145d276bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9282a90-2ed4-43fe-9725-2c3ec53b4f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00e1fa95-7379-4ab9-8d25-8f57654e5734",
   "metadata": {},
   "source": [
    "## Pipeline Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d32cbbf4-f448-42f4-a54b-56f7947f8c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02cf5a-e2d5-49af-8f55-aca2c4bec315",
   "metadata": {},
   "source": [
    "## [Optional]: Test Config Load Functionality\n",
    "\n",
    "Please skip this section if you are not concern about the config information loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79af0dc-1b46-4809-a0b2-8eb534e4d365",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee5eb858-99b6-4937-a3d7-265e53f95af8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from cursus.steps.hyperparams.hyperparameters_xgboost import XGBoostModelHyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26e2d72b-1a34-42ca-9aee-a8430d6b8706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hyparam_path = config_dir / hyparam_filename\n",
    "#with open(hyparam_path, 'r') as file:\n",
    "#    hyperparam_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3f00717-87c5-4270-85d4-f81c34f7deb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hyperparams = XGBoostModelHyperparameters(**hyperparam_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e74fb0c-7a5f-4792-8123-fa0142ff15ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hyperparams.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f57e6d2-3012-4746-90a3-9fd7c2559b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hyperparams.is_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23851f5a-be88-4aa8-a17e-95ca42f282ce",
   "metadata": {},
   "source": [
    "### Import Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07614f39-3683-42b1-baf0-dca78d21b6eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:55,253 - WARNING - Could not import constants from mods_workflow_core, using local definitions\n",
      "2025-11-30 06:22:55,494 - WARNING - CradleDataLoadingStepBuilder not available. This requires secure_ai_sandbox_workflow_python_sdk package. Import error: No module named 'secure_ai_sandbox_workflow_python_sdk'\n",
      "2025-11-30 06:22:55,532 - WARNING - RegistrationStepBuilder not available. This requires secure_ai_sandbox_workflow_python_sdk package. Import error: No module named 'secure_ai_sandbox_workflow_python_sdk'\n"
     ]
    }
   ],
   "source": [
    "from cursus.core.base.config_base import BasePipelineConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c507be6b-d6f4-42ff-99d3-3f5050589715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from cursus.steps.configs.config_cradle_data_loading_step import (CradleDataLoadingConfig,\n",
    "#                                                    MdsDataSourceConfig,\n",
    "#                                                    EdxDataSourceConfig,\n",
    "#                                                    DataSourceConfig,\n",
    "#                                                    DataSourcesSpecificationConfig,\n",
    "#                                                    JobSplitOptionsConfig,\n",
    "#                                                    TransformSpecificationConfig,\n",
    "#                                                    OutputSpecificationConfig,\n",
    "#                                                    CradleJobSpecificationConfig\n",
    "#                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2df6703-df32-4145-8571-e70b1740cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cursus.steps.configs.config_dummy_data_loading_step import DummyDataLoadingConfig\n",
    "from cursus.steps.configs.config_tabular_preprocessing_step import TabularPreprocessingConfig\n",
    "from cursus.steps.configs.config_bedrock_prompt_template_generation_step import BedrockPromptTemplateGenerationConfig\n",
    "from cursus.steps.configs.config_bedrock_batch_processing_step import BedrockBatchProcessingConfig\n",
    "from cursus.steps.configs.config_label_ruleset_generation_step import LabelRulesetGenerationConfig\n",
    "from cursus.steps.configs.config_label_ruleset_execution_step import LabelRulesetExecutionConfig\n",
    "from cursus.steps.configs.config_pytorch_training_step import PyTorchTrainingConfig\n",
    "from cursus.steps.configs.config_pytorch_model_eval_step import PyTorchModelEvalConfig\n",
    "from cursus.steps.configs.config_dummy_training_step import DummyTrainingConfig\n",
    "from cursus.steps.configs.config_model_calibration_step import ModelCalibrationConfig\n",
    "from cursus.steps.configs.config_package_step import PackageConfig\n",
    "from cursus.steps.configs.config_payload_step import PayloadConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fbb7c6-7f29-48bf-8940-86cf69df9c73",
   "metadata": {},
   "source": [
    "### Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "715f7a1c-a2c2-4809-b629-35d268b343e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cursus.steps.configs.utils import serialize_config, merge_and_save_configs, load_configs, verify_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a9787f3-493e-4631-9efc-eceeb0c2bc4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG_CLASSES = {\n",
    "        'DummyDataLoadingConfig':                     DummyDataLoadingConfig,\n",
    "        'BedrockPromptTemplateGenerationConfig':      BedrockPromptTemplateGenerationConfig,\n",
    "        'BedrockBatchProcessingConfig':               BedrockBatchProcessingConfig,\n",
    "        'TabularPreprocessingConfig':                 TabularPreprocessingConfig,\n",
    "        'LabelRulesetGenerationConfig':               LabelRulesetGenerationConfig,\n",
    "        'LabelRulesetExecutionConfig':                LabelRulesetExecutionConfig,\n",
    "        'PyTorchTrainingConfig':                      PyTorchTrainingConfig,\n",
    "        'PyTorchModelEvalConfig':                     PyTorchModelEvalConfig,\n",
    "        'DummyTrainingConfig':                        DummyTrainingConfig,\n",
    "        'ModelCalibrationConfig':                     ModelCalibrationConfig,\n",
    "        'PackageConfig':                              PackageConfig,\n",
    "        'PayloadConfig':                              PayloadConfig,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed47146d-6e3b-4254-aeae-21bae57e43d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dc47699-ed18-46e6-a9bc-ae8eb890feeb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:55,602 - INFO - Loading configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:55,602 - INFO - Loading configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:55,603 - INFO - Successfully loaded configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:55,604 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json with 7 specific configs\n",
      "2025-11-30 06:22:55,604 - INFO - Creating additional config instance for DummyDataLoading_calibration (DummyDataLoadingConfig)\n",
      "2025-11-30 06:22:55,605 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:55,605 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:55,606 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2025-11-30 06:22:55,606 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:55,606 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:55,607 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:55,607 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:55,607 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2025-11-30 06:22:55,608 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:55,608 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:55,718 - INFO - Discovered 63 core config classes\n",
      "2025-11-30 06:22:55,735 - INFO - Discovered 6 core hyperparameter classes\n",
      "2025-11-30 06:22:55,763 - INFO - Discovered 7 base hyperparameter classes from core/base\n",
      "2025-11-30 06:22:55,764 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,765 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,765 - INFO - Creating additional config instance for DummyTraining (DummyTrainingConfig)\n",
      "2025-11-30 06:22:55,766 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,766 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,767 - INFO - Creating additional config instance for ModelCalibration_calibration (ModelCalibrationConfig)\n",
      "2025-11-30 06:22:55,768 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,768 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,769 - INFO - Creating additional config instance for Package (PackageConfig)\n",
      "2025-11-30 06:22:55,769 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,770 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,770 - INFO - Creating additional config instance for Payload (PayloadConfig)\n",
      "2025-11-30 06:22:55,771 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,771 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,772 - INFO - Creating additional config instance for PyTorchModelEval_calibration (PyTorchModelEvalConfig)\n",
      "2025-11-30 06:22:55,773 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:55,773 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:55,773 - INFO - Creating additional config instance for TabularPreprocessing_calibration (TabularPreprocessingConfig)\n",
      "2025-11-30 06:22:55,774 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,775 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:55,775 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n"
     ]
    }
   ],
   "source": [
    "# Load configs\n",
    "loaded_configs = load_configs(config_path, CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8f2aee4-a039-42e6-a89b-86c0084f6c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DummyDataLoading_calibration': DummyDataLoadingConfig(author='lukexie', bucket='buyer-seller-messaging-reversal', role='arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default', region='NA', service_name='BuyerAbuseRnR', pipeline_version='0.0.2', model_class='pytorch', current_date='2025-11-30', framework_version='2.1.0', py_version='py310', source_dir='docker', enable_caching=False, use_secure_pypi=False, max_runtime_seconds=172800, project_root_folder='rnr_pytorch_bedrock', processing_instance_count=1, processing_volume_size=500, processing_instance_type_large='ml.m5.12xlarge', processing_instance_type_small='ml.m5.4xlarge', use_large_processing_instance=True, processing_source_dir='docker/scripts', processing_entry_point='dummy_data_loading.py', processing_script_arguments=None, processing_framework_version='1.2-1', data_source='s3://buyer-seller-messaging-reversal/pipeline/lukexie-BuyerAbuseRnR-pytorch-NA/20251111035543/labelrulesetexecution/processed_data/test', job_type='calibration', max_file_size_mb=1000, supported_formats=['csv', 'parquet', 'json', 'jsonl'], write_data_shards=True, shard_size=10000, output_format='PARQUET'),\n",
       " 'DummyTraining': DummyTrainingConfig(author='lukexie', bucket='buyer-seller-messaging-reversal', role='arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default', region='NA', service_name='BuyerAbuseRnR', pipeline_version='0.0.2', model_class='pytorch', current_date='2025-11-30', framework_version='2.1.0', py_version='py310', source_dir='docker', enable_caching=False, use_secure_pypi=False, max_runtime_seconds=172800, project_root_folder='rnr_pytorch_bedrock', processing_instance_count=1, processing_volume_size=500, processing_instance_type_large='ml.m5.12xlarge', processing_instance_type_small='ml.m5.4xlarge', use_large_processing_instance=True, processing_source_dir='docker/scripts', processing_entry_point='dummy_training.py', processing_script_arguments=None, processing_framework_version='1.2-1', pretrained_model_path='s3://buyer-seller-messaging-reversal/pipeline/lukexie-BuyerAbuseRnR-pytorch-NA/20251128070034/pytorch_training/pipelines-stiuq2fnydgp-PyTorchTraining-xXHG9pkuK0/output/model.tar.gz'),\n",
       " 'ModelCalibration_calibration': ModelCalibrationConfig(author='lukexie', bucket='buyer-seller-messaging-reversal', role='arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default', region='NA', service_name='BuyerAbuseRnR', pipeline_version='0.0.2', model_class='pytorch', current_date='2025-11-30', framework_version='2.1.0', py_version='py310', source_dir='docker', enable_caching=False, use_secure_pypi=False, max_runtime_seconds=172800, project_root_folder='rnr_pytorch_bedrock', processing_instance_count=1, processing_volume_size=500, processing_instance_type_large='ml.m5.12xlarge', processing_instance_type_small='ml.m5.4xlarge', use_large_processing_instance=False, processing_source_dir='docker/scripts', processing_entry_point='model_calibration.py', processing_script_arguments=None, processing_framework_version='1.2-1', label_field='llm_reversal_flag', score_field='prob_class_1', score_fields=None, calibration_method='gam', monotonic_constraint=True, gam_splines=10, error_threshold=0.05, is_binary=True, num_classes=2, score_field_prefix='prob_class_', calibration_sample_points=1000, multiclass_categories=[0, 1], job_type='calibration'),\n",
       " 'Package': PackageConfig(author='lukexie', bucket='buyer-seller-messaging-reversal', role='arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default', region='NA', service_name='BuyerAbuseRnR', pipeline_version='0.0.2', model_class='pytorch', current_date='2025-11-30', framework_version='2.1.0', py_version='py310', source_dir='docker', enable_caching=False, use_secure_pypi=False, max_runtime_seconds=172800, project_root_folder='rnr_pytorch_bedrock', processing_instance_count=1, processing_volume_size=500, processing_instance_type_large='ml.m5.12xlarge', processing_instance_type_small='ml.m5.4xlarge', use_large_processing_instance=False, processing_source_dir='docker/scripts', processing_entry_point='package.py', processing_script_arguments=None, processing_framework_version='1.2-1'),\n",
       " 'Payload': PayloadConfig(author='lukexie', bucket='buyer-seller-messaging-reversal', role='arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default', region='NA', service_name='BuyerAbuseRnR', pipeline_version='0.0.2', model_class='pytorch', current_date='2025-11-30', framework_version='2.1.0', py_version='py310', source_dir='docker', enable_caching=False, use_secure_pypi=False, max_runtime_seconds=172800, project_root_folder='rnr_pytorch_bedrock', processing_instance_count=1, processing_volume_size=500, processing_instance_type_large='ml.m5.12xlarge', processing_instance_type_small='ml.m5.4xlarge', use_large_processing_instance=False, processing_source_dir='docker/scripts', processing_entry_point='payload.py', processing_script_arguments=None, processing_framework_version='1.2-1', expected_tps=10, max_latency_in_millisecond=800, source_model_inference_content_types=['text/csv'], source_model_inference_response_types=['application/json'], default_numeric_value=0.0, default_text_value='DEFAULT_TEXT', field_defaults={'dialogue': '[bom] [Arrival Time]: 2025-06-11 [BUYER]: I need my refund. [eom]', 'shiptrack_event_history_by_order': '[bom] [Shipment ID]: [eom] [bom] [Ship Track Event Code]: EVENT_503 [Ship Track Event]: Pickup scheduled with Carrier. [eom]'}, custom_payload_path=None, max_acceptable_error_rate=0.2),\n",
       " 'PyTorchModelEval_calibration': PyTorchModelEvalConfig(author='lukexie', bucket='buyer-seller-messaging-reversal', role='arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default', region='NA', service_name='BuyerAbuseRnR', pipeline_version='0.0.2', model_class='pytorch', current_date='2025-11-30', framework_version='2.1.0', py_version='py310', source_dir='docker', enable_caching=False, use_secure_pypi=False, max_runtime_seconds=172800, project_root_folder='rnr_pytorch_bedrock', processing_instance_count=1, processing_volume_size=500, processing_instance_type_large='ml.g5.12xlarge', processing_instance_type_small='ml.m5.4xlarge', use_large_processing_instance=True, processing_source_dir='docker', processing_entry_point='pytorch_model_eval.py', processing_script_arguments=None, processing_framework_version='1.2-1', id_name='order_id', label_name='llm_reversal_flag', job_type='calibration', eval_metric_choices=['auroc', 'average_precision', 'f1_score'], ca_repository_arn='arn:aws:codeartifact:us-west-2:149122183214:repository/amazon/secure-pypi', comparison_mode=False, previous_score_field='', comparison_metrics='all', statistical_tests=True, comparison_plots=True),\n",
       " 'TabularPreprocessing_calibration': TabularPreprocessingConfig(author='lukexie', bucket='buyer-seller-messaging-reversal', role='arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default', region='NA', service_name='BuyerAbuseRnR', pipeline_version='0.0.2', model_class='pytorch', current_date='2025-11-30', framework_version='2.1.0', py_version='py310', source_dir='docker', enable_caching=False, use_secure_pypi=False, max_runtime_seconds=172800, project_root_folder='rnr_pytorch_bedrock', processing_instance_count=1, processing_volume_size=500, processing_instance_type_large='ml.m5.12xlarge', processing_instance_type_small='ml.m5.4xlarge', use_large_processing_instance=True, processing_source_dir='docker/scripts', processing_entry_point='tabular_preprocessing.py', processing_script_arguments=None, processing_framework_version='1.2-1', job_type='calibration', label_name=None, train_ratio=0.7, test_val_ratio=0.5, output_format='Parquet')}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bf71f23-b2af-4c1c-852a-7f53f538a896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10d3c8a6-a822-483b-be8b-2cacd1a8326f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DummyDataLoading_calibration',\n",
       " 'DummyTraining',\n",
       " 'ModelCalibration_calibration',\n",
       " 'Package',\n",
       " 'Payload',\n",
       " 'PyTorchModelEval_calibration',\n",
       " 'TabularPreprocessing_calibration']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(k) for k in loaded_configs.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c406dc5a-2e6e-40b4-981f-bf23c7dd1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_config = next(iter(loaded_configs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e76a613-f5a2-4008-9c08-85ec25077883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PIPELINE_VERSION = first_config.pipeline_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e42b028-085e-43d4-9fed-767174934670",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_DESCRIPTION = first_config.pipeline_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01aa4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = first_config.pipeline_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37356c7-34c6-472a-b9a0-7ccaaf87d374",
   "metadata": {},
   "source": [
    "## Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca29b12b-3867-426a-adfc-d6e46e65587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:55,836 - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "# Initialize boto3 clients\n",
    "ec2_client = boto3.client('ec2')\n",
    "kms_client = boto3.client('kms')\n",
    "sts_client = boto3.client('sts')\n",
    "\n",
    "# Get account and region info\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578482b6-1ef2-4a30-b52e-77843816f04f",
   "metadata": {},
   "source": [
    "### Find VPC Subnet - Get default VPC subnets or list all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c915ec6a-a3b5-47bc-9153-4159b809f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ec2_client.describe_subnets(\n",
    "    Filters=[{'Name': 'default-for-az', 'Values': ['true']}]\n",
    ")\n",
    "vpc_subnet_id = response['Subnets'][0]['SubnetId'] if response['Subnets'] else None\n",
    "\n",
    "# OR list all subnets and choose one\n",
    "#all_subnets = ec2_client.describe_subnets()\n",
    "#for subnet in all_subnets['Subnets']:\n",
    "#    print(f\"Subnet ID: {subnet['SubnetId']}, VPC: {subnet['VpcId']}, AZ: {subnet['AvailabilityZone']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb35919",
   "metadata": {},
   "source": [
    "### Find Security Group - Get default or list all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e02ebc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ec2_client.describe_security_groups(\n",
    "    Filters=[{'Name': 'group-name', 'Values': ['default']}]\n",
    ")\n",
    "security_group_id = response['SecurityGroups'][0]['GroupId'] if response['SecurityGroups'] else None\n",
    "\n",
    "# OR list all security groups\n",
    "#all_sgs = ec2_client.describe_security_groups()\n",
    "#for sg in all_sgs['SecurityGroups']:\n",
    "#    print(f\"SG ID: {sg['GroupId']}, Name: {sg['GroupName']}, VPC: {sg.get('VpcId')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed69c5-c066-421e-bd69-11ebb2a2bacc",
   "metadata": {},
   "source": [
    "### Find KMS Key - List KMS keys for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7d27cef-15bc-4602-9de7-6d6af0ce9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = kms_client.list_aliases()\n",
    "for alias in response['Aliases']:\n",
    "    if 'sagemaker' in alias['AliasName'].lower():\n",
    "        print(f\"KMS Alias: {alias['AliasName']}, Key ID: {alias.get('TargetKeyId')}\")\n",
    "\n",
    "# OR get account's default KMS key ARN\n",
    "kms_key_id = f\"arn:aws:kms:{region}:{account_id}:alias/aws/sagemaker\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e10cdeac-719b-43cc-aa46-6ef2c1ce91cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found values:\n",
      "VPC Subnet: subnet-45db3e4b\n",
      "Security Group: sg-e116c4be\n",
      "KMS Key: arn:aws:kms:us-east-1:178936618742:alias/aws/sagemaker\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFound values:\")\n",
    "print(f\"VPC Subnet: {vpc_subnet_id}\")\n",
    "print(f\"Security Group: {security_group_id}\")\n",
    "print(f\"KMS Key: {kms_key_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26b581",
   "metadata": {},
   "source": [
    "### Execution Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d840789",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_id = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e7b6d-8793-45e4-b228-32258643c246",
   "metadata": {},
   "source": [
    "### Define Parameter String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32b833cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.parameters import ParameterString\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdf5691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined Pipeline Parameters\n",
    "PIPELINE_EXECUTION_TEMP_DIR = ParameterString(name=\"EXECUTION_S3_PREFIX\", default_value=f\"s3://{bucket_name}/pipeline/{PIPELINE_NAME}/{execution_id}\")\n",
    "KMS_ENCRYPTION_KEY_PARAM = ParameterString(name=\"KMS_ENCRYPTION_KEY_PARAM\", default_value=kms_key_id)\n",
    "VPC_SUBNET = ParameterString(\n",
    "    name=\"VPC_SUBNET\",\n",
    "    default_value=vpc_subnet_id\n",
    ")  # TODO: test if we can replace it with multiple subnets\n",
    "SECURITY_GROUP_ID = ParameterString(name=\"SECURITY_GROUP_ID\", default_value=security_group_id)\n",
    "PROCESSING_JOB_SHARED_NETWORK_CONFIG = NetworkConfig(\n",
    "    enable_network_isolation=False,\n",
    "    security_group_ids=[SECURITY_GROUP_ID],\n",
    "    subnets=[VPC_SUBNET],\n",
    "    encrypt_inter_container_traffic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfbda68-5e79-419e-8de5-e4ce2b13d408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b04ac28-360a-4886-a447-332884b77a74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66e6a4d8-728e-4376-ab5d-5c1fb1659679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List, Any, Optional, Type\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import os\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7cf7f72-1ff6-4614-843c-d1c8e20e90e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import Session\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.parameters import Parameter\n",
    "from sagemaker.workflow.properties import Properties\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession # Crucial import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687beff8-d4b1-4eca-80cd-9921ab83e616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a27354d-00f5-4847-aae7-632d6260a4f7",
   "metadata": {},
   "source": [
    "## Demo: An End-to-End Pipeline based on PipelineDAG Compiler\n",
    "Let us use the following simpler DAG (without registration as example)\n",
    "\n",
    "\n",
    "In this demo there are several user input\n",
    "* the **Unified JSON file** in `config_path`\n",
    "* the **Registry Manager**: an object that handles the map between step logical name to `step.properties`\n",
    "* the **Dependency Resolver**: an object than handles the *automatic dependency resolution* between steps\n",
    "* the other fields\n",
    "    * `sagemaker_session`: pipelne session\n",
    "    * `role`: IAM Role\n",
    "    * `notebook_root`: track the root path \n",
    "\n",
    "\n",
    "In this pipeline template, we inherit from base class `PipelineTemplateBase`. \n",
    "\n",
    "The **major tasks** are\n",
    "* *`Config` Classes Import*\n",
    "* *Configuration Validation*\n",
    "* *Step Builder Retrieval and Step Builder Map Creation*\n",
    "* *Configuration Map Creation*\n",
    "* **Pipeline DAG Generation**: ideally, user should create this DAG and use it as input\n",
    "* **Automatic Pipeline Assemble**: Call `pipeline_assembler`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16849f-e888-4496-9737-a87f6de06288",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32afaaa-1586-410c-959a-a23912e05d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ab571ca-b049-4788-80a4-1ac03870d2bc",
   "metadata": {},
   "source": [
    "### DAG to Template Compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44a61b62-571b-4440-a3c1-17048474240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cursus.api.dag.base_dag import PipelineDAG\n",
    "from cursus.core.compiler.dag_compiler import compile_dag_to_pipeline, PipelineDAGCompiler\n",
    "from cursus.core.compiler.validation import ConversionReport\n",
    "from cursus.steps.configs.utils import load_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6045ac10-6937-461e-9611-50aa83cc824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bedrock_batch_pytorch_with_label_ruleset_e2e_dag() -> PipelineDAG:\n",
    "    \"\"\"\n",
    "    Create a DAG for Bedrock Batch-enhanced PyTorch E2E pipeline with Label Ruleset steps.\n",
    "\n",
    "    This DAG represents a complete end-to-end workflow that uses:\n",
    "    1. Bedrock prompt template generation and batch processing for LLM-enhanced data\n",
    "    2. Label ruleset generation and execution for transparent label transformation\n",
    "    3. PyTorch training, followed by calibration, packaging, and registration\n",
    "\n",
    "    The label ruleset steps sit between Bedrock processing and training/evaluation,\n",
    "    providing transparent, rule-based label transformation that's easy to modify.\n",
    "\n",
    "    Returns:\n",
    "        PipelineDAG: The directed acyclic graph for the pipeline\n",
    "    \"\"\"\n",
    "    dag = PipelineDAG()\n",
    "\n",
    "    # Add all nodes - incorporating Bedrock batch processing and label ruleset steps\n",
    "    dag.add_node(\"DummyDataLoading_training\")  # Dummy data load for training\n",
    "    dag.add_node(\"TabularPreprocessing_training\")  # Tabular preprocessing for training\n",
    "    #dag.add_node(\n",
    "    #    \"BedrockPromptTemplateGeneration\"\n",
    "    #)  # Bedrock prompt template generation (shared)\n",
    "    #dag.add_node(\n",
    "    #    \"BedrockBatchProcessing_training\"\n",
    "    #)  # Bedrock batch processing step for training\n",
    "    #dag.add_node(\n",
    "    #    \"LabelRulesetGeneration\"\n",
    "    #)  # Label ruleset generation (shared for training and calibration)\n",
    "    #dag.add_node(\n",
    "    #    \"LabelRulesetExecution_training\"\n",
    "    #)  # Label ruleset execution for training data\n",
    "    dag.add_node(\"PyTorchTraining\")  # PyTorch training step\n",
    "    #dag.add_node(\n",
    "    #    \"ModelCalibration_calibration\"\n",
    "    #)  # Model calibration step with calibration variant\n",
    "    #dag.add_node(\"Package\")  # Package step\n",
    "    #dag.add_node(\"Registration\")  # MIMS registration step\n",
    "    #dag.add_node(\"Payload\")  # Payload step\n",
    "    #dag.add_node(\"DummyDataLoading_calibration\")  # Dummy data load for calibration\n",
    "    #dag.add_node(\n",
    "    #    \"TabularPreprocessing_calibration\"\n",
    "    #)  # Tabular preprocessing for calibration\n",
    "    #dag.add_node(\n",
    "    #    \"BedrockBatchProcessing_calibration\"\n",
    "    #)  # Bedrock batch processing step for calibration\n",
    "    #dag.add_node(\n",
    "    #    \"LabelRulesetExecution_calibration\"\n",
    "    #)  # Label ruleset execution for calibration data\n",
    "    #dag.add_node(\"PyTorchModelEval_calibration\")  # Model evaluation step\n",
    "\n",
    "    # Training flow with Bedrock batch processing and label ruleset integration\n",
    "    dag.add_edge(\"DummyDataLoading_training\", \"TabularPreprocessing_training\")\n",
    "    dag.add_edge(\n",
    "        \"TabularPreprocessing_training\", \"PyTorchTraining\"\n",
    "    )  # Data input\n",
    "    \n",
    "    # Bedrock batch processing flow for training - two inputs to BedrockBatchProcessing_training\n",
    "    dag.add_edge(\n",
    "        \"TabularPreprocessing_training\", \"BedrockBatchProcessing_training\"\n",
    "    )  # Data input\n",
    "    dag.add_edge(\n",
    "        \"BedrockPromptTemplateGeneration\", \"BedrockBatchProcessing_training\"\n",
    "    )  # Template input\n",
    "\n",
    "    # Label ruleset execution for training - two inputs to LabelRulesetExecution_training\n",
    "    dag.add_edge(\n",
    "        \"BedrockBatchProcessing_training\", \"LabelRulesetExecution_training\"\n",
    "    )  # Data input\n",
    "    dag.add_edge(\n",
    "        \"LabelRulesetGeneration\", \"LabelRulesetExecution_training\"\n",
    "    )  # Ruleset input\n",
    "\n",
    "    # Labeled data flows to PyTorch training\n",
    "    dag.add_edge(\"LabelRulesetExecution_training\", \"PyTorchTraining\")\n",
    "\n",
    "    # Calibration flow with Bedrock batch processing and label ruleset integration\n",
    "    #dag.add_edge(\"DummyDataLoading_calibration\", \"TabularPreprocessing_calibration\")\n",
    "\n",
    "    # Bedrock batch processing flow for calibration - two inputs to BedrockBatchProcessing_calibration\n",
    "    #dag.add_edge(\n",
    "    #    \"TabularPreprocessing_calibration\", \"BedrockBatchProcessing_calibration\"\n",
    "    #)  # Data input\n",
    "    #dag.add_edge(\n",
    "    #    \"BedrockPromptTemplateGeneration\", \"BedrockBatchProcessing_calibration\"\n",
    "    #)  # Template input\n",
    "\n",
    "    # Label ruleset execution for calibration - two inputs to LabelRulesetExecution_calibration\n",
    "    #dag.add_edge(\n",
    "    #    \"BedrockBatchProcessing_calibration\", \"LabelRulesetExecution_calibration\"\n",
    "    #)  # Data input\n",
    "    #dag.add_edge(\n",
    "    #    \"LabelRulesetGeneration\", \"LabelRulesetExecution_calibration\"\n",
    "    #)  # Ruleset input\n",
    "\n",
    "    # Evaluation flow\n",
    "    #dag.add_edge(\"PyTorchTraining\", \"PyTorchModelEval_calibration\")\n",
    "    #dag.add_edge(\n",
    "    #    \"LabelRulesetExecution_calibration\", \"PyTorchModelEval_calibration\"\n",
    "    #)  # Use labeled calibration data\n",
    "\n",
    "    # Model calibration flow - depends on model evaluation\n",
    "    #dag.add_edge(\"PyTorchModelEval_calibration\", \"ModelCalibration_calibration\")\n",
    "\n",
    "    # Output flow\n",
    "    #dag.add_edge(\"ModelCalibration_calibration\", \"Package\")\n",
    "    #dag.add_edge(\"PyTorchTraining\", \"Package\")  # Raw model is also input to packaging\n",
    "    #dag.add_edge(\"PyTorchTraining\", \"Payload\")  # Payload test uses the raw model\n",
    "    #dag.add_edge(\"Package\", \"Registration\")\n",
    "    #dag.add_edge(\"Payload\", \"Registration\")\n",
    "\n",
    "    logger.info(\n",
    "        f\"Created Bedrock Batch-PyTorch with Label Ruleset E2E DAG with {len(dag.nodes)} nodes and {len(dag.edges)} edges\"\n",
    "    )\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "217ed238-72c2-49bc-9753-3e6a27445f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bedrock_batch_pytorch_with_label_ruleset_e2e_dag() -> PipelineDAG:\n",
    "    \"\"\"\n",
    "    Create a complete end-to-end XGBoost pipeline DAG.\n",
    "    \n",
    "    This DAG represents the same workflow as the legacy demo_config.ipynb\n",
    "    but in a structured, reusable format.\n",
    "    \n",
    "    Returns:\n",
    "        PipelineDAG: The directed acyclic graph for the pipeline\n",
    "    \"\"\"\n",
    "    dag = PipelineDAG()\n",
    "    \n",
    "    # Add all nodes - matching the structure from demo_config.ipynb\n",
    "    dag.add_node(\"DummyDataLoading_training\")      # Training data loading\n",
    "    dag.add_node(\"TabularPreprocessing_training\")   # Training data preprocessing\n",
    "    dag.add_node(\"PyTorchTraining\")                 # XGBoost model training\n",
    "    \n",
    "    # Define dependencies - training flow\n",
    "    dag.add_edge(\"DummyDataLoading_training\", \"TabularPreprocessing_training\")\n",
    "    dag.add_edge(\"TabularPreprocessing_training\", \"PyTorchTraining\")\n",
    "    \n",
    "    logger.info(f\"Created XGBoost E2E DAG with {len(dag.nodes)} nodes and {len(dag.edges)} edges\")\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cd520b7-2651-44dc-a1bb-42567bb012cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bedrock_batch_pytorch_with_label_ruleset_e2e_dag() -> PipelineDAG:\n",
    "    \"\"\"\n",
    "    Create a complete end-to-end XGBoost pipeline DAG.\n",
    "    \n",
    "    This DAG represents the same workflow as the legacy demo_config.ipynb\n",
    "    but in a structured, reusable format.\n",
    "    \n",
    "    Returns:\n",
    "        PipelineDAG: The directed acyclic graph for the pipeline\n",
    "    \"\"\"\n",
    "    dag = PipelineDAG()\n",
    "    \n",
    "    # Add all nodes - incorporating Bedrock batch processing and label ruleset steps\n",
    "    dag.add_node(\"DummyTraining\")  # Dummy data load for training\n",
    "    dag.add_node(\"DummyDataLoading_calibration\")  # Dummy data load for calibration\n",
    "    dag.add_node(\n",
    "        \"TabularPreprocessing_calibration\"\n",
    "    )  # Tabular preprocessing for calibration\n",
    "    dag.add_node(\"PyTorchModelEval_calibration\")  # Model evaluation step\n",
    "    dag.add_node(\n",
    "        \"ModelCalibration_calibration\"\n",
    "    )  # Model calibration step with calibration variant\n",
    "    dag.add_node(\"Package\")  # Package step\n",
    "    dag.add_node(\"Payload\")  # Payload step\n",
    "\n",
    "\n",
    "    # Calibration flow with Bedrock batch processing and label ruleset integration\n",
    "    dag.add_edge(\"DummyDataLoading_calibration\", \"TabularPreprocessing_calibration\")\n",
    "\n",
    "    # Evaluation flow\n",
    "    dag.add_edge(\"DummyTraining\", \"PyTorchModelEval_calibration\")\n",
    "    dag.add_edge(\n",
    "        \"TabularPreprocessing_calibration\", \"PyTorchModelEval_calibration\"\n",
    "    )  # Use labeled calibration data\n",
    "\n",
    "    # Model calibration flow - depends on model evaluation\n",
    "    dag.add_edge(\"PyTorchModelEval_calibration\", \"ModelCalibration_calibration\")\n",
    "\n",
    "    # Output flow\n",
    "    dag.add_edge(\"ModelCalibration_calibration\", \"Package\")\n",
    "    dag.add_edge(\"DummyTraining\", \"Package\")  # Raw model is also input to packaging\n",
    "    dag.add_edge(\"DummyTraining\", \"Payload\")  # Payload test uses the raw model\n",
    "    \n",
    "    logger.info(f\"Created XGBoost E2E DAG with {len(dag.nodes)} nodes and {len(dag.edges)} edges\")\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88e0d05f-404d-4732-b4b8-e3ae866a9f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:56,532 - INFO - Added node: DummyTraining\n",
      "2025-11-30 06:22:56,532 - INFO - Added node: DummyDataLoading_calibration\n",
      "2025-11-30 06:22:56,533 - INFO - Added node: TabularPreprocessing_calibration\n",
      "2025-11-30 06:22:56,533 - INFO - Added node: PyTorchModelEval_calibration\n",
      "2025-11-30 06:22:56,533 - INFO - Added node: ModelCalibration_calibration\n",
      "2025-11-30 06:22:56,534 - INFO - Added node: Package\n",
      "2025-11-30 06:22:56,534 - INFO - Added node: Payload\n",
      "2025-11-30 06:22:56,534 - INFO - Added edge: DummyDataLoading_calibration -> TabularPreprocessing_calibration\n",
      "2025-11-30 06:22:56,535 - INFO - Added edge: DummyTraining -> PyTorchModelEval_calibration\n",
      "2025-11-30 06:22:56,535 - INFO - Added edge: TabularPreprocessing_calibration -> PyTorchModelEval_calibration\n",
      "2025-11-30 06:22:56,535 - INFO - Added edge: PyTorchModelEval_calibration -> ModelCalibration_calibration\n",
      "2025-11-30 06:22:56,536 - INFO - Added edge: ModelCalibration_calibration -> Package\n",
      "2025-11-30 06:22:56,536 - INFO - Added edge: DummyTraining -> Package\n",
      "2025-11-30 06:22:56,536 - INFO - Added edge: DummyTraining -> Payload\n",
      "2025-11-30 06:22:56,536 - INFO - Created XGBoost E2E DAG with 7 nodes and 7 edges\n"
     ]
    }
   ],
   "source": [
    "dag = create_bedrock_batch_pytorch_with_label_ruleset_e2e_dag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82c4b4f5-171d-4a67-9c44-d95152104154",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_parameters = [\n",
    "    PIPELINE_EXECUTION_TEMP_DIR,\n",
    "    KMS_ENCRYPTION_KEY_PARAM,\n",
    "    SECURITY_GROUP_ID,\n",
    "    VPC_SUBNET,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afe3f43a-b759-47be-93dd-4f60249b44db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:56,546 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,547 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,547 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2025-11-30 06:22:56,548 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,548 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,548 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,549 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,549 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2025-11-30 06:22:56,550 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,550 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,551 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,551 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,552 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2025-11-30 06:22:56,552 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,553 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,553 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,553 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,554 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2025-11-30 06:22:56,554 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,555 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n"
     ]
    }
   ],
   "source": [
    "dag_compiler = PipelineDAGCompiler(\n",
    "    config_path=config_path,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    "    pipeline_parameters=pipeline_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c2242-932d-43c3-8b84-b81dfc5de16e",
   "metadata": {},
   "source": [
    "### Create a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def820f-b4fc-4660-85f5-f6d6c832b985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d7dbeb8-f0ba-42f2-9c55-fede4f97db62",
   "metadata": {},
   "source": [
    "#### DAG Validation and Preview of Config Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f1ce473-9034-472c-81ec-1edea11b38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f50ae6a-b1af-44e4-bab2-76dadeb33453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:56,565 - INFO - Previewing resolution for 7 DAG nodes\n",
      "2025-11-30 06:22:56,565 - INFO - Creating template for DAG with 7 nodes\n",
      "2025-11-30 06:22:56,566 - WARNING - Could not import config_class_detector, using fallback implementation\n",
      "2025-11-30 06:22:56,566 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,567 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,567 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2025-11-30 06:22:56,568 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,568 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,568 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,569 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,569 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2025-11-30 06:22:56,570 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,570 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,571 - INFO - Successfully discovered 76 config classes using step catalog\n",
      "2025-11-30 06:22:56,571 - INFO - Loading configs from: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,572 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,572 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,573 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2025-11-30 06:22:56,573 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,573 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,574 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,574 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,575 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2025-11-30 06:22:56,575 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,575 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,576 - INFO - Successfully discovered 76 config classes using step catalog\n",
      "2025-11-30 06:22:56,576 - INFO - Loading configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,577 - INFO - Loading configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,578 - INFO - Successfully loaded configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,578 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json with 7 specific configs\n",
      "2025-11-30 06:22:56,579 - INFO - Creating additional config instance for DummyDataLoading_calibration (DummyDataLoadingConfig)\n",
      "2025-11-30 06:22:56,580 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,580 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,580 - INFO - Creating additional config instance for DummyTraining (DummyTrainingConfig)\n",
      "2025-11-30 06:22:56,581 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,582 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,582 - INFO - Creating additional config instance for ModelCalibration_calibration (ModelCalibrationConfig)\n",
      "2025-11-30 06:22:56,583 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,583 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,584 - INFO - Creating additional config instance for Package (PackageConfig)\n",
      "2025-11-30 06:22:56,584 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,585 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,585 - INFO - Creating additional config instance for Payload (PayloadConfig)\n",
      "2025-11-30 06:22:56,586 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,587 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,587 - INFO - Creating additional config instance for PyTorchModelEval_calibration (PyTorchModelEvalConfig)\n",
      "2025-11-30 06:22:56,588 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:56,588 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:56,589 - INFO - Creating additional config instance for TabularPreprocessing_calibration (TabularPreprocessingConfig)\n",
      "2025-11-30 06:22:56,589 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,590 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,590 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,591 - INFO - Loaded raw configuration data from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,591 - INFO - Initialized registry manager with workspace context: None\n",
      "2025-11-30 06:22:56,592 - INFO - Created specification registry for context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,593 - INFO - Created new workspace-aware registry for context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,593 - INFO - Created registry manager for context: lukexie-BuyerAbuseRnR-pytorch-NA\n",
      "2025-11-30 06:22:56,593 - INFO - Created dependency resolver for context: lukexie-BuyerAbuseRnR-pytorch-NA\n",
      "2025-11-30 06:22:56,594 - INFO - Validating dynamic pipeline configuration\n",
      "2025-11-30 06:22:56,594 - INFO - Resolving 7 DAG nodes to configurations\n",
      "2025-11-30 06:22:56,594 - INFO - Using metadata from loaded configuration\n",
      "2025-11-30 06:22:56,595 - INFO - Found exact key match for node 'DummyTraining'\n",
      "2025-11-30 06:22:56,595 - INFO - Found exact key match for node 'DummyDataLoading_calibration'\n",
      "2025-11-30 06:22:56,595 - INFO - Found exact key match for node 'TabularPreprocessing_calibration'\n",
      "2025-11-30 06:22:56,596 - INFO - Found exact key match for node 'PyTorchModelEval_calibration'\n",
      "2025-11-30 06:22:56,596 - INFO - Found exact key match for node 'ModelCalibration_calibration'\n",
      "2025-11-30 06:22:56,596 - INFO - Found exact key match for node 'Package'\n",
      "2025-11-30 06:22:56,597 - INFO - Found exact key match for node 'Payload'\n",
      "2025-11-30 06:22:56,597 - INFO - Successfully resolved all 7 nodes\n",
      "2025-11-30 06:22:56,604 - INFO - Index built successfully in 0.007s with 90 steps\n",
      "2025-11-30 06:22:56,629 - WARNING - Error loading class RegistrationStepBuilder from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/steps/builders/builder_registration_step.py (relative module: ..steps.builders.builder_registration_step): No module named 'secure_ai_sandbox_workflow_python_sdk'\n",
      "2025-11-30 06:22:56,660 - WARNING - Error loading class CradleDataLoadingStepBuilder from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/steps/builders/builder_cradle_data_loading_step.py (relative module: ..steps.builders.builder_cradle_data_loading_step): No module named 'secure_ai_sandbox_workflow_python_sdk'\n",
      "2025-11-30 06:22:56,672 - INFO - Builder discovery complete: 38 builders found\n",
      "2025-11-30 06:22:56,673 - INFO - Using 42 registered step builders from StepCatalog\n",
      "2025-11-30 06:22:56,673 - INFO - Successfully loaded builder class using base name 'DummyDataLoading' for 'DummyDataLoading_calibration': DummyDataLoadingStepBuilder\n",
      "2025-11-30 06:22:56,674 - INFO - Successfully loaded builder class using base name 'TabularPreprocessing' for 'TabularPreprocessing_calibration': TabularPreprocessingStepBuilder\n",
      "2025-11-30 06:22:56,674 - INFO - Successfully loaded builder class using base name 'PyTorchModelEval' for 'PyTorchModelEval_calibration': PyTorchModelEvalStepBuilder\n",
      "2025-11-30 06:22:56,674 - INFO - Successfully loaded builder class using base name 'ModelCalibration' for 'ModelCalibration_calibration': ModelCalibrationStepBuilder\n",
      "2025-11-30 06:22:56,675 - INFO - Configuration validation passed successfully\n",
      "2025-11-30 06:22:56,676 - INFO - Pipeline name 'lukexie-BuyerAbuseRnR-pytorch-NA-0.0.2-pipeline' sanitized to 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' to conform to SageMaker constraints\n",
      "2025-11-30 06:22:56,676 - INFO - Initialized template for: lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline\n",
      "2025-11-30 06:22:56,676 - INFO - Successfully created template\n",
      "2025-11-30 06:22:56,677 - INFO - Using metadata.config_types mapping with 7 entries\n",
      "2025-11-30 06:22:56,677 - INFO - Found exact key match for node 'DummyTraining'\n",
      "2025-11-30 06:22:56,677 - INFO - Found exact key match for node 'DummyDataLoading_calibration'\n",
      "2025-11-30 06:22:56,678 - INFO - Found exact key match for node 'TabularPreprocessing_calibration'\n",
      "2025-11-30 06:22:56,678 - INFO - Found exact key match for node 'PyTorchModelEval_calibration'\n",
      "2025-11-30 06:22:56,678 - INFO - Found exact key match for node 'ModelCalibration_calibration'\n",
      "2025-11-30 06:22:56,679 - INFO - Found exact key match for node 'Package'\n",
      "2025-11-30 06:22:56,680 - INFO - Found exact key match for node 'Payload'\n",
      "2025-11-30 06:22:56,680 - ERROR - Failed to generate resolution preview: 0\n",
      "2025-11-30 06:22:56,681 - INFO - DAG node resolution preview:\n",
      "2025-11-30 06:22:56,681 - INFO - Recommendations:\n",
      "2025-11-30 06:22:56,681 - INFO -   - Preview failed: 0\n",
      "2025-11-30 06:22:56,682 - INFO - Validating DAG compatibility for 7 nodes\n",
      "2025-11-30 06:22:56,682 - INFO - Creating template for DAG with 7 nodes\n",
      "2025-11-30 06:22:56,682 - INFO - Loading configs from: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,683 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,683 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,684 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2025-11-30 06:22:56,685 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,685 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,685 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,686 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,686 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2025-11-30 06:22:56,686 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,687 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,687 - INFO - Successfully discovered 76 config classes using step catalog\n",
      "2025-11-30 06:22:56,688 - INFO - Loading configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,688 - INFO - Loading configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,689 - INFO - Successfully loaded configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,690 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json with 7 specific configs\n",
      "2025-11-30 06:22:56,690 - INFO - Creating additional config instance for DummyDataLoading_calibration (DummyDataLoadingConfig)\n",
      "2025-11-30 06:22:56,691 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,691 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,692 - INFO - Creating additional config instance for DummyTraining (DummyTrainingConfig)\n",
      "2025-11-30 06:22:56,693 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,693 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,694 - INFO - Creating additional config instance for ModelCalibration_calibration (ModelCalibrationConfig)\n",
      "2025-11-30 06:22:56,694 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,695 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,695 - INFO - Creating additional config instance for Package (PackageConfig)\n",
      "2025-11-30 06:22:56,696 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,696 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,696 - INFO - Creating additional config instance for Payload (PayloadConfig)\n",
      "2025-11-30 06:22:56,697 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,697 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,698 - INFO - Creating additional config instance for PyTorchModelEval_calibration (PyTorchModelEvalConfig)\n",
      "2025-11-30 06:22:56,698 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:56,699 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:56,699 - INFO - Creating additional config instance for TabularPreprocessing_calibration (TabularPreprocessingConfig)\n",
      "2025-11-30 06:22:56,700 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,700 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,700 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,702 - INFO - Loaded raw configuration data from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,702 - INFO - Initialized registry manager with workspace context: None\n",
      "2025-11-30 06:22:56,703 - INFO - Created specification registry for context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,704 - INFO - Created new workspace-aware registry for context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,704 - INFO - Created registry manager for context: lukexie-BuyerAbuseRnR-pytorch-NA\n",
      "2025-11-30 06:22:56,705 - INFO - Created dependency resolver for context: lukexie-BuyerAbuseRnR-pytorch-NA\n",
      "2025-11-30 06:22:56,705 - INFO - Validating dynamic pipeline configuration\n",
      "2025-11-30 06:22:56,705 - INFO - Resolving 7 DAG nodes to configurations\n",
      "2025-11-30 06:22:56,706 - INFO - Using metadata from loaded configuration\n",
      "2025-11-30 06:22:56,706 - INFO - Found exact key match for node 'DummyTraining'\n",
      "2025-11-30 06:22:56,706 - INFO - Found exact key match for node 'DummyDataLoading_calibration'\n",
      "2025-11-30 06:22:56,707 - INFO - Found exact key match for node 'TabularPreprocessing_calibration'\n",
      "2025-11-30 06:22:56,707 - INFO - Found exact key match for node 'PyTorchModelEval_calibration'\n",
      "2025-11-30 06:22:56,707 - INFO - Found exact key match for node 'ModelCalibration_calibration'\n",
      "2025-11-30 06:22:56,707 - INFO - Found exact key match for node 'Package'\n",
      "2025-11-30 06:22:56,708 - INFO - Found exact key match for node 'Payload'\n",
      "2025-11-30 06:22:56,708 - INFO - Successfully resolved all 7 nodes\n",
      "2025-11-30 06:22:56,709 - INFO - Using 42 registered step builders from StepCatalog\n",
      "2025-11-30 06:22:56,709 - INFO - Successfully loaded builder class using base name 'DummyDataLoading' for 'DummyDataLoading_calibration': DummyDataLoadingStepBuilder\n",
      "2025-11-30 06:22:56,710 - INFO - Successfully loaded builder class using base name 'TabularPreprocessing' for 'TabularPreprocessing_calibration': TabularPreprocessingStepBuilder\n",
      "2025-11-30 06:22:56,710 - INFO - Successfully loaded builder class using base name 'PyTorchModelEval' for 'PyTorchModelEval_calibration': PyTorchModelEvalStepBuilder\n",
      "2025-11-30 06:22:56,710 - INFO - Successfully loaded builder class using base name 'ModelCalibration' for 'ModelCalibration_calibration': ModelCalibrationStepBuilder\n",
      "2025-11-30 06:22:56,712 - INFO - Configuration validation passed successfully\n",
      "2025-11-30 06:22:56,712 - INFO - Pipeline name 'lukexie-BuyerAbuseRnR-pytorch-NA-0.0.2-pipeline' sanitized to 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' to conform to SageMaker constraints\n",
      "2025-11-30 06:22:56,713 - INFO - Initialized template for: lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline\n",
      "2025-11-30 06:22:56,713 - INFO - Successfully created template\n",
      "2025-11-30 06:22:56,714 - INFO - Validation completed: âœ… Validation passed\n",
      "2025-11-30 06:22:56,714 - INFO - DAG validation: VALID\n"
     ]
    }
   ],
   "source": [
    "if preview_only:\n",
    "    preview = dag_compiler.preview_resolution(dag)\n",
    "    logger.info(\"DAG node resolution preview:\")\n",
    "    for node, config_type in preview.node_config_map.items():\n",
    "        confidence = preview.resolution_confidence.get(node, 0.0)\n",
    "        logger.info(f\"  {node} â†’ {config_type} (confidence: {confidence:.2f})\")\n",
    "        \n",
    "    if preview.recommendations:\n",
    "        logger.info(\"Recommendations:\")\n",
    "        for recommendation in preview.recommendations:\n",
    "            logger.info(f\"  - {recommendation}\")\n",
    "        \n",
    "    validation = dag_compiler.validate_dag_compatibility(dag)\n",
    "    logger.info(f\"DAG validation: {'VALID' if validation.is_valid else 'INVALID'}\")\n",
    "    if not validation.is_valid:\n",
    "        if validation.missing_configs:\n",
    "            logger.warning(f\"Missing configs: {validation.missing_configs}\")\n",
    "        if validation.unresolvable_builders:\n",
    "            logger.warning(f\"Unresolvable builders: {validation.unresolvable_builders}\")\n",
    "        if validation.config_errors:\n",
    "            logger.warning(f\"Config errors: {validation.config_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15ff04-893e-41d1-a153-420405a38382",
   "metadata": {},
   "source": [
    "### Put it Together: Pipeline Generation from DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a8a68cc-a8a1-43d0-b5de-b3d473f13628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:56,719 - INFO - Converting DAG to pipeline\n",
      "2025-11-30 06:22:56,720 - INFO - Compiling DAG with detailed reporting\n",
      "2025-11-30 06:22:56,720 - INFO - Compiling DAG with 7 nodes to pipeline\n",
      "2025-11-30 06:22:56,720 - INFO - Creating template for DAG with 7 nodes\n",
      "2025-11-30 06:22:56,721 - INFO - Loading configs from: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,721 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,722 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,723 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2025-11-30 06:22:56,723 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,723 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,724 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:56,724 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:56,724 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2025-11-30 06:22:56,725 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:56,725 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:56,725 - INFO - Successfully discovered 76 config classes using step catalog\n",
      "2025-11-30 06:22:56,727 - INFO - Loading configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,727 - INFO - Loading configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,728 - INFO - Successfully loaded configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,728 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json with 7 specific configs\n",
      "2025-11-30 06:22:56,729 - INFO - Creating additional config instance for DummyDataLoading_calibration (DummyDataLoadingConfig)\n",
      "2025-11-30 06:22:56,730 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,730 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,730 - INFO - Creating additional config instance for DummyTraining (DummyTrainingConfig)\n",
      "2025-11-30 06:22:56,731 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,732 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,732 - INFO - Creating additional config instance for ModelCalibration_calibration (ModelCalibrationConfig)\n",
      "2025-11-30 06:22:56,733 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,733 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,734 - INFO - Creating additional config instance for Package (PackageConfig)\n",
      "2025-11-30 06:22:56,734 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,735 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,735 - INFO - Creating additional config instance for Payload (PayloadConfig)\n",
      "2025-11-30 06:22:56,736 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,737 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,737 - INFO - Creating additional config instance for PyTorchModelEval_calibration (PyTorchModelEvalConfig)\n",
      "2025-11-30 06:22:56,738 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:56,738 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:56,738 - INFO - Creating additional config instance for TabularPreprocessing_calibration (TabularPreprocessingConfig)\n",
      "2025-11-30 06:22:56,739 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,739 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:56,740 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,741 - INFO - Loaded raw configuration data from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:56,741 - INFO - Initialized registry manager with workspace context: None\n",
      "2025-11-30 06:22:56,742 - INFO - Created specification registry for context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,743 - INFO - Created new workspace-aware registry for context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,743 - INFO - Created registry manager for context: lukexie-BuyerAbuseRnR-pytorch-NA\n",
      "2025-11-30 06:22:56,743 - INFO - Created dependency resolver for context: lukexie-BuyerAbuseRnR-pytorch-NA\n",
      "2025-11-30 06:22:56,744 - INFO - Skipping configuration validation (requested)\n",
      "2025-11-30 06:22:56,744 - INFO - Pipeline name 'lukexie-BuyerAbuseRnR-pytorch-NA-0.0.2-pipeline' sanitized to 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' to conform to SageMaker constraints\n",
      "2025-11-30 06:22:56,744 - INFO - Initialized template for: lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline\n",
      "2025-11-30 06:22:56,745 - INFO - Successfully created template\n",
      "2025-11-30 06:22:56,745 - INFO - Pipeline name 'lukexie-BuyerAbuseRnR-pytorch-NA-0.0.2-pipeline' sanitized to 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' to conform to SageMaker constraints\n",
      "2025-11-30 06:22:56,745 - INFO - Generating pipeline: lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline\n",
      "2025-11-30 06:22:56,746 - INFO - Resolving 7 DAG nodes to configurations\n",
      "2025-11-30 06:22:56,746 - INFO - Using metadata from loaded configuration\n",
      "2025-11-30 06:22:56,746 - INFO - Found exact key match for node 'DummyTraining'\n",
      "2025-11-30 06:22:56,747 - INFO - Found exact key match for node 'DummyDataLoading_calibration'\n",
      "2025-11-30 06:22:56,748 - INFO - Found exact key match for node 'TabularPreprocessing_calibration'\n",
      "2025-11-30 06:22:56,748 - INFO - Found exact key match for node 'PyTorchModelEval_calibration'\n",
      "2025-11-30 06:22:56,749 - INFO - Found exact key match for node 'ModelCalibration_calibration'\n",
      "2025-11-30 06:22:56,749 - INFO - Found exact key match for node 'Package'\n",
      "2025-11-30 06:22:56,749 - INFO - Found exact key match for node 'Payload'\n",
      "2025-11-30 06:22:56,750 - INFO - Successfully resolved all 7 nodes\n",
      "2025-11-30 06:22:56,751 - INFO - Using 42 registered step builders from StepCatalog\n",
      "2025-11-30 06:22:56,751 - INFO - Successfully loaded builder class using base name 'DummyDataLoading' for 'DummyDataLoading_calibration': DummyDataLoadingStepBuilder\n",
      "2025-11-30 06:22:56,752 - INFO - Successfully loaded builder class using base name 'TabularPreprocessing' for 'TabularPreprocessing_calibration': TabularPreprocessingStepBuilder\n",
      "2025-11-30 06:22:56,752 - INFO - Successfully loaded builder class using base name 'PyTorchModelEval' for 'PyTorchModelEval_calibration': PyTorchModelEvalStepBuilder\n",
      "2025-11-30 06:22:56,752 - INFO - Successfully loaded builder class using base name 'ModelCalibration' for 'ModelCalibration_calibration': ModelCalibrationStepBuilder\n",
      "2025-11-30 06:22:56,753 - INFO - Using provided StepCatalog instance\n",
      "2025-11-30 06:22:56,753 - INFO - Using stored custom pipeline parameters\n",
      "2025-11-30 06:22:56,754 - INFO - Successfully loaded builder class using base name 'DummyDataLoading' for 'DummyDataLoading_calibration': DummyDataLoadingStepBuilder\n",
      "2025-11-30 06:22:56,754 - INFO - Successfully loaded builder class using base name 'TabularPreprocessing' for 'TabularPreprocessing_calibration': TabularPreprocessingStepBuilder\n",
      "2025-11-30 06:22:56,755 - INFO - Successfully loaded builder class using base name 'PyTorchModelEval' for 'PyTorchModelEval_calibration': PyTorchModelEvalStepBuilder\n",
      "2025-11-30 06:22:56,755 - INFO - Successfully loaded builder class using base name 'ModelCalibration' for 'ModelCalibration_calibration': ModelCalibrationStepBuilder\n",
      "2025-11-30 06:22:56,756 - INFO - Input validation successful\n",
      "2025-11-30 06:22:56,756 - INFO - Initializing step builders\n",
      "2025-11-30 06:22:56,757 - INFO - Initializing DummyTrainingStepBuilder with region: NA\n",
      "2025-11-30 06:22:56,757 - INFO - Validating DummyTraining INTERNAL configuration...\n",
      "2025-11-30 06:22:56,757 - INFO - Model artifacts will be sourced from config field: s3://buyer-seller-messaging-reversal/pipeline/lukexie-BuyerAbuseRnR-pytorch-NA/20251128070034/pytorch_training/pipelines-stiuq2fnydgp-PyTorchTraining-xXHG9pkuK0/output/model.tar.gz\n",
      "2025-11-30 06:22:56,758 - INFO - DummyTraining INTERNAL configuration validation succeeded.\n",
      "2025-11-30 06:22:56,758 - INFO - Set execution prefix for DummyTraining\n",
      "2025-11-30 06:22:56,758 - INFO - Initialized builder for step DummyTraining using StepCatalog\n",
      "2025-11-30 06:22:56,759 - INFO - Successfully loaded builder class using base name 'DummyDataLoading' for 'DummyDataLoading_calibration': DummyDataLoadingStepBuilder\n",
      "2025-11-30 06:22:56,759 - INFO - Using unified DUMMY_DATA_LOADING_SPEC for all job types\n",
      "2025-11-30 06:22:56,759 - INFO - Initializing DummyDataLoadingStepBuilder with region: NA\n",
      "2025-11-30 06:22:56,760 - INFO - Validating DummyDataLoadingConfig...\n",
      "2025-11-30 06:22:56,760 - INFO - DummyDataLoadingConfig validation succeeded.\n",
      "2025-11-30 06:22:56,760 - INFO - Set execution prefix for DummyDataLoading_calibration\n",
      "2025-11-30 06:22:56,761 - INFO - Initialized builder for step DummyDataLoading_calibration using StepCatalog\n",
      "2025-11-30 06:22:56,761 - INFO - Successfully loaded builder class using base name 'TabularPreprocessing' for 'TabularPreprocessing_calibration': TabularPreprocessingStepBuilder\n",
      "2025-11-30 06:22:56,761 - INFO - Using unified TABULAR_PREPROCESSING_SPEC for all job types\n",
      "2025-11-30 06:22:56,762 - INFO - Initializing TabularPreprocessingStepBuilder with region: NA\n",
      "2025-11-30 06:22:56,762 - INFO - Set execution prefix for TabularPreprocessing_calibration\n",
      "2025-11-30 06:22:56,762 - INFO - Initialized builder for step TabularPreprocessing_calibration using StepCatalog\n",
      "2025-11-30 06:22:56,763 - INFO - Successfully loaded builder class using base name 'PyTorchModelEval' for 'PyTorchModelEval_calibration': PyTorchModelEvalStepBuilder\n",
      "2025-11-30 06:22:56,763 - INFO - Initializing PyTorchModelEvalStepBuilder with region: NA\n",
      "2025-11-30 06:22:56,763 - INFO - Validating PyTorchModelEvalConfig...\n",
      "2025-11-30 06:22:56,764 - INFO - PyTorchModelEvalConfig validation succeeded.\n",
      "2025-11-30 06:22:56,764 - INFO - Set execution prefix for PyTorchModelEval_calibration\n",
      "2025-11-30 06:22:56,765 - INFO - Initialized builder for step PyTorchModelEval_calibration using StepCatalog\n",
      "2025-11-30 06:22:56,765 - INFO - Successfully loaded builder class using base name 'ModelCalibration' for 'ModelCalibration_calibration': ModelCalibrationStepBuilder\n",
      "2025-11-30 06:22:56,765 - INFO - Using unified MODEL_CALIBRATION_SPEC for all job types\n",
      "2025-11-30 06:22:56,766 - INFO - Initializing ModelCalibrationStepBuilder with region: NA\n",
      "2025-11-30 06:22:56,766 - INFO - Validating ModelCalibrationConfig...\n",
      "2025-11-30 06:22:56,766 - INFO - ModelCalibrationConfig validation succeeded.\n",
      "2025-11-30 06:22:56,767 - INFO - Set execution prefix for ModelCalibration_calibration\n",
      "2025-11-30 06:22:56,769 - INFO - Initialized builder for step ModelCalibration_calibration using StepCatalog\n",
      "2025-11-30 06:22:56,770 - INFO - Initializing PackageStepBuilder with region: NA\n",
      "2025-11-30 06:22:56,770 - INFO - Validating PackageConfig...\n",
      "2025-11-30 06:22:56,770 - INFO - PackageConfig validation succeeded.\n",
      "2025-11-30 06:22:56,771 - INFO - Set execution prefix for Package\n",
      "2025-11-30 06:22:56,771 - INFO - Initialized builder for step Package using StepCatalog\n",
      "2025-11-30 06:22:56,772 - INFO - Initializing PayloadStepBuilder with region: NA\n",
      "2025-11-30 06:22:56,772 - INFO - Validating PayloadConfig...\n",
      "2025-11-30 06:22:56,773 - INFO - PayloadConfig validation succeeded.\n",
      "2025-11-30 06:22:56,773 - INFO - Set execution prefix for Payload\n",
      "2025-11-30 06:22:56,773 - INFO - Initialized builder for step Payload using StepCatalog\n",
      "2025-11-30 06:22:56,774 - INFO - Initialized 7 step builders in 0.02 seconds\n",
      "2025-11-30 06:22:56,774 - INFO - Generating pipeline: lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline\n",
      "2025-11-30 06:22:56,775 - INFO - Initializing step connections using specifications\n",
      "2025-11-30 06:22:56,776 - INFO - Matched TabularPreprocessing_calibration.DATA to DummyDataLoading_calibration.DATA (score: 1.00)\n",
      "2025-11-30 06:22:56,777 - INFO - Matched TabularPreprocessing_calibration.SIGNATURE to DummyDataLoading_calibration.SIGNATURE (score: 1.00)\n",
      "2025-11-30 06:22:56,777 - INFO - Matched PyTorchModelEval_calibration.model_input to DummyTraining.model_output (score: 1.00)\n",
      "2025-11-30 06:22:56,778 - INFO - Matched PyTorchModelEval_calibration.processed_data to TabularPreprocessing_calibration.processed_data (score: 1.00)\n",
      "2025-11-30 06:22:56,779 - INFO - Matched ModelCalibration_calibration.evaluation_data to PyTorchModelEval_calibration.eval_output (score: 1.00)\n",
      "2025-11-30 06:22:56,785 - INFO - Matched Package.calibration_model to ModelCalibration_calibration.calibration_output (score: 1.00)\n",
      "2025-11-30 06:22:56,787 - INFO - Matched Package.model_input to DummyTraining.model_output (score: 0.92)\n",
      "2025-11-30 06:22:56,787 - INFO - Matched Payload.model_input to DummyTraining.model_output (score: 1.00)\n",
      "2025-11-30 06:22:56,788 - INFO - Build order: ['DummyTraining', 'DummyDataLoading_calibration', 'Payload', 'TabularPreprocessing_calibration', 'PyTorchModelEval_calibration', 'ModelCalibration_calibration', 'Package']\n",
      "2025-11-30 06:22:56,788 - INFO - Using execution_prefix for base output path\n",
      "2025-11-30 06:22:56,852 - INFO - [Tier 1 - Config] Using pretrained_model_path: s3://buyer-seller-messaging-reversal/pipeline/lukexie-BuyerAbuseRnR-pytorch-NA/20251128070034/pytorch_training/pipelines-stiuq2fnydgp-PyTorchTraining-xXHG9pkuK0/output/model.tar.gz\n",
      "2025-11-30 06:22:56,853 - INFO - [SOURCE Fallback] No hyperparameters input - using code directory or source_dir/hyperparams/\n",
      "2025-11-30 06:22:56,853 - INFO - Using execution_prefix for base output path\n",
      "2025-11-30 06:22:56,853 - INFO - Processing PipelineVariable for output_path: {...}\n",
      "2025-11-30 06:22:56,854 - INFO - No command-line arguments needed for dummy training script\n",
      "2025-11-30 06:22:56,854 - INFO - Using resolved script path: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts/dummy_training.py\n",
      "2025-11-30 06:22:56,855 - INFO - Using entry point: dummy_training.py\n",
      "2025-11-30 06:22:56,855 - INFO - Using source directory: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n",
      "2025-11-30 06:22:56,856 - INFO - Built step DummyTraining\n",
      "2025-11-30 06:22:56,857 - INFO - Using execution_prefix for base output path\n",
      "2025-11-30 06:22:56,857 - INFO - Creating Dummy Data Loading ProcessingStep...\n",
      "2025-11-30 06:22:56,858 - INFO - Added configuration environment variables: {...}\n",
      "2025-11-30 06:22:56,859 - INFO - Final dummy data loading environment variables: {...}\n",
      "2025-11-30 06:22:56,860 - INFO - Defaulting to only available Python version: py3\n",
      "2025-11-30 06:22:56,879 - INFO - Using user-provided data source from configuration: s3://buyer-seller-messaging-reversal/pipeline/lukexie-BuyerAbuseRnR-pytorch-NA/20251111035543/labelrulesetexecution/processed_data/test -> /opt/ml/processing/input/data\n",
      "2025-11-30 06:22:56,880 - INFO - No command-line arguments needed for dummy data loading script\n",
      "2025-11-30 06:22:56,880 - INFO - Using script path: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts/dummy_data_loading.py\n",
      "2025-11-30 06:22:56,881 - INFO - Created ProcessingStep with name: DummyDataLoading-Calibration\n",
      "2025-11-30 06:22:56,881 - INFO - Built step DummyDataLoading_calibration\n",
      "2025-11-30 06:22:56,882 - INFO - Using execution_prefix for base output path\n",
      "2025-11-30 06:22:56,882 - INFO - Creating MIMS Payload ProcessingStep...\n",
      "2025-11-30 06:22:56,883 - INFO - Registered specification for step 'PayloadStepStep' of type 'Payload' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,883 - INFO - Registered specification for step 'DummyTraining' of type 'DummyTraining' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,884 - INFO - Best match for model_input: DummyTraining.model_output (confidence: 1.000)\n",
      "2025-11-30 06:22:56,884 - INFO - Resolved PayloadStepStep.model_input -> DummyTraining.model_output\n",
      "2025-11-30 06:22:56,884 - INFO - Optional dependency not resolved: PayloadStepStep.custom_payload_input\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a real number is required, not str\n",
      "Call stack:\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2974, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3029, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3256, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3472, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_5757/1821125981.py\", line 4, in <cell line: 2>\n",
      "    template_pipeline, report = dag_compiler.compile_with_report(\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/core/compiler/dag_compiler.py\", line 469, in compile_with_report\n",
      "    pipeline = self.compile(dag, pipeline_name=pipeline_name, **kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/core/compiler/dag_compiler.py\", line 420, in compile\n",
      "    pipeline = cast(SageMakerPipeline, template.generate_pipeline())\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/core/assembler/pipeline_template_base.py\", line 330, in generate_pipeline\n",
      "    pipeline = template.generate_pipeline(pipeline_name)\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/core/assembler/pipeline_assembler.py\", line 527, in generate_pipeline\n",
      "    step = self._instantiate_step(step_name)\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/core/assembler/pipeline_assembler.py\", line 435, in _instantiate_step\n",
      "    step = builder.create_step(**kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/steps/builders/builder_payload_step.py\", line 371, in create_step\n",
      "    processor = self._create_processor()\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/steps/builders/builder_payload_step.py\", line 137, in _create_processor\n",
      "    env=self._get_environment_variables(),\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/steps/builders/builder_payload_step.py\", line 173, in _get_environment_variables\n",
      "    self.log_info(\n",
      "  File \"/home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus/core/base/builder_base.py\", line 498, in log_info\n",
      "    logger.info(message, *safe_args)\n",
      "Message: 'Added FIELD_DEFAULTS for %d fields'\n",
      "Arguments: ('2',)\n",
      "2025-11-30 06:22:56,890 - INFO - Payload environment variables configured\n",
      "2025-11-30 06:22:56,891 - INFO - Defaulting to only available Python version: py3\n",
      "2025-11-30 06:22:56,911 - INFO - No command-line arguments needed for payload script\n",
      "2025-11-30 06:22:56,912 - INFO - Using script path: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts/payload.py\n",
      "2025-11-30 06:22:56,912 - INFO - Created ProcessingStep with name: Payload\n",
      "2025-11-30 06:22:56,913 - INFO - Built step Payload\n",
      "2025-11-30 06:22:56,913 - INFO - Using execution_prefix for base output path\n",
      "2025-11-30 06:22:56,913 - INFO - Registered specification for step 'TabularPreprocessingStepStep' of type 'TabularPreprocessing' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,914 - INFO - Registered specification for step 'DummyDataLoading-Calibration' of type 'DummyDataLoading' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,915 - INFO - Best match for DATA: DummyDataLoading-Calibration.DATA (confidence: 1.000)\n",
      "2025-11-30 06:22:56,915 - INFO - Resolved TabularPreprocessingStepStep.DATA -> DummyDataLoading-Calibration.DATA\n",
      "2025-11-30 06:22:56,916 - INFO - Best match for SIGNATURE: DummyDataLoading-Calibration.SIGNATURE (confidence: 1.000)\n",
      "2025-11-30 06:22:56,916 - INFO - Resolved TabularPreprocessingStepStep.SIGNATURE -> DummyDataLoading-Calibration.SIGNATURE\n",
      "2025-11-30 06:22:56,918 - INFO - Defaulting to only available Python version: py3\n",
      "2025-11-30 06:22:56,938 - INFO - Setting job_type argument to: calibration\n",
      "2025-11-30 06:22:56,939 - INFO - Using script path: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts/tabular_preprocessing.py\n",
      "2025-11-30 06:22:56,939 - INFO - Built step TabularPreprocessing_calibration\n",
      "2025-11-30 06:22:56,940 - INFO - Using execution_prefix for base output path\n",
      "2025-11-30 06:22:56,941 - INFO - Creating PyTorchModelEval ProcessingStep...\n",
      "2025-11-30 06:22:56,941 - INFO - Registered specification for step 'PyTorchModelEvalStepStep' of type 'PyTorchModelEval' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,941 - INFO - Registered specification for step 'DummyTraining' of type 'DummyTraining' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,942 - INFO - Registered specification for step 'TabularPreprocessing-Calibration' of type 'TabularPreprocessing' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,943 - INFO - Best match for model_input: DummyTraining.model_output (confidence: 1.000)\n",
      "2025-11-30 06:22:56,943 - INFO - Resolved PyTorchModelEvalStepStep.model_input -> DummyTraining.model_output\n",
      "2025-11-30 06:22:56,944 - INFO - Best match for processed_data: TabularPreprocessing-Calibration.processed_data (confidence: 1.000)\n",
      "2025-11-30 06:22:56,944 - INFO - Resolved PyTorchModelEvalStepStep.processed_data -> TabularPreprocessing-Calibration.processed_data\n",
      "2025-11-30 06:22:56,945 - WARNING - Required environment variable 'ID_FIELD' not found in config\n",
      "2025-11-30 06:22:56,946 - WARNING - Required environment variable 'LABEL_FIELD' not found in config\n",
      "2025-11-30 06:22:56,946 - INFO - PyTorch evaluation environment variables: {...}\n",
      "2025-11-30 06:22:56,952 - INFO - image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "2025-11-30 06:22:56,973 - INFO - Setting job_type argument to: calibration\n",
      "2025-11-30 06:22:56,974 - INFO - Using resolved script path: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/pytorch_model_eval.py\n",
      "2025-11-30 06:22:56,974 - INFO - Using entry point: pytorch_model_eval.py\n",
      "2025-11-30 06:22:56,974 - INFO - Using source directory: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:56,975 - INFO - Created ProcessingStep with name: PyTorchModelEval-Calibration\n",
      "2025-11-30 06:22:56,975 - INFO - Built step PyTorchModelEval_calibration\n",
      "2025-11-30 06:22:56,976 - INFO - Using execution_prefix for base output path\n",
      "2025-11-30 06:22:56,976 - INFO - Creating ModelCalibration ProcessingStep...\n",
      "2025-11-30 06:22:56,976 - INFO - Registered specification for step 'ModelCalibrationStepStep' of type 'ModelCalibration' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,977 - INFO - Registered specification for step 'PyTorchModelEval-Calibration' of type 'PyTorchModelEval' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:56,978 - INFO - Best match for evaluation_data: PyTorchModelEval-Calibration.eval_output (confidence: 1.000)\n",
      "2025-11-30 06:22:56,979 - INFO - Resolved ModelCalibrationStepStep.evaluation_data -> PyTorchModelEval-Calibration.eval_output\n",
      "2025-11-30 06:22:56,980 - INFO - Defaulting to only available Python version: py3\n",
      "2025-11-30 06:22:57,236 - INFO - Setting job_type argument to: calibration\n",
      "2025-11-30 06:22:57,237 - INFO - Using script path: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts/model_calibration.py\n",
      "2025-11-30 06:22:57,238 - INFO - Created ProcessingStep with name: ModelCalibration-Calibration\n",
      "2025-11-30 06:22:57,238 - INFO - Built step ModelCalibration_calibration\n",
      "2025-11-30 06:22:57,238 - INFO - Using execution_prefix for base output path\n",
      "2025-11-30 06:22:57,239 - INFO - Creating Packaging ProcessingStep...\n",
      "2025-11-30 06:22:57,239 - INFO - Registered specification for step 'PackageStepStep' of type 'Package' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:57,240 - INFO - Registered specification for step 'ModelCalibration-Calibration' of type 'ModelCalibration' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:57,240 - INFO - Registered specification for step 'DummyTraining' of type 'DummyTraining' in context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:57,241 - INFO - Best match for model_input: DummyTraining.model_output (confidence: 0.920)\n",
      "2025-11-30 06:22:57,241 - INFO - Resolved PackageStepStep.model_input -> DummyTraining.model_output\n",
      "2025-11-30 06:22:57,241 - INFO - Optional dependency not resolved: PackageStepStep.inference_scripts_input\n",
      "2025-11-30 06:22:57,247 - INFO - Best match for calibration_model: ModelCalibration-Calibration.calibration_output (confidence: 1.000)\n",
      "2025-11-30 06:22:57,247 - INFO - Resolved PackageStepStep.calibration_model -> ModelCalibration-Calibration.calibration_output\n",
      "2025-11-30 06:22:57,248 - INFO - Packaging environment variables: {...}\n",
      "2025-11-30 06:22:57,250 - INFO - Defaulting to only available Python version: py3\n",
      "2025-11-30 06:22:57,269 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:57,270 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:57,270 - INFO - Using source dir: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:57,270 - INFO - [PACKAGING INPUT OVERRIDE] Using local inference scripts path from configuration: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:57,271 - INFO - [PACKAGING INPUT OVERRIDE] This local path will be used regardless of any dependency-resolved values\n",
      "2025-11-30 06:22:57,271 - INFO - Added inference scripts input with local path: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker -> /opt/ml/processing/input/script\n",
      "2025-11-30 06:22:57,271 - INFO - No command-line arguments needed for packaging script\n",
      "2025-11-30 06:22:57,272 - INFO - Using script path: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts/package.py\n",
      "2025-11-30 06:22:57,273 - INFO - Created ProcessingStep with name: Package\n",
      "2025-11-30 06:22:57,273 - INFO - Built step Package\n",
      "2025-11-30 06:22:57,278 - INFO - Generated pipeline lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline with 7 steps in 0.50 seconds\n",
      "2025-11-30 06:22:57,279 - INFO - Stored 7 step instances\n",
      "2025-11-30 06:22:57,279 - INFO - Pipeline name 'lukexie-BuyerAbuseRnR-pytorch-NA-0.0.2-pipeline' sanitized to 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' to conform to SageMaker constraints\n",
      "2025-11-30 06:22:57,280 - INFO - Successfully compiled DAG to pipeline: lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline\n",
      "2025-11-30 06:22:57,280 - INFO - Previewing resolution for 7 DAG nodes\n",
      "2025-11-30 06:22:57,281 - INFO - Creating template for DAG with 7 nodes\n",
      "2025-11-30 06:22:57,281 - INFO - Loading configs from: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:57,281 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:57,282 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:57,282 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2025-11-30 06:22:57,283 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:57,283 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:57,284 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/cursus\n",
      "2025-11-30 06:22:57,284 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2025-11-30 06:22:57,284 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2025-11-30 06:22:57,285 - INFO - âœ… Registry info loaded: 43 steps\n",
      "2025-11-30 06:22:57,285 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n",
      "2025-11-30 06:22:57,285 - INFO - Successfully discovered 76 config classes using step catalog\n",
      "2025-11-30 06:22:57,286 - INFO - Loading configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:57,287 - INFO - Loading configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:57,288 - INFO - Successfully loaded configuration from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:57,288 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json with 7 specific configs\n",
      "2025-11-30 06:22:57,289 - INFO - Creating additional config instance for DummyDataLoading_calibration (DummyDataLoadingConfig)\n",
      "2025-11-30 06:22:57,289 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,290 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,291 - INFO - Creating additional config instance for DummyTraining (DummyTrainingConfig)\n",
      "2025-11-30 06:22:57,291 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,292 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,292 - INFO - Creating additional config instance for ModelCalibration_calibration (ModelCalibrationConfig)\n",
      "2025-11-30 06:22:57,293 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,293 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,294 - INFO - Creating additional config instance for Package (PackageConfig)\n",
      "2025-11-30 06:22:57,294 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,295 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,295 - INFO - Creating additional config instance for Payload (PayloadConfig)\n",
      "2025-11-30 06:22:57,296 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,296 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,297 - INFO - Creating additional config instance for PyTorchModelEval_calibration (PyTorchModelEvalConfig)\n",
      "2025-11-30 06:22:57,298 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:57,298 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker\n",
      "2025-11-30 06:22:57,298 - INFO - Creating additional config instance for TabularPreprocessing_calibration (TabularPreprocessingConfig)\n",
      "2025-11-30 06:22:57,299 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,300 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts\n",
      "2025-11-30 06:22:57,300 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:57,301 - INFO - Loaded raw configuration data from /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/pipeline_config/config.json\n",
      "2025-11-30 06:22:57,301 - INFO - Initialized registry manager with workspace context: None\n",
      "2025-11-30 06:22:57,302 - INFO - Created specification registry for context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:57,302 - INFO - Created new workspace-aware registry for context 'lukexie-BuyerAbuseRnR-pytorch-NA'\n",
      "2025-11-30 06:22:57,303 - INFO - Created registry manager for context: lukexie-BuyerAbuseRnR-pytorch-NA\n",
      "2025-11-30 06:22:57,303 - INFO - Created dependency resolver for context: lukexie-BuyerAbuseRnR-pytorch-NA\n",
      "2025-11-30 06:22:57,303 - INFO - Validating dynamic pipeline configuration\n",
      "2025-11-30 06:22:57,304 - INFO - Resolving 7 DAG nodes to configurations\n",
      "2025-11-30 06:22:57,304 - INFO - Using metadata from loaded configuration\n",
      "2025-11-30 06:22:57,304 - INFO - Found exact key match for node 'DummyTraining'\n",
      "2025-11-30 06:22:57,305 - INFO - Found exact key match for node 'DummyDataLoading_calibration'\n",
      "2025-11-30 06:22:57,305 - INFO - Found exact key match for node 'TabularPreprocessing_calibration'\n",
      "2025-11-30 06:22:57,305 - INFO - Found exact key match for node 'PyTorchModelEval_calibration'\n",
      "2025-11-30 06:22:57,306 - INFO - Found exact key match for node 'ModelCalibration_calibration'\n",
      "2025-11-30 06:22:57,306 - INFO - Found exact key match for node 'Package'\n",
      "2025-11-30 06:22:57,306 - INFO - Found exact key match for node 'Payload'\n",
      "2025-11-30 06:22:57,308 - INFO - Successfully resolved all 7 nodes\n",
      "2025-11-30 06:22:57,308 - INFO - Using 42 registered step builders from StepCatalog\n",
      "2025-11-30 06:22:57,309 - INFO - Successfully loaded builder class using base name 'DummyDataLoading' for 'DummyDataLoading_calibration': DummyDataLoadingStepBuilder\n",
      "2025-11-30 06:22:57,309 - INFO - Successfully loaded builder class using base name 'TabularPreprocessing' for 'TabularPreprocessing_calibration': TabularPreprocessingStepBuilder\n",
      "2025-11-30 06:22:57,310 - INFO - Successfully loaded builder class using base name 'PyTorchModelEval' for 'PyTorchModelEval_calibration': PyTorchModelEvalStepBuilder\n",
      "2025-11-30 06:22:57,310 - INFO - Successfully loaded builder class using base name 'ModelCalibration' for 'ModelCalibration_calibration': ModelCalibrationStepBuilder\n",
      "2025-11-30 06:22:57,310 - INFO - Configuration validation passed successfully\n",
      "2025-11-30 06:22:57,311 - INFO - Pipeline name 'lukexie-BuyerAbuseRnR-pytorch-NA-0.0.2-pipeline' sanitized to 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' to conform to SageMaker constraints\n",
      "2025-11-30 06:22:57,311 - INFO - Initialized template for: lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline\n",
      "2025-11-30 06:22:57,311 - INFO - Successfully created template\n",
      "2025-11-30 06:22:57,312 - INFO - Using metadata.config_types mapping with 7 entries\n",
      "2025-11-30 06:22:57,312 - INFO - Found exact key match for node 'DummyTraining'\n",
      "2025-11-30 06:22:57,313 - INFO - Found exact key match for node 'DummyDataLoading_calibration'\n",
      "2025-11-30 06:22:57,313 - INFO - Found exact key match for node 'TabularPreprocessing_calibration'\n",
      "2025-11-30 06:22:57,313 - INFO - Found exact key match for node 'PyTorchModelEval_calibration'\n",
      "2025-11-30 06:22:57,314 - INFO - Found exact key match for node 'ModelCalibration_calibration'\n",
      "2025-11-30 06:22:57,314 - INFO - Found exact key match for node 'Package'\n",
      "2025-11-30 06:22:57,314 - INFO - Found exact key match for node 'Payload'\n",
      "2025-11-30 06:22:57,314 - ERROR - Failed to generate resolution preview: 0\n",
      "2025-11-30 06:22:57,315 - INFO - Compilation completed with report: Pipeline 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' created successfully with 7 steps (avg confidence: 0.00)\n",
      "2025-11-30 06:22:57,315 - INFO - Conversion complete: Pipeline 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' created successfully with 7 steps (avg confidence: 0.00)\n",
      "2025-11-30 06:22:57,316 - INFO - Pipeline 'lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline' created successfully\n",
      "2025-11-30 06:22:57,316 - INFO - Pipeline ARN: Not available until upserted\n",
      "2025-11-30 06:22:57,316 - INFO - To upsert the pipeline, call pipeline.upsert()\n"
     ]
    }
   ],
   "source": [
    "# Convert DAG to pipeline and get report\n",
    "try:\n",
    "    logger.info(f\"Converting DAG to pipeline\")\n",
    "    template_pipeline, report = dag_compiler.compile_with_report(\n",
    "        dag=dag\n",
    "    )\n",
    "        \n",
    "    # Log report summary\n",
    "    logger.info(f\"Conversion complete: {report.summary()}\")\n",
    "    for node, details in report.resolution_details.items():\n",
    "        logger.info(f\"  {node} â†’ {details['config_type']} ({details['builder_type']})\")\n",
    "        \n",
    "    # Log pipeline creation details\n",
    "    logger.info(f\"Pipeline '{template_pipeline.name}' created successfully\")\n",
    "    logger.info(f\"Pipeline ARN: {template_pipeline.arn if hasattr(template_pipeline, 'arn') else 'Not available until upserted'}\")\n",
    "    logger.info(\"To upsert the pipeline, call pipeline.upsert()\")       \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to convert DAG to pipeline: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee855a-7a10-43e2-aa69-a26ec7bc3fc7",
   "metadata": {},
   "source": [
    "### Pipeline Template\n",
    "\n",
    "After the pipeline is generated, we can retrieve the pipeline template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b24ae2b-ad4f-40db-9389-d405d80e6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_template_builder = dag_compiler.get_last_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152c1e2-f1d4-458b-83d9-6437fc7c2e75",
   "metadata": {},
   "source": [
    "## Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0448dafe-595c-4c14-80d5-260cbe6abac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::178936618742:role/AmazonSageMaker-ExecutionRole-Default'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role_arn = pipeline_session.get_caller_identity_arn()\n",
    "role_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c473d23-c3e0-475a-8e72-74fb89b3be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_description=PIPELINE_DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e406ca9-6452-4730-9997-e09c21f2baa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BuyerAbuseRnR pytorch Model NA'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPELINE_DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1ab84-5565-4950-848c-cd5f70fe7b99",
   "metadata": {},
   "source": [
    "### Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5436920-9867-4d17-b670-88b4361da282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:22:57,401 - INFO - SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "2025-11-30 06:22:57,814 - INFO - Uploaded /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts to s3://buyer-seller-messaging-reversal/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline/code/1ab2be6de97597c80d219d20eb33001aa781ae46fd39e85d51a7d69fd249e405/sourcedir.tar.gz\n",
      "2025-11-30 06:22:57,874 - INFO - runproc.sh uploaded to s3://buyer-seller-messaging-reversal/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline/code/98f6fa33c1a36beaee98b312e63ec04cef74b2ac27e39d60b70e8a5cbfb87f71/runproc.sh\n",
      "2025-11-30 06:22:57,876 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:22:57,944 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:22:57,994 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:22:58,036 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:22:58,429 - INFO - Uploaded /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker to s3://buyer-seller-messaging-reversal/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline/code/ad7ab05591c9a3fdaf1cb8bc431f450b3bd9c5a18505dc83fcfa13635cb3cef1/sourcedir.tar.gz\n",
      "2025-11-30 06:22:58,473 - INFO - runproc.sh uploaded to s3://buyer-seller-messaging-reversal/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline/code/602671d92c7eb805628d3775bd01f73cd3ef79558330597dcfd540091de6e14b/runproc.sh\n",
      "2025-11-30 06:22:58,474 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:22:58,532 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:23:05,010 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:23:05,505 - INFO - Uploaded /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker/scripts to s3://buyer-seller-messaging-reversal/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline/code/1ab2be6de97597c80d219d20eb33001aa781ae46fd39e85d51a7d69fd249e405/sourcedir.tar.gz\n",
      "2025-11-30 06:23:05,572 - INFO - runproc.sh uploaded to s3://buyer-seller-messaging-reversal/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline/code/98f6fa33c1a36beaee98b312e63ec04cef74b2ac27e39d60b70e8a5cbfb87f71/runproc.sh\n",
      "2025-11-30 06:23:05,573 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:23:05,626 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:23:05,677 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:23:05,725 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:23:06,122 - INFO - Uploaded /home/ec2-user/SageMaker/AmazonSageMaker-lukexie-sagemaker-bsm-repo/pipelines/rnr_pytorch_bedrock/docker to s3://buyer-seller-messaging-reversal/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline/code/ad7ab05591c9a3fdaf1cb8bc431f450b3bd9c5a18505dc83fcfa13635cb3cef1/sourcedir.tar.gz\n",
      "2025-11-30 06:23:06,182 - INFO - runproc.sh uploaded to s3://buyer-seller-messaging-reversal/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline/code/602671d92c7eb805628d3775bd01f73cd3ef79558330597dcfd540091de6e14b/runproc.sh\n",
      "2025-11-30 06:23:06,183 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:23:06,231 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-11-30 06:23:06,320 - WARNING - Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:178936618742:pipeline/lukexie-BuyerAbuseRnR-pytorch-NA-0-0-2-pipeline',\n",
       " 'PipelineVersionId': 10,\n",
       " 'ResponseMetadata': {'RequestId': '5dfca02b-149d-4b3d-a112-c9bb55a13f79',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5dfca02b-149d-4b3d-a112-c9bb55a13f79',\n",
       "   'strict-transport-security': 'max-age=47304000; includeSubDomains',\n",
       "   'x-frame-options': 'DENY',\n",
       "   'content-security-policy': \"frame-ancestors 'none'\",\n",
       "   'cache-control': 'no-cache, no-store, must-revalidate',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '138',\n",
       "   'date': 'Sun, 30 Nov 2025 06:23:06 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_pipeline.upsert(\n",
    "                role_arn=role_arn, description=pipeline_description\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc41fc",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41ba2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_execution_parameters={\n",
    "    \"EXECUTION_S3_PREFIX\": f\"s3://{bucket_name}/pipeline/{PIPELINE_NAME}/{execution_id}\",\n",
    "    \"KMS_ENCRYPTION_KEY_PARAM\": kms_key_id,\n",
    "    \"VPC_SUBNET\": vpc_subnet_id,\n",
    "    \"SECURITY_GROUP_ID\": security_group_id,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30a156f0-b19e-4791-9160-38dc3c9209a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 06:23:06,585 - INFO - SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n"
     ]
    }
   ],
   "source": [
    "pipeline_execution = template_pipeline.start(\n",
    "                parameters=pipeline_execution_parameters\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50734c8a-50a7-4ed7-a431-67945560e51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91899306-eaae-4d7e-a2fc-702162e43a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506b412-34c9-426b-a8fa-16f3793404c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Pipeline Configuration with DAGConfigFactory\n",
    "\n",
    "This notebook demonstrates the new interactive approach to pipeline configuration using the DAGConfigFactory.\n",
    "Instead of manually creating 500+ lines of static configuration, we use a guided step-by-step process.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Define Pipeline DAG** - Create the pipeline structure\n",
    "2. **Initialize DAGConfigFactory** - Set up the interactive factory\n",
    "3. **Configure Base Settings** - Set shared pipeline configuration\n",
    "4. **Configure Processing Settings** - Set shared processing configuration\n",
    "5. **Configure Individual Steps** - Set step-specific configurations\n",
    "6. **Generate Final Configurations** - Create config instances\n",
    "7. **Save to JSON** - Export unified configuration file\n",
    "\n",
    "![mods_pipeline_train_eval_calib](./tutorials/mods_end_to_end_xgboost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project root /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template\n",
      "add project root /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template into system\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date\n",
    "import logging\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Get parent directory of current notebook\n",
    "project_root = str(Path().absolute().parent)\n",
    "print(f\"project root {project_root}\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"add project root {project_root} into system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 00:00:49,795 - INFO - Note: NumExpr detected 48 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2026-01-08 00:00:49,796 - INFO - NumExpr defaulting to 8 threads.\n",
      "2026-01-08 00:00:50,995 - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# SageMaker and SAIS imports\n",
    "from sagemaker import Session\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 00:00:52,343 - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: arn:aws:iam::601857636239:role/SandboxRole-lukexie-us-east-1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Role: {PipelineSession().get_caller_identity_arn()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sandboxdependency-abuse-secureaisandboxteamshare-1l77v9am252um\n"
     ]
    }
   ],
   "source": [
    "bucket = \"sandboxdependency-abuse-secureaisandboxteamshare-1l77v9am252um\"  # \"buyer-seller-messaging-reversal\"\n",
    "print(f\"Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Pipeline DAG\n",
    "\n",
    "First, we define the pipeline structure using a DAG (Directed Acyclic Graph).\n",
    "This replaces the hardcoded pipeline structure from the legacy approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 00:00:55,950 - WARNING - Could not import constants from mods_workflow_core, using local definitions\n",
      "2026-01-08 00:00:56,325 - WARNING - CradleDataLoadingStepBuilder not available. This requires secure_ai_sandbox_workflow_python_sdk package. Import error: No module named 'secure_ai_sandbox_workflow_python_sdk'\n",
      "2026-01-08 00:00:56,350 - WARNING - RegistrationStepBuilder not available. This requires secure_ai_sandbox_workflow_python_sdk package. Import error: No module named 'secure_ai_sandbox_workflow_python_sdk'\n",
      "2026-01-08 00:00:56,391 - INFO - Added node: CradleDataLoading_training\n",
      "2026-01-08 00:00:56,392 - INFO - Added node: TabularPreprocessing_training\n",
      "2026-01-08 00:00:56,392 - INFO - Added node: TokenizerTraining_training\n",
      "2026-01-08 00:00:56,392 - INFO - Added node: PyTorchTraining\n",
      "2026-01-08 00:00:56,393 - INFO - Added node: CradleDataLoading_calibration\n",
      "2026-01-08 00:00:56,393 - INFO - Added node: TabularPreprocessing_calibration\n",
      "2026-01-08 00:00:56,393 - INFO - Added node: PyTorchModelEval_calibration\n",
      "2026-01-08 00:00:56,393 - INFO - Added node: PercentileModelCalibration_calibration\n",
      "2026-01-08 00:00:56,393 - INFO - Added node: Package\n",
      "2026-01-08 00:00:56,394 - INFO - Added node: Registration\n",
      "2026-01-08 00:00:56,394 - INFO - Added node: Payload\n",
      "2026-01-08 00:00:56,395 - INFO - Added edge: CradleDataLoading_training -> TabularPreprocessing_training\n",
      "2026-01-08 00:00:56,395 - INFO - Added edge: TabularPreprocessing_training -> TokenizerTraining_training\n",
      "2026-01-08 00:00:56,395 - INFO - Added edge: TokenizerTraining_training -> PyTorchTraining\n",
      "2026-01-08 00:00:56,396 - INFO - Added edge: TabularPreprocessing_training -> PyTorchTraining\n",
      "2026-01-08 00:00:56,396 - INFO - Added edge: CradleDataLoading_calibration -> TabularPreprocessing_calibration\n",
      "2026-01-08 00:00:56,396 - INFO - Added edge: PyTorchTraining -> PyTorchModelEval_calibration\n",
      "2026-01-08 00:00:56,396 - INFO - Added edge: TabularPreprocessing_calibration -> PyTorchModelEval_calibration\n",
      "2026-01-08 00:00:56,397 - INFO - Added edge: PyTorchModelEval_calibration -> PercentileModelCalibration_calibration\n",
      "2026-01-08 00:00:56,397 - INFO - Added edge: PercentileModelCalibration_calibration -> Package\n",
      "2026-01-08 00:00:56,397 - INFO - Added edge: PyTorchTraining -> Package\n",
      "2026-01-08 00:00:56,397 - INFO - Added edge: PyTorchTraining -> Payload\n",
      "2026-01-08 00:00:56,397 - INFO - Added edge: Package -> Registration\n",
      "2026-01-08 00:00:56,398 - INFO - Added edge: Payload -> Registration\n",
      "2026-01-08 00:00:56,399 - INFO - Created XGBoost E2E DAG with 11 nodes and 13 edges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline DAG created with 11 steps:\n",
      "  - CradleDataLoading_training\n",
      "  - TabularPreprocessing_training\n",
      "  - TokenizerTraining_training\n",
      "  - PyTorchTraining\n",
      "  - CradleDataLoading_calibration\n",
      "  - TabularPreprocessing_calibration\n",
      "  - PyTorchModelEval_calibration\n",
      "  - PercentileModelCalibration_calibration\n",
      "  - Package\n",
      "  - Registration\n",
      "  - Payload\n"
     ]
    }
   ],
   "source": [
    "from cursus.api.dag.base_dag import PipelineDAG\n",
    "\n",
    "\n",
    "def create_pytorch_e2e_training_dag() -> PipelineDAG:\n",
    "    \"\"\"\n",
    "    Create a complete end-to-end XGBoost pipeline DAG.\n",
    "\n",
    "    This DAG represents the same workflow as the legacy demo_config.ipynb\n",
    "    but in a structured, reusable format.\n",
    "\n",
    "    Returns:\n",
    "        PipelineDAG: The directed acyclic graph for the pipeline\n",
    "    \"\"\"\n",
    "    dag = PipelineDAG()\n",
    "\n",
    "    # Add all nodes - matching the structure from demo_config.ipynb\n",
    "    dag.add_node(\"CradleDataLoading_training\")  # Training data loading\n",
    "    dag.add_node(\"TabularPreprocessing_training\")  # Training data preprocessing\n",
    "    dag.add_node(\"TokenizerTraining_training\")  # Customized Tokenizer training\n",
    "    dag.add_node(\"PyTorchTraining\")  # XGBoost model training\n",
    "\n",
    "    dag.add_node(\"CradleDataLoading_calibration\")  # Dummy data load for calibration\n",
    "    dag.add_node(\n",
    "        \"TabularPreprocessing_calibration\"\n",
    "    )  # Tabular preprocessing for calibration\n",
    "    dag.add_node(\"PyTorchModelEval_calibration\")  # Model evaluation step\n",
    "    dag.add_node(\n",
    "        \"PercentileModelCalibration_calibration\"\n",
    "    )  # Model calibration step with calibration variant\n",
    "    dag.add_node(\"Package\")  # Package step\n",
    "    dag.add_node(\"Registration\")  # MIMS registration step\n",
    "    dag.add_node(\"Payload\")  # Payload step\n",
    "\n",
    "    # Define dependencies - training flow\n",
    "    dag.add_edge(\"CradleDataLoading_training\", \"TabularPreprocessing_training\")\n",
    "    dag.add_edge(\"TabularPreprocessing_training\", \"TokenizerTraining_training\")\n",
    "    dag.add_edge(\"TokenizerTraining_training\", \"PyTorchTraining\")\n",
    "    dag.add_edge(\"TabularPreprocessing_training\", \"PyTorchTraining\")\n",
    "\n",
    "    # Calibration flow with Bedrock batch processing and label ruleset integration\n",
    "    dag.add_edge(\"CradleDataLoading_calibration\", \"TabularPreprocessing_calibration\")\n",
    "\n",
    "    # Evaluation flow\n",
    "    dag.add_edge(\"PyTorchTraining\", \"PyTorchModelEval_calibration\")\n",
    "    dag.add_edge(\n",
    "        \"TabularPreprocessing_calibration\", \"PyTorchModelEval_calibration\"\n",
    "    )  # Use labeled calibration data\n",
    "\n",
    "    # Model calibration flow - depends on model evaluation\n",
    "    dag.add_edge(\n",
    "        \"PyTorchModelEval_calibration\", \"PercentileModelCalibration_calibration\"\n",
    "    )\n",
    "\n",
    "    # Output flow\n",
    "    dag.add_edge(\"PercentileModelCalibration_calibration\", \"Package\")\n",
    "    dag.add_edge(\"PyTorchTraining\", \"Package\")  # Raw model is also input to packaging\n",
    "    dag.add_edge(\"PyTorchTraining\", \"Payload\")  # Raw model is also input to packaging\n",
    "    dag.add_edge(\"Package\", \"Registration\")\n",
    "    dag.add_edge(\"Payload\", \"Registration\")\n",
    "\n",
    "    logger.info(\n",
    "        f\"Created XGBoost E2E DAG with {len(dag.nodes)} nodes and {len(dag.edges)} edges\"\n",
    "    )\n",
    "    return dag\n",
    "\n",
    "\n",
    "# Create the pipeline DAG\n",
    "dag = create_pytorch_e2e_training_dag()\n",
    "\n",
    "print(f\"Pipeline DAG created with {len(dag.nodes)} steps:\")\n",
    "for node in dag.nodes:\n",
    "    print(f\"  - {node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize DAGConfigFactory\n",
    "\n",
    "Now we initialize the DAGConfigFactory with our DAG. This will automatically:\n",
    "- Map DAG nodes to configuration classes\n",
    "- Set up the interactive workflow\n",
    "- Prepare for step-by-step configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 00:01:02,846 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/cursus\n",
      "2026-01-08 00:01:02,847 - INFO - ðŸ”§ BuilderAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2026-01-08 00:01:02,847 - INFO - âœ… BuilderAutoDiscovery basic initialization complete\n",
      "2026-01-08 00:01:02,847 - INFO - âœ… Registry info loaded: 49 steps\n",
      "2026-01-08 00:01:02,848 - INFO - ðŸŽ‰ BuilderAutoDiscovery initialization completed successfully\n",
      "2026-01-08 00:01:02,848 - INFO - ðŸ” ScriptAutoDiscovery.__init__ starting - package_root: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/cursus\n",
      "2026-01-08 00:01:02,848 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - workspace_dirs: []\n",
      "2026-01-08 00:01:02,848 - INFO - ðŸ” ScriptAutoDiscovery.__init__ - priority_workspace_dir: None\n",
      "2026-01-08 00:01:02,849 - INFO - âœ… Registry info loaded: 49 steps\n",
      "2026-01-08 00:01:02,849 - INFO - ðŸŽ‰ ScriptAutoDiscovery initialization completed successfully\n",
      "2026-01-08 00:01:03,156 - INFO - Discovered 69 core config classes\n",
      "2026-01-08 00:01:03,164 - WARNING - Error importing hyperparameter class LSTM2RiskHyperparameters from /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/cursus/steps/hyperparams/hyperparameters_lstm2risk.py: No module named 'cursus.steps.hyperparams.hyperparameters_base'\n",
      "2026-01-08 00:01:03,171 - WARNING - Error importing hyperparameter class Transformer2RiskHyperparameters from /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/cursus/steps/hyperparams/hyperparameters_transformer2risk.py: No module named 'cursus.steps.hyperparams.hyperparameters_base'\n",
      "2026-01-08 00:01:03,178 - INFO - Discovered 7 core hyperparameter classes\n",
      "2026-01-08 00:01:03,197 - INFO - Discovered 7 base hyperparameter classes from core/base\n",
      "2026-01-08 00:01:03,198 - INFO - âœ… Mapped 'CradleDataLoading_training' -> 'CradleDataLoading' -> CradleDataLoadingConfig\n",
      "2026-01-08 00:01:03,198 - INFO - âœ… Mapped 'TabularPreprocessing_training' -> 'TabularPreprocessing' -> TabularPreprocessingConfig\n",
      "2026-01-08 00:01:03,198 - INFO - âœ… Mapped 'TokenizerTraining_training' -> 'TokenizerTraining' -> TokenizerTrainingConfig\n",
      "2026-01-08 00:01:03,198 - INFO - âœ… Mapped 'PyTorchTraining' -> 'PyTorchTraining' -> PyTorchTrainingConfig\n",
      "2026-01-08 00:01:03,199 - INFO - âœ… Mapped 'CradleDataLoading_calibration' -> 'CradleDataLoading' -> CradleDataLoadingConfig\n",
      "2026-01-08 00:01:03,199 - INFO - âœ… Mapped 'TabularPreprocessing_calibration' -> 'TabularPreprocessing' -> TabularPreprocessingConfig\n",
      "2026-01-08 00:01:03,199 - INFO - âœ… Mapped 'PyTorchModelEval_calibration' -> 'PyTorchModelEval' -> PyTorchModelEvalConfig\n",
      "2026-01-08 00:01:03,199 - INFO - âœ… Mapped 'PercentileModelCalibration_calibration' -> 'PercentileModelCalibration' -> PercentileModelCalibrationConfig\n",
      "2026-01-08 00:01:03,200 - INFO - âœ… Mapped 'Package' -> 'Package' -> PackageConfig\n",
      "2026-01-08 00:01:03,200 - INFO - âœ… Mapped 'Registration' -> 'Registration' -> RegistrationConfig\n",
      "2026-01-08 00:01:03,200 - INFO - âœ… Mapped 'Payload' -> 'Payload' -> PayloadConfig\n",
      "2026-01-08 00:01:03,200 - INFO - Successfully mapped 11/11 DAG nodes to config classes\n",
      "2026-01-08 00:01:03,201 - INFO - Initialized DAGConfigFactory for DAG with 11 steps using robust step detection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAG Node to Config Class Mapping:\n",
      "==================================================\n",
      "  CradleDataLoading_training          -> CradleDataLoadingConfig\n",
      "  TabularPreprocessing_training       -> TabularPreprocessingConfig\n",
      "  TokenizerTraining_training          -> TokenizerTrainingConfig\n",
      "  PyTorchTraining                     -> PyTorchTrainingConfig\n",
      "  CradleDataLoading_calibration       -> CradleDataLoadingConfig\n",
      "  TabularPreprocessing_calibration    -> TabularPreprocessingConfig\n",
      "  PyTorchModelEval_calibration        -> PyTorchModelEvalConfig\n",
      "  PercentileModelCalibration_calibration -> PercentileModelCalibrationConfig\n",
      "  Package                             -> PackageConfig\n",
      "  Registration                        -> RegistrationConfig\n",
      "  Payload                             -> PayloadConfig\n",
      "\n",
      "Successfully mapped 11 steps to configuration classes.\n"
     ]
    }
   ],
   "source": [
    "from cursus.api.factory.dag_config_factory import DAGConfigFactory\n",
    "\n",
    "# Initialize the factory with our DAG\n",
    "factory = DAGConfigFactory(dag)\n",
    "\n",
    "# Get the config class mapping\n",
    "config_map = factory.get_config_class_map()\n",
    "\n",
    "print(\"DAG Node to Config Class Mapping:\")\n",
    "print(\"=\" * 50)\n",
    "for node_name, config_class in config_map.items():\n",
    "    print(f\"  {node_name:<35} -> {config_class.__name__}\")\n",
    "\n",
    "print(f\"\\nSuccessfully mapped {len(config_map)} steps to configuration classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Base Pipeline Settings\n",
    "\n",
    "These settings are shared across ALL pipeline steps. Instead of repeating them\n",
    "in every step configuration, we set them once here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Pipeline Configuration Requirements:\n",
      "==================================================\n",
      "* author                    (str)\n",
      "    Author or owner of the pipeline.\n",
      "\n",
      "* bucket                    (str)\n",
      "    S3 bucket name for pipeline artifacts and data.\n",
      "\n",
      "* role                      (str)\n",
      "    IAM role for pipeline execution.\n",
      "\n",
      "* region                    (str)\n",
      "    Custom region code (NA, EU, FE) for internal logic.\n",
      "\n",
      "* service_name              (str)\n",
      "    Service name for the pipeline.\n",
      "\n",
      "* pipeline_version          (str)\n",
      "    Version string for the SageMaker Pipeline.\n",
      "\n",
      "  model_class               (str) (default: xgboost)\n",
      "    Model class (e.g., XGBoost, PyTorch).\n",
      "\n",
      "  current_date              (str) (default: PydanticUndefined)\n",
      "    Current date, typically used for versioning or pathing.\n",
      "\n",
      "  framework_version         (str) (default: 2.1.0)\n",
      "    Default framework version (e.g., PyTorch).\n",
      "\n",
      "  py_version                (str) (default: py310)\n",
      "    Default Python version.\n",
      "\n",
      "  source_dir                (Optional) (default: None)\n",
      "    Common source directory for scripts if applicable. Can be overridden by step configs.\n",
      "\n",
      "  enable_caching            (bool) (default: False)\n",
      "    Enable caching for pipeline steps.\n",
      "\n",
      "  use_secure_pypi           (bool) (default: False)\n",
      "    Use secure CodeArtifact PyPI instead of public PyPI for package installation in processing scripts.\n",
      "\n",
      "  max_runtime_seconds       (int) (default: 172800)\n",
      "    Maximum runtime for jobs in seconds. Default: 2 days (172800 seconds).\n",
      "\n",
      "* project_root_folder       (str)\n",
      "    Root folder name for the user's project (required for hybrid resolution)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get base configuration requirements\n",
    "base_requirements = factory.get_base_config_requirements()\n",
    "\n",
    "print(\"Base Pipeline Configuration Requirements:\")\n",
    "print(\"=\" * 50)\n",
    "for req in base_requirements:\n",
    "    marker = \"*\" if req[\"required\"] else \" \"\n",
    "    default_info = (\n",
    "        f\" (default: {req.get('default')})\"\n",
    "        if not req[\"required\"] and \"default\" in req\n",
    "        else \"\"\n",
    "    )\n",
    "    print(f\"{marker} {req['name']:<25} ({req['type']}){default_info}\")\n",
    "    print(f\"    {req['description']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 00:01:28,166 - INFO - Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "2026-01-08 00:01:28,319 - INFO - Base configuration set successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Base pipeline configuration set successfully!\n",
      "   Region: NA (us-east-1)\n",
      "   Service: Names3Risk\n",
      "   Author: lukexie\n",
      "   Pipeline Version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "# Set up basic configuration values\n",
    "region_list = [\"NA\", \"EU\", \"FE\"]\n",
    "region_selection = 0\n",
    "region = region_list[region_selection]\n",
    "\n",
    "# Map region to AWS region\n",
    "region_mapping = {\"NA\": \"us-east-1\", \"EU\": \"eu-west-1\", \"FE\": \"us-west-2\"}\n",
    "aws_region = region_mapping[region]\n",
    "\n",
    "service_name = \"Names3Risk\"\n",
    "pipeline_version = \"1.0.0\"\n",
    "author = \"lukexie\"\n",
    "model_class = \"pytorch\"\n",
    "\n",
    "# Get current directory and set up paths\n",
    "current_dir = Path.cwd()\n",
    "package_root = Path(current_dir).resolve()\n",
    "source_dir = Path(\"dockers\")\n",
    "project_root_folder = \"names3risk_pytorch\"\n",
    "\n",
    "# Set base configuration\n",
    "factory.set_base_config(\n",
    "    # Infrastructure settings\n",
    "    bucket=bucket,\n",
    "    role=PipelineSession().get_caller_identity_arn(),\n",
    "    region=region,\n",
    "    aws_region=aws_region,\n",
    "    # Project identification\n",
    "    author=author,\n",
    "    service_name=service_name,\n",
    "    pipeline_version=pipeline_version,\n",
    "    model_class=model_class,\n",
    "    # Framework settings\n",
    "    framework_version=\"2.1.0\",\n",
    "    py_version=\"py310\",\n",
    "    source_dir=str(source_dir),\n",
    "    project_root_folder=project_root_folder,\n",
    "    # Date settings\n",
    "    current_date=date.today().strftime(\"%Y-%m-%d\"),\n",
    "    # Enable Cache\n",
    "    enable_caching=False,\n",
    "    # Use Secure PyPI\n",
    "    use_secure_pypi=True,\n",
    ")\n",
    "\n",
    "print(\"âœ… Base pipeline configuration set successfully!\")\n",
    "print(f\"   Region: {region} ({aws_region})\")\n",
    "print(f\"   Service: {service_name}\")\n",
    "print(f\"   Author: {author}\")\n",
    "print(f\"   Pipeline Version: {pipeline_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Configure Base Processing Settings\n",
    "\n",
    "These settings are shared across all PROCESSING steps (data loading, preprocessing, etc.)\n",
    "but not training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Processing Configuration Requirements:\n",
      "==================================================\n",
      "  processing_instance_count      (int) (default: 1)\n",
      "    Instance count for processing jobs\n",
      "\n",
      "  processing_volume_size         (int) (default: 500)\n",
      "    Volume size for processing jobs in GB\n",
      "\n",
      "  processing_instance_type_large (str) (default: ml.m5.4xlarge)\n",
      "    Large instance type for processing step.\n",
      "\n",
      "  processing_instance_type_small (str) (default: ml.m5.2xlarge)\n",
      "    Small instance type for processing step.\n",
      "\n",
      "  use_large_processing_instance  (bool) (default: False)\n",
      "    Set to True to use large instance type, False for small instance type.\n",
      "\n",
      "  processing_source_dir          (Optional) (default: None)\n",
      "    Source directory for processing scripts. Falls back to base source_dir if not provided.\n",
      "\n",
      "  processing_entry_point         (Optional) (default: None)\n",
      "    Entry point script for processing, must be relative to source directory. Can be overridden by derived classes.\n",
      "\n",
      "  processing_script_arguments    (Optional) (default: None)\n",
      "    Optional arguments for the processing script.\n",
      "\n",
      "  processing_framework_version   (str) (default: 1.2-1)\n",
      "    Framework version for processing container. Format depends on framework: sklearn uses '<version>-<build>' (e.g., '1.2-1'), pytorch uses '<version>' (e.g., '2.6.0'). No validation performed - version is passed directly to SageMaker.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get base processing configuration requirements\n",
    "processing_requirements = factory.get_base_processing_config_requirements()\n",
    "\n",
    "if processing_requirements:\n",
    "    print(\"Base Processing Configuration Requirements:\")\n",
    "    print(\"=\" * 50)\n",
    "    for req in processing_requirements:\n",
    "        marker = \"*\" if req[\"required\"] else \" \"\n",
    "        default_info = (\n",
    "            f\" (default: {req.get('default')})\"\n",
    "            if not req[\"required\"] and \"default\" in req\n",
    "            else \"\"\n",
    "        )\n",
    "        print(f\"{marker} {req['name']:<30} ({req['type']}){default_info}\")\n",
    "        print(f\"    {req['description']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No base processing configuration required for this pipeline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 00:01:36,527 - INFO - Working directory discovery succeeded (direct): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/names3risk_pytorch/dockers\n",
      "2026-01-08 00:01:36,527 - INFO - Hybrid resolution completed successfully via Working Directory Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/names3risk_pytorch/dockers\n",
      "2026-01-08 00:01:36,527 - INFO - Base processing configuration set successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Base processing configuration set successfully!\n",
      "   Processing source: dockers/scripts\n"
     ]
    }
   ],
   "source": [
    "# Set base processing configuration if needed\n",
    "if processing_requirements:\n",
    "    processing_source_dir = source_dir / \"scripts\"\n",
    "\n",
    "    factory.set_base_processing_config(\n",
    "        # Processing infrastructure\n",
    "        processing_source_dir=str(processing_source_dir),\n",
    "        processing_instance_type_large=\"ml.m5.12xlarge\",\n",
    "        processing_instance_type_small=\"ml.m5.4xlarge\",\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Base processing configuration set successfully!\")\n",
    "    print(f\"   Processing source: {processing_source_dir}\")\n",
    "else:\n",
    "    print(\"âœ… No base processing configuration needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Check Configuration Status\n",
    "\n",
    "Let's see which steps still need configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Status:\n",
      "==============================\n",
      "Base config set: âœ…\n",
      "Processing config set: âœ…\n",
      "Total steps: 11\n",
      "Pending steps: 10\n",
      "\n",
      "Steps needing configuration:\n",
      "  - CradleDataLoading_training\n",
      "  - TabularPreprocessing_training\n",
      "  - TokenizerTraining_training\n",
      "  - PyTorchTraining\n",
      "  - CradleDataLoading_calibration\n",
      "  - TabularPreprocessing_calibration\n",
      "  - PyTorchModelEval_calibration\n",
      "  - PercentileModelCalibration_calibration\n",
      "  - Registration\n",
      "  - Payload\n"
     ]
    }
   ],
   "source": [
    "# Check current status\n",
    "status = factory.get_configuration_status()\n",
    "pending_steps = factory.get_pending_steps()\n",
    "\n",
    "print(\"Configuration Status:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Base config set: {'âœ…' if status['base_config'] else 'âŒ'}\")\n",
    "print(f\"Processing config set: {'âœ…' if status['base_processing_config'] else 'âŒ'}\")\n",
    "print(f\"Total steps: {len(config_map)}\")\n",
    "print(f\"Pending steps: {len(pending_steps)}\")\n",
    "print()\n",
    "\n",
    "if pending_steps:\n",
    "    print(\"Steps needing configuration:\")\n",
    "    for step in pending_steps:\n",
    "        print(f\"  - {step}\")\n",
    "else:\n",
    "    print(\"âœ… All steps configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Configure Individual Steps\n",
    "\n",
    "Now we configure each step with its specific requirements. The factory will show us\n",
    "only the fields that are unique to each step (not inherited from base configs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.1: Configure Training Step\n",
    "\n",
    "This config is for **TrainingStep**. \n",
    "* It ask user to provide all necessary information to construct a **Container** and start a **Training Job**\n",
    "* Ths most important information has provided in the **HyperParameter** section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_field_list = [\n",
    "    f\"Abuse.abuse_fap_action_by_customer_inline_transform_{region.lower()}.n_claims_solicit_count_last_365_days\",\n",
    "    f\"Abuse.abuse_fap_action_by_customer_inline_transform_{region.lower()}.n_claims_warn_count_last_365_days\",\n",
    "    f\"Abuse.abuse_fap_action_by_customer_inline_transform_{region.lower()}.n_concession_solicit_count_last_365_days\",\n",
    "    f\"Abuse.abuse_fap_action_by_customer_inline_transform_{region.lower()}.n_concession_warn_count_last_365_days\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_max_buyer_order_message_time_gap\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_max_order_message_time_gap\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_max_seller_order_message_time_gap\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_message_count_with_diff_topic_si\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_message_count_with_notr_topic_si\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_message_count_with_return_keywords_si\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_min_buyer_message_count\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_min_buyer_order_message_time_gap\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_min_message_count\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_min_order_message_time_gap\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_min_seller_message_count\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_min_seller_order_message_time_gap\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_total_buyer_message_count\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_total_message_count\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_total_seller_message_count\",\n",
    "    f\"Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}.n_total_topic_count\",\n",
    "    \"Abuse.completed_afn_orders_by_customer_marketplace.n_afn_order_count_last_365_days\",\n",
    "    \"Abuse.completed_afn_orders_by_customer_marketplace.n_afn_unit_amount_last_365_days\",\n",
    "    \"Abuse.completed_afn_orders_by_customer_marketplace.n_afn_unit_count_last_365_days\",\n",
    "    \"Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_order_count_last_365_days\",\n",
    "    \"Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_unit_amount_last_365_days\",\n",
    "    \"Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_unit_count_last_365_days\",\n",
    "    \"Abuse.dnr_by_customer_marketplace.n_dnr_amount_si_last_365_days\",\n",
    "    \"Abuse.dnr_by_customer_marketplace.n_dnr_order_count_last_365_days\",\n",
    "    \"Abuse.dnr_by_customer_marketplace.n_dnr_unit_amount_last_365_days\",\n",
    "    \"Abuse.dnr_by_customer_marketplace.n_dnr_unit_count_last_365_days\",\n",
    "    f\"Abuse.mfn_a2z_claims_by_customer_{region.lower()}.n_mfn_claims_amount_last_365_days\",\n",
    "    f\"Abuse.mfn_a2z_claims_by_customer_{region.lower()}.n_mfn_claims_count_last_365_days\",\n",
    "    f\"Abuse.mfn_a2z_claims_by_customer_{region.lower()}.n_mfn_diff_claims_amount_last_365_days\",\n",
    "    f\"Abuse.mfn_a2z_claims_by_customer_{region.lower()}.n_mfn_diff_claims_count_last_365_days\",\n",
    "    f\"Abuse.mfn_a2z_claims_by_customer_{region.lower()}.n_mfn_notr_claims_amount_last_365_days\",\n",
    "    f\"Abuse.mfn_a2z_claims_by_customer_{region.lower()}.n_mfn_notr_claims_count_last_365_days\",\n",
    "    \"Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_order_count_last_365_days\",\n",
    "    \"Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_unit_amount_last_365_days\",\n",
    "    \"Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_unit_count_last_365_days\",\n",
    "    \"Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_order_count_last_365_days\",\n",
    "    \"Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_unit_amount_last_365_days\",\n",
    "    \"Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_unit_count_last_365_days\",\n",
    "    \"Abuse.mfn_categorized_refunds_si_by_customer_marketplace.n_mfn_diff_refunds_si_365_days\",\n",
    "    \"Abuse.mfn_categorized_refunds_si_by_customer_marketplace.n_mfn_notr_refunds_si_365_days\",\n",
    "    \"Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_order_count_last_365_days\",\n",
    "    \"Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_unit_amount_last_365_days\",\n",
    "    \"Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_unit_count_last_365_days\",\n",
    "    \"Abuse.mfn_refunds_si_by_customer_marketplace.n_mfn_refund_amount_si_last_365_days\",\n",
    "    \"Abuse.order_to_execution_time_from_eventvariables.n_order_to_execution\",\n",
    "    \"Abuse.shiptrack_flag_by_order.n_any_delivered\",\n",
    "    \"Abuse.shiptrack_flag_by_order.n_any_available_for_pickup\",\n",
    "    \"Abuse.shiptrack_flag_by_order.n_any_partial_delivered\",\n",
    "    \"Abuse.shiptrack_flag_by_order.n_any_undeliverable\",\n",
    "    \"Abuse.shiptrack_flag_by_order.n_any_returning\",\n",
    "    \"Abuse.shiptrack_flag_by_order.n_any_returned\",\n",
    "    \"COMP_DAYOB\",\n",
    "    \"claimAmount_value\",\n",
    "    \"claimantInfo_allClaimCount365day\",\n",
    "    \"claimantInfo_lifetimeClaimCount\",\n",
    "    \"claimantInfo_pendingClaimCount\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_field_list = [\n",
    "    \"PAYMETH\",\n",
    "    \"claim_reason\",\n",
    "    \"claimantInfo_status\",\n",
    "    \"shipments_status\",\n",
    "    \"Abuse.buyer_abuse_bsm_message_body_concat_by_order_marketplaceid.c_message_body_concat_by_order\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"is_abuse\"  # \"llm_reversal_flag\"\n",
    "id_name = \"order_id\"\n",
    "\n",
    "in_house_field_list = [\n",
    "    \"marketplace_id\",\n",
    "    id_name,\n",
    "    label_name,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_field_list = tab_field_list + cat_field_list + in_house_field_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "lr = 2e-5  # 3e-05\n",
    "max_epochs = 5  # 3, #15,\n",
    "metric_choices = [\"f1_score\", \"auroc\"]\n",
    "optimizer = \"SGD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create the hyperparameters\n",
    "from cursus.core.base.hyperparameters_base import ModelHyperparameters\n",
    "from cursus.steps.hyperparams.hyperparameters_bimodal import BimodalModelHyperparameters\n",
    "\n",
    "\n",
    "# Create base hyperparameters\n",
    "base_hyperparameter = ModelHyperparameters(\n",
    "    full_field_list=full_field_list,\n",
    "    cat_field_list=cat_field_list,\n",
    "    tab_field_list=tab_field_list,\n",
    "    label_name=label_name,\n",
    "    id_name=id_name,\n",
    "    multiclass_categories=[0, 1],\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    metric_choices=metric_choices,\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = \"bimodal_gate_fusion\"  # \"bimodal_bert\"\n",
    "tokenizer = \"bert-base-multilingual-uncased\"\n",
    "text_name = \"Abuse.buyer_abuse_bsm_message_body_concat_by_order_marketplaceid.c_message_body_concat_by_order\"\n",
    "lr_decay = 0.05\n",
    "max_sen_len = 512\n",
    "chunk_trancate = True\n",
    "max_total_chunks = 3\n",
    "momentum = 0.9\n",
    "pretrained_embedding = True\n",
    "reinit_layers = 2\n",
    "reinit_pooler = True\n",
    "run_scheduler = True\n",
    "load_ckpt = False\n",
    "hidden_common_dim = 100\n",
    "val_check_interval = 0.25\n",
    "warmup_steps = 300\n",
    "weight_decay = 0\n",
    "early_stop_metric = \"val_loss\"\n",
    "early_stop_patience = 3\n",
    "text_input_ids_key = \"input_ids\"\n",
    "text_attention_mask_key = \"attention_mask\"\n",
    "fp16 = False\n",
    "use_gradient_checkpointing = False  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hyperparameters created\n",
      "   Features: 68 total, 60 numerical, 5 categorical\n",
      "   XGBoost rounds: 5\n"
     ]
    }
   ],
   "source": [
    "# Create XGBoost hyperparameters\n",
    "bimodal_hyperparams = BimodalModelHyperparameters.from_base_hyperparam(\n",
    "    base_hyperparameter,\n",
    "    model_class=model_class,\n",
    "    text_name=text_name,\n",
    "    tokenizer=tokenizer,\n",
    "    text_input_ids_key=text_input_ids_key,\n",
    "    text_attention_mask_key=text_attention_mask_key,\n",
    "    momentum=momentum,\n",
    "    lr_decay=lr_decay,\n",
    "    weight_decay=weight_decay,\n",
    "    max_sen_len=max_sen_len,\n",
    "    chunk_trancate=chunk_trancate,\n",
    "    max_total_chunks=max_total_chunks,\n",
    "    reinit_layers=reinit_layers,\n",
    "    reinit_pooler=reinit_pooler,\n",
    "    run_scheduler=run_scheduler,\n",
    "    load_ckpt=load_ckpt,\n",
    "    hidden_common_dim=hidden_common_dim,\n",
    "    warmup_steps=warmup_steps,\n",
    "    val_check_interval=val_check_interval,\n",
    "    early_stop_metric=early_stop_metric,\n",
    "    early_stop_patience=early_stop_patience,\n",
    "    fp16=fp16,\n",
    "    use_gradient_checkpointing=use_gradient_checkpointing,\n",
    ")\n",
    "\n",
    "print(\"âœ… Hyperparameters created\")\n",
    "print(\n",
    "    f\"   Features: {len(full_field_list)} total, {len(tab_field_list)} numerical, {len(cat_field_list)} categorical\"\n",
    ")\n",
    "print(f\"   XGBoost rounds: {bimodal_hyperparams.max_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BimodalModelHyperparameters(full_field_list=['Abuse.abuse_fap_action_by_customer_inline_transform_na.n_claims_solicit_count_last_365_days', 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_claims_warn_count_last_365_days', 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_concession_solicit_count_last_365_days', 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_concession_warn_count_last_365_days', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_buyer_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_seller_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_diff_topic_si', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_notr_topic_si', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_return_keywords_si', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_buyer_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_buyer_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_seller_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_seller_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_buyer_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_seller_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_topic_count', 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_order_count_last_365_days', 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_unit_amount_last_365_days', 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_unit_count_last_365_days', 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_order_count_last_365_days', 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_unit_amount_last_365_days', 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_unit_count_last_365_days', 'Abuse.dnr_by_customer_marketplace.n_dnr_amount_si_last_365_days', 'Abuse.dnr_by_customer_marketplace.n_dnr_order_count_last_365_days', 'Abuse.dnr_by_customer_marketplace.n_dnr_unit_amount_last_365_days', 'Abuse.dnr_by_customer_marketplace.n_dnr_unit_count_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_claims_amount_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_claims_count_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_diff_claims_amount_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_diff_claims_count_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_notr_claims_amount_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_notr_claims_count_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_order_count_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_unit_amount_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_unit_count_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_order_count_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_unit_amount_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_unit_count_last_365_days', 'Abuse.mfn_categorized_refunds_si_by_customer_marketplace.n_mfn_diff_refunds_si_365_days', 'Abuse.mfn_categorized_refunds_si_by_customer_marketplace.n_mfn_notr_refunds_si_365_days', 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_order_count_last_365_days', 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_unit_amount_last_365_days', 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_unit_count_last_365_days', 'Abuse.mfn_refunds_si_by_customer_marketplace.n_mfn_refund_amount_si_last_365_days', 'Abuse.order_to_execution_time_from_eventvariables.n_order_to_execution', 'Abuse.shiptrack_flag_by_order.n_any_delivered', 'Abuse.shiptrack_flag_by_order.n_any_available_for_pickup', 'Abuse.shiptrack_flag_by_order.n_any_partial_delivered', 'Abuse.shiptrack_flag_by_order.n_any_undeliverable', 'Abuse.shiptrack_flag_by_order.n_any_returning', 'Abuse.shiptrack_flag_by_order.n_any_returned', 'COMP_DAYOB', 'claimAmount_value', 'claimantInfo_allClaimCount365day', 'claimantInfo_lifetimeClaimCount', 'claimantInfo_pendingClaimCount', 'PAYMETH', 'claim_reason', 'claimantInfo_status', 'shipments_status', 'Abuse.buyer_abuse_bsm_message_body_concat_by_order_marketplaceid.c_message_body_concat_by_order', 'marketplace_id', 'order_id', 'is_abuse'], cat_field_list=['PAYMETH', 'claim_reason', 'claimantInfo_status', 'shipments_status', 'Abuse.buyer_abuse_bsm_message_body_concat_by_order_marketplaceid.c_message_body_concat_by_order'], tab_field_list=['Abuse.abuse_fap_action_by_customer_inline_transform_na.n_claims_solicit_count_last_365_days', 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_claims_warn_count_last_365_days', 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_concession_solicit_count_last_365_days', 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_concession_warn_count_last_365_days', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_buyer_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_seller_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_diff_topic_si', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_notr_topic_si', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_return_keywords_si', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_buyer_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_buyer_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_seller_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_seller_order_message_time_gap', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_buyer_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_seller_message_count', 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_topic_count', 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_order_count_last_365_days', 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_unit_amount_last_365_days', 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_unit_count_last_365_days', 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_order_count_last_365_days', 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_unit_amount_last_365_days', 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_unit_count_last_365_days', 'Abuse.dnr_by_customer_marketplace.n_dnr_amount_si_last_365_days', 'Abuse.dnr_by_customer_marketplace.n_dnr_order_count_last_365_days', 'Abuse.dnr_by_customer_marketplace.n_dnr_unit_amount_last_365_days', 'Abuse.dnr_by_customer_marketplace.n_dnr_unit_count_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_claims_amount_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_claims_count_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_diff_claims_amount_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_diff_claims_count_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_notr_claims_amount_last_365_days', 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_notr_claims_count_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_order_count_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_unit_amount_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_unit_count_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_order_count_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_unit_amount_last_365_days', 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_unit_count_last_365_days', 'Abuse.mfn_categorized_refunds_si_by_customer_marketplace.n_mfn_diff_refunds_si_365_days', 'Abuse.mfn_categorized_refunds_si_by_customer_marketplace.n_mfn_notr_refunds_si_365_days', 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_order_count_last_365_days', 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_unit_amount_last_365_days', 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_unit_count_last_365_days', 'Abuse.mfn_refunds_si_by_customer_marketplace.n_mfn_refund_amount_si_last_365_days', 'Abuse.order_to_execution_time_from_eventvariables.n_order_to_execution', 'Abuse.shiptrack_flag_by_order.n_any_delivered', 'Abuse.shiptrack_flag_by_order.n_any_available_for_pickup', 'Abuse.shiptrack_flag_by_order.n_any_partial_delivered', 'Abuse.shiptrack_flag_by_order.n_any_undeliverable', 'Abuse.shiptrack_flag_by_order.n_any_returning', 'Abuse.shiptrack_flag_by_order.n_any_returned', 'COMP_DAYOB', 'claimAmount_value', 'claimantInfo_allClaimCount365day', 'claimantInfo_lifetimeClaimCount', 'claimantInfo_pendingClaimCount'], id_name='order_id', label_name='is_abuse', multiclass_categories=[0, 1], categorical_features_to_encode=[], model_class='bimodal_gate_fusion', device=-1, header=0, lr=2e-05, batch_size=2, max_epochs=5, metric_choices=['f1_score', 'auroc'], optimizer='SGD', class_weights=[1.0, 1.0], tokenizer='bert-base-multilingual-uncased', text_name='Abuse.buyer_abuse_bsm_message_body_concat_by_order_marketplaceid.c_message_body_concat_by_order', lr_decay=0.05, momentum=0.9, weight_decay=0.0, adam_epsilon=1e-08, warmup_steps=300, run_scheduler=True, val_check_interval=0.25, gradient_clip_val=1.0, fp16=False, use_gradient_checkpointing=False, early_stop_metric='val_loss', early_stop_patience=3, load_ckpt=False, smooth_factor=0.0, count_threshold=0, text_field_overwrite=False, chunk_trancate=True, max_total_chunks=3, max_sen_len=512, fixed_tokenizer_length=True, text_input_ids_key='input_ids', text_attention_mask_key='attention_mask', text_processing_steps=['dialogue_splitter', 'html_normalizer', 'emoji_remover', 'text_normalizer', 'dialogue_chunker', 'tokenizer'], num_channels=[100, 100], num_layers=2, dropout_keep=0.1, kernel_size=[3, 5, 7], is_embeddings_trainable=True, pretrained_embedding=True, reinit_layers=2, reinit_pooler=True, hidden_common_dim=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bimodal_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type_list = [\n",
    "    \"ml.m5.4xlarge\",\n",
    "    \"ml.m5.12xlarge\",\n",
    "    \"ml.p3.16xlarge\",\n",
    "    \"ml.g4dn.16xlarge\",\n",
    "    \"ml.g5.12xlarge\",\n",
    "    \"ml.g5.16xlarge\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml.p3.16xlarge'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_select = -4  # -2 #-1\n",
    "instance_type_list[instance_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,371 - INFO - âœ… PyTorchTraining configured successfully using PyTorchTrainingConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorchTraining configured\n",
      "   Instance type: ml.p3.16xlarge\n",
      "   Volume size: 800 GB\n"
     ]
    }
   ],
   "source": [
    "# Configure XGBoost training\n",
    "if \"PyTorchTraining\" in pending_steps:\n",
    "    step_name = \"PyTorchTraining\"\n",
    "    training_volume_size = 800\n",
    "    factory.set_step_config(\n",
    "        step_name,\n",
    "        training_instance_type=instance_type_list[instance_select],\n",
    "        training_entry_point=\"pytorch_training.py\",\n",
    "        training_volume_size=training_volume_size,\n",
    "    )\n",
    "    print(f\"âœ… {step_name} configured\")\n",
    "    print(f\"   Instance type: {instance_type_list[instance_select]}\")\n",
    "    print(f\"   Volume size: {training_volume_size} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.2: Configure Data Loading Steps\n",
    "\n",
    "\n",
    "In this section, user provide the input to construct a **cradle profile**. In Cradle Profle, there are **four** sections\n",
    "1. **Data Source Specification**: specify\n",
    "    1. *data source* (MDS, EDX, ANDES)\n",
    "    2. *input schema*\n",
    "2. **Transform Specification**: specifiy \n",
    "    1. *transform SQL*\n",
    "    2. *job split*\n",
    "3. **Output Specification**: specify\n",
    "    1. *output path*,\n",
    "    2. *ouptut format* (CSV, UNESCAPED_TSV, JSON, ION, PARQUET)\n",
    "    3. *output schema*\n",
    "    4. *save mode*\n",
    "4. **Cradle Job Specification** specify\n",
    "    1. *cradle account*\n",
    "    2. *cluster_type*\n",
    "\n",
    "This config is for **CradleDataLoadingStep**, which is a customized step provided under [SecureAISandboxWorkflowPythonSDK](https://code.amazon.com/packages/SecureAISandboxWorkflowPythonSDK/trees/mainline#)\n",
    "* This step inherit from **MODSPredefinedProcessingStep**, which is a customized base class that itself inherits from **ScriptProcessingStep**. Source code in [MODSWorkflowCore](https://code.amazon.com/packages/MODSWorkflowCore/trees/mainline#)\n",
    "* This step would need to load **Execution Document** to take action.\n",
    "* This step itself does not have many options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cursus.steps.configs.config_cradle_data_loading_step import (\n",
    "    CradleDataLoadingConfig,\n",
    "    MdsDataSourceConfig,\n",
    "    EdxDataSourceConfig,\n",
    "    DataSourceConfig,\n",
    "    DataSourcesSpecificationConfig,\n",
    "    JobSplitOptionsConfig,\n",
    "    TransformSpecificationConfig,\n",
    "    OutputSpecificationConfig,\n",
    "    CradleJobSpecificationConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cradle Data Loading (Training) Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start_datetime = \"2025-01-01T00:00:00\"  # \"2025-05-11T00:00:00\"  #'2024-12-01T00:00:00'  #'2024-03-01T00:00:00'\n",
    "training_end_datetime = \"2025-10-31T00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds_service_name = \"AtoZ\"\n",
    "org_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds_field_list = [\"objectId\", \"transactionDate\"] + tab_field_list + cat_field_list\n",
    "mds_output_schema = [\n",
    "    {\"field_name\": field, \"field_type\": \"STRING\"} for field in mds_field_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edx_arn = {\n",
    "    \"NA\": 'arn:amazon:edx:iad::manifest/trms-abuse-analytics/buyer-seller-messaging/bsm-tag-atoz/[\"20251215\",2025-01-01T00:00:00Z,2025-10-31T01:00:00Z,\"LLM_TAG_WW_Train\"]',\n",
    "    \"EU\": 'arn:amazon:edx:iad::manifest/trms-abuse-analytics/buyer-seller-messaging/bsm-tag-atoz/[\"20251215\",2025-01-01T00:00:00Z,2025-10-31T01:00:00Z,\"LLM_TAG_WW_Train\"]',\n",
    "    \"FE\": 'arn:amazon:edx:iad::manifest/trms-abuse-analytics/buyer-seller-messaging/bsm-tag-atoz/[\"20251215\",2025-01-01T00:00:00Z,2025-10-31T01:00:00Z,\"LLM_TAG_WW_Train\"]',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_schema = [\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"marketplace_id\",\n",
    "    \"llm_reversal_flag\",\n",
    "    \"is_abuse\",\n",
    "]\n",
    "edx_schema_overrides = [\n",
    "    {\"field_name\": field, \"field_type\": \"STRING\"} for field in tag_schema\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_fields(mds_fields: List[str], tag_fields: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a combined list of all fields from MDS and EDX sources.\n",
    "\n",
    "    This function handles case-insensitivity to avoid duplicate columns in SQL SELECT\n",
    "    statements where the only difference is case (e.g., \"OrderId\" and \"orderid\").\n",
    "    When duplicates with different cases are found, the first occurrence is kept.\n",
    "\n",
    "    Args:\n",
    "        mds_fields (List[str]): List of MDS fields\n",
    "        tag_fields (List[str]): List of tag fields\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Combined and deduplicated list of fields\n",
    "    \"\"\"\n",
    "    # Track lowercase field names to detect duplicates\n",
    "    seen_lowercase = {}\n",
    "    deduplicated_fields = []\n",
    "\n",
    "    # Process all fields, keeping only the first occurrence when case-insensitive duplicates exist\n",
    "    for field in mds_fields + tag_fields:\n",
    "        field_lower = field.lower()\n",
    "        if field_lower not in seen_lowercase:\n",
    "            seen_lowercase[field_lower] = True\n",
    "            deduplicated_fields.append(field)\n",
    "\n",
    "    return sorted(deduplicated_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_schema = get_all_fields(mds_field_list, tag_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abuse.abuse_fap_action_by_customer_inline_transform_na.n_claims_solicit_count_last_365_days',\n",
       " 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_claims_warn_count_last_365_days',\n",
       " 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_concession_solicit_count_last_365_days',\n",
       " 'Abuse.abuse_fap_action_by_customer_inline_transform_na.n_concession_warn_count_last_365_days',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_buyer_order_message_time_gap',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_order_message_time_gap',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_max_seller_order_message_time_gap',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_diff_topic_si',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_notr_topic_si',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_message_count_with_return_keywords_si',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_buyer_message_count',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_buyer_order_message_time_gap',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_message_count',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_order_message_time_gap',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_seller_message_count',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_min_seller_order_message_time_gap',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_buyer_message_count',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_message_count',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_seller_message_count',\n",
       " 'Abuse.bsm_stats_for_evaluated_mfn_concessions_by_customer_na.n_total_topic_count',\n",
       " 'Abuse.buyer_abuse_bsm_message_body_concat_by_order_marketplaceid.c_message_body_concat_by_order',\n",
       " 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_order_count_last_365_days',\n",
       " 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_unit_amount_last_365_days',\n",
       " 'Abuse.completed_afn_orders_by_customer_marketplace.n_afn_unit_count_last_365_days',\n",
       " 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_order_count_last_365_days',\n",
       " 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_unit_amount_last_365_days',\n",
       " 'Abuse.completed_mfn_orders_by_customer_marketplace.n_mfn_unit_count_last_365_days',\n",
       " 'Abuse.dnr_by_customer_marketplace.n_dnr_amount_si_last_365_days',\n",
       " 'Abuse.dnr_by_customer_marketplace.n_dnr_order_count_last_365_days',\n",
       " 'Abuse.dnr_by_customer_marketplace.n_dnr_unit_amount_last_365_days',\n",
       " 'Abuse.dnr_by_customer_marketplace.n_dnr_unit_count_last_365_days',\n",
       " 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_claims_amount_last_365_days',\n",
       " 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_claims_count_last_365_days',\n",
       " 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_diff_claims_amount_last_365_days',\n",
       " 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_diff_claims_count_last_365_days',\n",
       " 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_notr_claims_amount_last_365_days',\n",
       " 'Abuse.mfn_a2z_claims_by_customer_na.n_mfn_notr_claims_count_last_365_days',\n",
       " 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_order_count_last_365_days',\n",
       " 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_unit_amount_last_365_days',\n",
       " 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_diff_refunds_unit_count_last_365_days',\n",
       " 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_order_count_last_365_days',\n",
       " 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_unit_amount_last_365_days',\n",
       " 'Abuse.mfn_categorized_refunds_by_customer_marketplace.n_mfn_notr_refunds_unit_count_last_365_days',\n",
       " 'Abuse.mfn_categorized_refunds_si_by_customer_marketplace.n_mfn_diff_refunds_si_365_days',\n",
       " 'Abuse.mfn_categorized_refunds_si_by_customer_marketplace.n_mfn_notr_refunds_si_365_days',\n",
       " 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_order_count_last_365_days',\n",
       " 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_unit_amount_last_365_days',\n",
       " 'Abuse.mfn_refunds_by_customer_marketplace.n_mfn_refund_unit_count_last_365_days',\n",
       " 'Abuse.mfn_refunds_si_by_customer_marketplace.n_mfn_refund_amount_si_last_365_days',\n",
       " 'Abuse.order_to_execution_time_from_eventvariables.n_order_to_execution',\n",
       " 'Abuse.shiptrack_flag_by_order.n_any_available_for_pickup',\n",
       " 'Abuse.shiptrack_flag_by_order.n_any_delivered',\n",
       " 'Abuse.shiptrack_flag_by_order.n_any_partial_delivered',\n",
       " 'Abuse.shiptrack_flag_by_order.n_any_returned',\n",
       " 'Abuse.shiptrack_flag_by_order.n_any_returning',\n",
       " 'Abuse.shiptrack_flag_by_order.n_any_undeliverable',\n",
       " 'COMP_DAYOB',\n",
       " 'PAYMETH',\n",
       " 'claimAmount_value',\n",
       " 'claim_reason',\n",
       " 'claimantInfo_allClaimCount365day',\n",
       " 'claimantInfo_lifetimeClaimCount',\n",
       " 'claimantInfo_pendingClaimCount',\n",
       " 'claimantInfo_status',\n",
       " 'customer_id',\n",
       " 'is_abuse',\n",
       " 'llm_reversal_flag',\n",
       " 'marketplace_id',\n",
       " 'objectId',\n",
       " 'order_id',\n",
       " 'shipments_status',\n",
       " 'transactionDate']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = \"PARQUET\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following transform sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_sql = f\"\"\"\n",
    "SELECT\n",
    "    Abuse__DOT__abuse_fap_action_by_customer_inline_transform_{region.lower()}__DOT__n_claims_solicit_count_last_365_days,\n",
    "    Abuse__DOT__abuse_fap_action_by_customer_inline_transform_{region.lower()}__DOT__n_claims_warn_count_last_365_days,\n",
    "    Abuse__DOT__abuse_fap_action_by_customer_inline_transform_{region.lower()}__DOT__n_concession_solicit_count_last_365_days,\n",
    "    Abuse__DOT__abuse_fap_action_by_customer_inline_transform_{region.lower()}__DOT__n_concession_warn_count_last_365_days,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_max_buyer_order_message_time_gap,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_max_order_message_time_gap,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_max_seller_order_message_time_gap,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_message_count_with_diff_topic_si,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_message_count_with_notr_topic_si,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_message_count_with_return_keywords_si,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_buyer_message_count,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_buyer_order_message_time_gap,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_message_count,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_order_message_time_gap,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_seller_message_count,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_seller_order_message_time_gap,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_total_buyer_message_count,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_total_message_count,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_total_seller_message_count,\n",
    "    Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_total_topic_count,\n",
    "    Abuse__DOT__completed_afn_orders_by_customer_marketplace__DOT__n_afn_order_count_last_365_days,\n",
    "    Abuse__DOT__completed_afn_orders_by_customer_marketplace__DOT__n_afn_unit_amount_last_365_days,\n",
    "    Abuse__DOT__completed_afn_orders_by_customer_marketplace__DOT__n_afn_unit_count_last_365_days,\n",
    "    Abuse__DOT__completed_mfn_orders_by_customer_marketplace__DOT__n_mfn_order_count_last_365_days,\n",
    "    Abuse__DOT__completed_mfn_orders_by_customer_marketplace__DOT__n_mfn_unit_amount_last_365_days,\n",
    "    Abuse__DOT__completed_mfn_orders_by_customer_marketplace__DOT__n_mfn_unit_count_last_365_days,\n",
    "    Abuse__DOT__dnr_by_customer_marketplace__DOT__n_dnr_amount_si_last_365_days,\n",
    "    Abuse__DOT__dnr_by_customer_marketplace__DOT__n_dnr_order_count_last_365_days,\n",
    "    Abuse__DOT__dnr_by_customer_marketplace__DOT__n_dnr_unit_amount_last_365_days,\n",
    "    Abuse__DOT__dnr_by_customer_marketplace__DOT__n_dnr_unit_count_last_365_days,\n",
    "    Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_claims_amount_last_365_days,\n",
    "    Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_claims_count_last_365_days,\n",
    "    Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_diff_claims_amount_last_365_days,\n",
    "    Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_diff_claims_count_last_365_days,\n",
    "    Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_notr_claims_amount_last_365_days,\n",
    "    Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_notr_claims_count_last_365_days,\n",
    "    Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_diff_refunds_order_count_last_365_days,\n",
    "    Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_diff_refunds_unit_amount_last_365_days,\n",
    "    Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_diff_refunds_unit_count_last_365_days,\n",
    "    Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_notr_refunds_order_count_last_365_days,\n",
    "    Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_notr_refunds_unit_amount_last_365_days,\n",
    "    Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_notr_refunds_unit_count_last_365_days,\n",
    "    Abuse__DOT__mfn_categorized_refunds_si_by_customer_marketplace__DOT__n_mfn_diff_refunds_si_365_days,\n",
    "    Abuse__DOT__mfn_categorized_refunds_si_by_customer_marketplace__DOT__n_mfn_notr_refunds_si_365_days,\n",
    "    Abuse__DOT__mfn_refunds_by_customer_marketplace__DOT__n_mfn_refund_order_count_last_365_days,\n",
    "    Abuse__DOT__mfn_refunds_by_customer_marketplace__DOT__n_mfn_refund_unit_amount_last_365_days,\n",
    "    Abuse__DOT__mfn_refunds_by_customer_marketplace__DOT__n_mfn_refund_unit_count_last_365_days,\n",
    "    Abuse__DOT__mfn_refunds_si_by_customer_marketplace__DOT__n_mfn_refund_amount_si_last_365_days,\n",
    "    Abuse__DOT__order_to_execution_time_from_eventvariables__DOT__n_order_to_execution,\n",
    "    Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_available_for_pickup,\n",
    "    Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_delivered,\n",
    "    Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_partial_delivered,\n",
    "    Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_returned,\n",
    "    Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_returning,\n",
    "    Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_undeliverable,\n",
    "    COMP_DAYOB,\n",
    "    PAYMETH,\n",
    "    claimAmount_value,\n",
    "    claim_reason,\n",
    "    claimantInfo_allClaimCount365day,\n",
    "    claimantInfo_lifetimeClaimCount,\n",
    "    claimantInfo_pendingClaimCount,\n",
    "    claimantInfo_status,\n",
    "    marketplace_id,\n",
    "    objectId,\n",
    "    order_id,\n",
    "    shipments_status,\n",
    "    customer_id,\n",
    "    llm_reversal_flag,\n",
    "    is_abuse,\n",
    "    transactionDate,\n",
    "    Abuse__DOT__buyer_abuse_bsm_message_body_concat_by_order_marketplaceid__DOT__c_message_body_concat_by_order\n",
    "FROM (\n",
    "    SELECT\n",
    "        RAW_MDS_{region}.Abuse__DOT__abuse_fap_action_by_customer_inline_transform_{region.lower()}__DOT__n_claims_solicit_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__abuse_fap_action_by_customer_inline_transform_{region.lower()}__DOT__n_claims_warn_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__abuse_fap_action_by_customer_inline_transform_{region.lower()}__DOT__n_concession_solicit_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__abuse_fap_action_by_customer_inline_transform_{region.lower()}__DOT__n_concession_warn_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_max_buyer_order_message_time_gap,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_max_order_message_time_gap,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_max_seller_order_message_time_gap,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_message_count_with_diff_topic_si,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_message_count_with_notr_topic_si,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_message_count_with_return_keywords_si,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_buyer_message_count,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_buyer_order_message_time_gap,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_message_count,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_order_message_time_gap,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_seller_message_count,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_min_seller_order_message_time_gap,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_total_buyer_message_count,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_total_message_count,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_total_seller_message_count,\n",
    "        RAW_MDS_{region}.Abuse__DOT__bsm_stats_for_evaluated_mfn_concessions_by_customer_{region.lower()}__DOT__n_total_topic_count,\n",
    "        RAW_MDS_{region}.Abuse__DOT__completed_afn_orders_by_customer_marketplace__DOT__n_afn_order_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__completed_afn_orders_by_customer_marketplace__DOT__n_afn_unit_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__completed_afn_orders_by_customer_marketplace__DOT__n_afn_unit_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__completed_mfn_orders_by_customer_marketplace__DOT__n_mfn_order_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__completed_mfn_orders_by_customer_marketplace__DOT__n_mfn_unit_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__completed_mfn_orders_by_customer_marketplace__DOT__n_mfn_unit_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__dnr_by_customer_marketplace__DOT__n_dnr_amount_si_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__dnr_by_customer_marketplace__DOT__n_dnr_order_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__dnr_by_customer_marketplace__DOT__n_dnr_unit_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__dnr_by_customer_marketplace__DOT__n_dnr_unit_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_claims_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_claims_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_diff_claims_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_diff_claims_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_notr_claims_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_a2z_claims_by_customer_{region.lower()}__DOT__n_mfn_notr_claims_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_diff_refunds_order_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_diff_refunds_unit_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_diff_refunds_unit_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_notr_refunds_order_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_notr_refunds_unit_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_categorized_refunds_by_customer_marketplace__DOT__n_mfn_notr_refunds_unit_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_categorized_refunds_si_by_customer_marketplace__DOT__n_mfn_diff_refunds_si_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_categorized_refunds_si_by_customer_marketplace__DOT__n_mfn_notr_refunds_si_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_refunds_by_customer_marketplace__DOT__n_mfn_refund_order_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_refunds_by_customer_marketplace__DOT__n_mfn_refund_unit_amount_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_refunds_by_customer_marketplace__DOT__n_mfn_refund_unit_count_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__mfn_refunds_si_by_customer_marketplace__DOT__n_mfn_refund_amount_si_last_365_days,\n",
    "        RAW_MDS_{region}.Abuse__DOT__order_to_execution_time_from_eventvariables__DOT__n_order_to_execution,\n",
    "        RAW_MDS_{region}.Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_available_for_pickup,\n",
    "        RAW_MDS_{region}.Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_delivered,\n",
    "        RAW_MDS_{region}.Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_partial_delivered,\n",
    "        RAW_MDS_{region}.Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_returned,\n",
    "        RAW_MDS_{region}.Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_returning,\n",
    "        RAW_MDS_{region}.Abuse__DOT__shiptrack_flag_by_order__DOT__n_any_undeliverable,\n",
    "        RAW_MDS_{region}.COMP_DAYOB,\n",
    "        RAW_MDS_{region}.PAYMETH,\n",
    "        RAW_MDS_{region}.claimAmount_value,\n",
    "        RAW_MDS_{region}.claim_reason,\n",
    "        RAW_MDS_{region}.claimantInfo_allClaimCount365day,\n",
    "        RAW_MDS_{region}.claimantInfo_lifetimeClaimCount,\n",
    "        RAW_MDS_{region}.claimantInfo_pendingClaimCount,\n",
    "        RAW_MDS_{region}.claimantInfo_status,\n",
    "        RAW_MDS_{region}.objectId,\n",
    "        RAW_MDS_{region}.shipments_status,\n",
    "        RAW_MDS_{region}.transactionDate,\n",
    "        TAGS.llm_reversal_flag,\n",
    "        TAGS.is_abuse,\n",
    "        TAGS.marketplace_id,\n",
    "        TAGS.order_id,\n",
    "        TAGS.customer_id,\n",
    "        ROW_NUMBER() OVER (PARTITION BY RAW_MDS_{region}.objectId, TAGS.order_id ORDER BY RAW_MDS_{region}.transactionDate DESC) as row_num,\n",
    "        regexp_replace(regexp_replace(regexp_replace(RAW_MDS_{region}.Abuse__DOT__buyer_abuse_bsm_message_body_concat_by_order_marketplaceid__DOT__c_message_body_concat_by_order, '(\")', ''), '\\\\n', ''), '\\\\t', '') as Abuse__DOT__buyer_abuse_bsm_message_body_concat_by_order_marketplaceid__DOT__c_message_body_concat_by_order\n",
    "    FROM RAW_MDS_{region}\n",
    "    JOIN TAGS ON RAW_MDS_{region}.objectId = TAGS.order_id\n",
    ")\n",
    "WHERE row_num = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_sql = \"\"\"\n",
    "select * from INPUT\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MEDIUM'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_cluster_types = [\"STANDARD\", \"SMALL\", \"MEDIUM\", \"LARGE\"]\n",
    "cluster_choice = -2\n",
    "cluster_type = available_cluster_types[cluster_choice]\n",
    "cluster_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cradle_account = \"BRP-ML-Abuse\"  #'Buyer-Abuse-RnD-Dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cradle_data_load_dict = {\n",
    "    \"job_type\": \"training\",\n",
    "    \"data_sources_spec\": DataSourcesSpecificationConfig(\n",
    "        start_date=training_start_datetime,\n",
    "        end_date=training_end_datetime,\n",
    "        data_sources=[\n",
    "            DataSourceConfig(\n",
    "                data_source_name=f\"RAW_MDS_{region}\",\n",
    "                data_source_type=\"MDS\",\n",
    "                mds_data_source_properties=MdsDataSourceConfig(\n",
    "                    service_name=mds_service_name,\n",
    "                    region=region,\n",
    "                    output_schema=mds_output_schema,\n",
    "                    org_id=org_id,\n",
    "                ),\n",
    "            ),\n",
    "            DataSourceConfig(\n",
    "                data_source_name=\"TAGS\",\n",
    "                data_source_type=\"EDX\",\n",
    "                edx_data_source_properties=EdxDataSourceConfig(\n",
    "                    schema_overrides=edx_schema_overrides,\n",
    "                    edx_arn=train_edx_arn[region],\n",
    "                ),\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    \"output_spec\": OutputSpecificationConfig(\n",
    "        output_schema=output_schema, output_format=output_format\n",
    "    ),\n",
    "    \"transform_spec\": TransformSpecificationConfig(\n",
    "        transform_sql=transform_sql,\n",
    "        job_split_options=JobSplitOptionsConfig(merge_sql=merge_sql),\n",
    "    ),\n",
    "    \"cradle_job_spec\": CradleJobSpecificationConfig(\n",
    "        cradle_account=cradle_account,\n",
    "        cluster_type=cluster_type,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,473 - INFO - âœ… CradleDataLoading_training configured successfully using CradleDataLoadingConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring CradleDataLoading_training:\n",
      "----------------------------------------\n",
      "* job_type                  (str)\n",
      "    One of ['training','validation','testing','calibration'] to indicate which dataset this job is pulling\n",
      "* data_sources_spec         (DataSourcesSpecificationConfig)\n",
      "    Full dataâ€sources specification (start/end dates plus list of sources).\n",
      "* transform_spec            (TransformSpecificationConfig)\n",
      "    Transform specification: SQL + jobâ€split options.\n",
      "* output_spec               (OutputSpecificationConfig)\n",
      "    Output specification: schema, output format, save mode, etc.\n",
      "* cradle_job_spec           (CradleJobSpecificationConfig)\n",
      "    Cradle job specification: cluster type, account, retry count, etc.\n",
      "    ... and 1 more fields\n",
      "âœ… CradleDataLoading_training configured\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configure training data loading\n",
    "if \"CradleDataLoading_training\" in pending_steps:\n",
    "    step_name = \"CradleDataLoading_training\"\n",
    "    requirements = factory.get_step_requirements(step_name)\n",
    "\n",
    "    print(f\"Configuring {step_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for req in requirements[:5]:  # Show first 5 requirements\n",
    "        marker = \"*\" if req[\"required\"] else \" \"\n",
    "        print(f\"{marker} {req['name']:<25} ({req['type']})\")\n",
    "        print(f\"    {req['description']}\")\n",
    "\n",
    "    if len(requirements) > 5:\n",
    "        print(f\"    ... and {len(requirements) - 5} more fields\")\n",
    "\n",
    "    # Set configuration for training data loading\n",
    "    factory.set_step_config(step_name, **training_cradle_data_load_dict)\n",
    "    print(f\"âœ… {step_name} configured\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cradle Data Loading (Calibration) Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "calibration_start_datetime = \"2025-01-01T00:00:00\"  #'2024-05-26T00:00:00'\n",
    "calibration_end_datetime = \"2025-10-31T00:00:00\"  #'2024-06-29T23:00:00'\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "calibration_edx_arn = {\n",
    "    \"NA\": 'arn:amazon:edx:iad::manifest/trms-abuse-analytics/buyer-seller-messaging/bsm-tag-atoz/[\"20251215\",2025-01-01T00:00:00Z,2025-10-31T01:00:00Z,\"LLM_TAG_WW_Test\"]',\n",
    "    \"EU\": 'arn:amazon:edx:iad::manifest/trms-abuse-analytics/buyer-seller-messaging/bsm-tag-atoz/[\"20251215\",2025-01-01T00:00:00Z,2025-10-31T01:00:00Z,\"LLM_TAG_WW_Test\"]',\n",
    "    \"FE\": 'arn:amazon:edx:iad::manifest/trms-abuse-analytics/buyer-seller-messaging/bsm-tag-atoz/[\"20251215\",2025-01-01T00:00:00Z,2025-10-31T01:00:00Z,\"LLM_TAG_WW_Test\"]',\n",
    "}\n",
    "# ======================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_cradle_data_load_dict = {\n",
    "    \"job_type\": \"calibration\",\n",
    "    \"data_sources_spec\": DataSourcesSpecificationConfig(\n",
    "        start_date=calibration_start_datetime,\n",
    "        end_date=calibration_end_datetime,\n",
    "        data_sources=[\n",
    "            DataSourceConfig(\n",
    "                data_source_name=f\"RAW_MDS_{region}\",\n",
    "                data_source_type=\"MDS\",\n",
    "                mds_data_source_properties=MdsDataSourceConfig(\n",
    "                    service_name=mds_service_name,\n",
    "                    region=region,\n",
    "                    output_schema=mds_output_schema,\n",
    "                    org_id=org_id,\n",
    "                ),\n",
    "            ),\n",
    "            DataSourceConfig(\n",
    "                data_source_name=\"TAGS\",\n",
    "                data_source_type=\"EDX\",\n",
    "                edx_data_source_properties=EdxDataSourceConfig(\n",
    "                    schema_overrides=edx_schema_overrides,\n",
    "                    edx_arn=calibration_edx_arn[region],\n",
    "                ),\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    \"output_spec\": OutputSpecificationConfig(\n",
    "        output_schema=output_schema, output_format=output_format\n",
    "    ),\n",
    "    \"transform_spec\": TransformSpecificationConfig(\n",
    "        transform_sql=transform_sql,\n",
    "        job_split_options=JobSplitOptionsConfig(merge_sql=merge_sql),\n",
    "    ),\n",
    "    \"cradle_job_spec\": CradleJobSpecificationConfig(\n",
    "        cradle_account=cradle_account,\n",
    "        cluster_type=cluster_type,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,497 - INFO - âœ… CradleDataLoading_calibration configured successfully using CradleDataLoadingConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CradleDataLoading_calibration configured\n"
     ]
    }
   ],
   "source": [
    "# Configure calibration data loading\n",
    "if \"CradleDataLoading_calibration\" in pending_steps:\n",
    "    step_name = \"CradleDataLoading_calibration\"\n",
    "\n",
    "    factory.set_step_config(step_name, **calibration_cradle_data_load_dict)\n",
    "    print(f\"âœ… {step_name} configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.3: Configure Registration Step\n",
    "\n",
    "\n",
    "* [MRAS (Model Resource Allocation System)](https://w.amazon.com/bin/view/CMLS/ME/MIMS/)Â is a system that manages your **model endpoints**. \n",
    "    * It takes your model artifact and its metadata and deploys an endpoint to an AWS account you have onboarded to MRAS. You can access this endpoint through the AMES system, which URES uses.\n",
    "* **MIMS (Model Inference Management System)** is a system that handles the model creation\n",
    "* **MMS (Model Management Service)** would manage the model card\n",
    "> \n",
    "> Note that we used to call **MRAS MIMS** (**Model Inference Management System**). \n",
    "> - **MIMS** is the component of MRAS that handles endpoint creation. \n",
    "> - To reduce customer confusion, we have started to use *MRAS* to also refer to *MIMS*. \n",
    "> - Some of our wikis may still use *MIMS* instead of *MRAS*.\n",
    "> \n",
    "> If your team has not already, pleaseÂ [onboard an AWS account to MRAS](https://w.amazon.com/bin/view/CMLS/ME/MIMS/UserGuide/Onboarding/).\n",
    "\n",
    "* **MIMSModelRegistrationStep** is a SageMaker Workflow Step that wrap around the service call to **MIMS**.\n",
    "    * It is also a customized step provided by SAIS Python SDK\n",
    "        * See Source code[SecureAISandboxWorkflowPythonSDK](https://code.amazon.com/packages/SecureAISandboxWorkflowPythonSDK/trees/mainline#)\n",
    "    * This step inherit from **MODSPredefinedProcessingStep**, which is a customized base class that itself inherits from **ScriptProcessingStep**.\n",
    "        * Source code in [MODSWorkflowCore](https://code.amazon.com/packages/MODSWorkflowCore/trees/mainline#)\n",
    "    * This step would need to load **Execution Document** to take action.\n",
    "\n",
    "In **MIMSModelRegistrationStep**, we need to specify the fields to fill in the **Execution Document**\n",
    "* *model_owner*\n",
    "* *model_registration_domain*\n",
    "* *model_registration_objective*\n",
    "* *source_model_inference_input_variable_list*\n",
    "* *source_model_inference_output_variable_list*\n",
    "* *source_model_inference_content_types*\n",
    "* *source_model_inference_response_types*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,505 - INFO - âœ… Registration configured successfully using RegistrationConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Registration configured\n"
     ]
    }
   ],
   "source": [
    "# Configure Registration step\n",
    "if \"Registration\" in pending_steps:\n",
    "    # =================== Update This =======================\n",
    "    model_domain = \"BuyerSellerMessaging\"\n",
    "    model_objective = (\n",
    "        f\"AtoZ_Claims_BSM_Model_{region}\"\n",
    "        if region in [\"EU\", \"FE\"]\n",
    "        else \"AtoZ_Claims_BSM_Model_US\"\n",
    "    )\n",
    "    # =======================================================\n",
    "\n",
    "    # source_model_inference_input_variable_list = {\n",
    "    #    field: 'NUMERIC' if field in tab_field_list else 'TEXT'\n",
    "    #    for field in tab_field_list + cat_field_list\n",
    "    # }\n",
    "    source_model_inference_input_variable_list = [\n",
    "        [field, \"NUMERIC\"] if field in tab_field_list else [field, \"TEXT\"]\n",
    "        for field in tab_field_list + cat_field_list\n",
    "    ]\n",
    "\n",
    "    source_model_inference_output_variable_list = {\n",
    "        \"legacy-score\": \"NUMERIC\",\n",
    "        \"score-percentile\": \"NUMERIC\",\n",
    "        \"calibrated-score\": \"NUMERIC\",\n",
    "        \"custom-output-label\": \"TEXT\",\n",
    "    }\n",
    "\n",
    "    # =================== Update This =======================\n",
    "    framework = \"pytorch\"\n",
    "    inference_entry_point = \"pytorch_inference_handler.py\"\n",
    "    # =======================================================\n",
    "\n",
    "    factory.set_step_config(\n",
    "        \"Registration\",\n",
    "        framework=framework,\n",
    "        inference_entry_point=inference_entry_point,\n",
    "        model_owner=\"amzn1.abacus.team.djmdvixm5abr3p75c5ca\",  # abuse-analytics team\n",
    "        model_domain=model_domain,\n",
    "        model_objective=model_objective,\n",
    "        source_model_inference_output_variable_list=source_model_inference_output_variable_list,\n",
    "        source_model_inference_input_variable_list=source_model_inference_input_variable_list,\n",
    "    )\n",
    "    print(f\"âœ… Registration configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.4: Configure Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,510 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,511 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,511 - INFO - âœ… TabularPreprocessing_training configured successfully using TabularPreprocessingConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TabularPreprocessing_training configured\n"
     ]
    }
   ],
   "source": [
    "# Configure training preprocessing\n",
    "if \"TabularPreprocessing_training\" in pending_steps:\n",
    "    step_name = \"TabularPreprocessing_training\"\n",
    "\n",
    "    factory.set_step_config(\n",
    "        step_name,\n",
    "        job_type=\"training\",\n",
    "        label_name=label_name,\n",
    "        processing_entry_point=\"tabular_preprocessing.py\",\n",
    "        use_large_processing_instance=True,\n",
    "        output_format=\"Parquet\",\n",
    "    )\n",
    "    print(f\"âœ… {step_name} configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,517 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,517 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,518 - INFO - âœ… TabularPreprocessing_calibration configured successfully using TabularPreprocessingConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TabularPreprocessing_calibration configured\n"
     ]
    }
   ],
   "source": [
    "# Configure training preprocessing\n",
    "if \"TabularPreprocessing_calibration\" in pending_steps:\n",
    "    step_name = \"TabularPreprocessing_calibration\"\n",
    "\n",
    "    factory.set_step_config(\n",
    "        step_name,\n",
    "        job_type=\"calibration\",\n",
    "        label_name=None,\n",
    "        processing_entry_point=\"tabular_preprocessing.py\",\n",
    "        use_large_processing_instance=True,\n",
    "        output_format=\"Parquet\",\n",
    "    )\n",
    "    print(f\"âœ… {step_name} configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.5: Configure Remaining Steps\n",
    "\n",
    "**USER INPUT BLOCK**: Fill in the essential fields for each remaining step.\n",
    "The factory has identified the required fields for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining steps to configure:\n",
      "========================================\n",
      "\n",
      "PyTorchModelEval_calibration:\n",
      "  Essential fields (2):\n",
      "    * id_name (str) - Name of the ID field in the dataset (required for evaluation).\n",
      "    * label_name (str) - Name of the label field in the dataset (required for evaluation).\n",
      "  Optional fields: 7\n",
      "\n",
      "PercentileModelCalibration_calibration:\n",
      "  Essential fields (1):\n",
      "    * job_type (str) - Which data split to use for calibration (e.g., 'training', 'calibration', 'validation', 'test').\n",
      "  Optional fields: 4\n",
      "\n",
      "Payload:\n",
      "  Essential fields (2):\n",
      "    * expected_tps (int) - Expected transactions per second\n",
      "    * max_latency_in_millisecond (int) - Maximum acceptable latency in milliseconds\n",
      "  Optional fields: 8\n"
     ]
    }
   ],
   "source": [
    "# Get current pending steps\n",
    "current_pending = factory.get_pending_steps()\n",
    "\n",
    "print(\"Remaining steps to configure:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for step_name in current_pending:\n",
    "    requirements = factory.get_step_requirements(step_name)\n",
    "    essential_reqs = [req for req in requirements if req[\"required\"]]\n",
    "\n",
    "    print(f\"\\n{step_name}:\")\n",
    "    print(f\"  Essential fields ({len(essential_reqs)}):\")\n",
    "    for req in essential_reqs:\n",
    "        print(f\"    * {req['name']} ({req['type']}) - {req['description']}\")\n",
    "\n",
    "    if len(requirements) > len(essential_reqs):\n",
    "        optional_count = len(requirements) - len(essential_reqs)\n",
    "        print(f\"  Optional fields: {optional_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'order_id'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is_abuse'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,542 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,542 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,543 - INFO - âœ… PyTorchModelEval_calibration configured successfully using PyTorchModelEvalConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorchModelEval_calibration configured\n"
     ]
    }
   ],
   "source": [
    "# Configure Model Evaluation\n",
    "if \"PyTorchModelEval_calibration\" in current_pending:\n",
    "    step_name = \"PyTorchModelEval_calibration\"\n",
    "    factory.set_step_config(\n",
    "        step_name,\n",
    "        job_type=\"calibration\",\n",
    "        processing_entry_point=\"pytorch_model_eval.py\",\n",
    "        id_name=id_name,\n",
    "        label_name=label_name,\n",
    "        processing_source_dir=str(source_dir),\n",
    "        processing_instance_type_large=\"ml.p3.8xlarge\",\n",
    "        use_large_processing_instance=True,\n",
    "        processing_framework_version=\"2.1.2\",\n",
    "        py_version=\"py310\",\n",
    "    )\n",
    "    print(f\"âœ… {step_name} configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Model Calibration\n",
    "if \"ModelCalibration_calibration\" in current_pending:\n",
    "    factory.set_step_config(\n",
    "        \"ModelCalibration_calibration\",\n",
    "        label_field=label_name,\n",
    "        processing_entry_point=\"model_calibration.py\",\n",
    "        score_field=\"prob_class_1\",\n",
    "        is_binary=True,\n",
    "        num_classes=2,\n",
    "        score_field_prefix=\"prob_class_\",\n",
    "        multiclass_categories=[0, 1],\n",
    "    )\n",
    "    print(f\"âœ… ModelCalibration_calibration configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,553 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,554 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,554 - INFO - âœ… PercentileModelCalibration_calibration configured successfully using PercentileModelCalibrationConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PercentileModelCalibration_calibration configured\n"
     ]
    }
   ],
   "source": [
    "# Configure Model Calibration\n",
    "if \"PercentileModelCalibration_calibration\" in current_pending:\n",
    "    factory.set_step_config(\n",
    "        \"PercentileModelCalibration_calibration\",\n",
    "        job_type=\"calibration\",\n",
    "        processing_entry_point=\"percentile_model_calibration.py\",\n",
    "        score_field=\"prob_class_1\",\n",
    "        score_fields=None,\n",
    "    )\n",
    "    print(f\"âœ… PercentileModelCalibration_calibration configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,560 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,561 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,561 - INFO - âœ… Payload configured successfully using PayloadConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Payload configured\n"
     ]
    }
   ],
   "source": [
    "# Configure Model Calibration\n",
    "if \"Payload\" in current_pending:\n",
    "    field_dict = {\n",
    "        \"Abuse.buyer_abuse_bsm_message_body_concat_by_order_marketplaceid.c_message_body_concat_by_order\": \"[bom] [Arrival Time]: 2025-06-11 [BUYER]: I need my refund. [eom]\",\n",
    "    }\n",
    "    load_test_instance_type_list = [\n",
    "        \"ml.m5.12xlarge\"  # \"ml.m5.4xlarge\"\n",
    "    ]\n",
    "    factory.set_step_config(\n",
    "        \"Payload\",\n",
    "        processing_entry_point=\"payload.py\",\n",
    "        # =================================\n",
    "        expected_tps=10,\n",
    "        max_latency_in_millisecond=1000,\n",
    "        field_defaults=field_dict,\n",
    "        load_test_instance_type_list=load_test_instance_type_list,\n",
    "    )\n",
    "    print(f\"âœ… Payload configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Final Configurations\n",
    "\n",
    "Now that all steps are configured, we can generate the final configuration instances.\n",
    "The factory will validate that all essential fields are provided and create the config objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Configuration Status:\n",
      "========================================\n",
      "Base config: âœ…\n",
      "Processing config: âœ…\n",
      "Pending steps: 0\n",
      "\n",
      "âœ… All steps configured! Ready to generate configurations.\n"
     ]
    }
   ],
   "source": [
    "# Check final status\n",
    "final_status = factory.get_configuration_status()\n",
    "final_pending = factory.get_pending_steps()\n",
    "\n",
    "print(\"Final Configuration Status:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Base config: {'âœ…' if final_status['base_config'] else 'âŒ'}\")\n",
    "print(f\"Processing config: {'âœ…' if final_status['base_processing_config'] else 'âŒ'}\")\n",
    "print(f\"Pending steps: {len(final_pending)}\")\n",
    "\n",
    "if final_pending:\n",
    "    print(\"\\nStill pending:\")\n",
    "    for step in final_pending:\n",
    "        print(f\"  - {step}\")\n",
    "    print(\"\\nâš ï¸  Please configure remaining steps before generating configs.\")\n",
    "else:\n",
    "    print(\"\\nâœ… All steps configured! Ready to generate configurations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating final configurations..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,574 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,574 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,575 - INFO - âœ… Package auto-configured successfully (only tier 2+ fields)\n",
      "2025-12-20 22:37:19,575 - INFO - âœ… Auto-configured 1 steps with only tier 2+ fields\n",
      "2025-12-20 22:37:19,575 - INFO - âœ… Returning 10 pre-validated configuration instances\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "âœ… Successfully generated 10 configuration instances:\n",
      "   1. PyTorchTrainingConfig\n",
      "   2. CradleDataLoadingConfig\n",
      "   3. CradleDataLoadingConfig\n",
      "   4. RegistrationConfig\n",
      "   5. TabularPreprocessingConfig\n",
      "   6. TabularPreprocessingConfig\n",
      "   7. PyTorchModelEvalConfig\n",
      "   8. PercentileModelCalibrationConfig\n",
      "   9. PayloadConfig\n",
      "  10. PackageConfig\n",
      "\n",
      "ðŸŽ‰ Configuration generation complete!\n"
     ]
    }
   ],
   "source": [
    "# Generate final configurations\n",
    "if not final_pending:\n",
    "    try:\n",
    "        print(\"Generating final configurations...\")\n",
    "        configs = factory.generate_all_configs()\n",
    "\n",
    "        print(f\"\\nâœ… Successfully generated {len(configs)} configuration instances:\")\n",
    "        for i, config in enumerate(configs, 1):\n",
    "            print(f\"  {i:2d}. {config.__class__.__name__}\")\n",
    "\n",
    "        print(\"\\nðŸŽ‰ Configuration generation complete!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Configuration generation failed: {e}\")\n",
    "        print(\"\\nPlease check that all required fields are provided.\")\n",
    "        configs = None\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Cannot generate configs - some steps are still pending configuration.\")\n",
    "    configs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save to JSON\n",
    "\n",
    "Finally, we save the generated configurations to a unified JSON file using the existing\n",
    "`merge_and_save_configs` utility. This creates the same format as the legacy approach\n",
    "but with much less effort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,587 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,588 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,590 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,590 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,592 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,592 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,594 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,594 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,598 - INFO - Merging and saving 10 configs to /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n",
      "2025-12-20 22:37:19,599 - INFO - Collecting field information for 10 configs (6 processing configs)\n",
      "2025-12-20 22:37:19,607 - INFO - Collected information for 78 unique fields\n",
      "2025-12-20 22:37:19,609 - INFO - Efficient algorithm identified 15 shared fields\n",
      "2025-12-20 22:37:19,614 - INFO - Populated specific fields for 10 configs\n",
      "2025-12-20 22:37:19,614 - INFO - Shared fields: 15\n",
      "2025-12-20 22:37:19,615 - INFO - Specific steps: 10\n",
      "2025-12-20 22:37:19,615 - INFO - Saving merged configuration to /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n",
      "2025-12-20 22:37:19,619 - INFO - Successfully saved merged configuration to /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n",
      "2025-12-20 22:37:19,620 - INFO - Successfully saved merged configs to /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving configurations to: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n",
      "\n",
      "âœ… Configuration saved successfully!\n",
      "   File: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n",
      "   Size: 116.7 KB\n",
      "   Hyperparameters: dockers/hyperparams/hyperparameters_NA.json\n",
      "\n",
      "ðŸŽ‰ Interactive configuration complete!\n",
      "\n",
      "ðŸ“Š Comparison with legacy approach:\n",
      "   Legacy: 500+ lines of manual configuration\n",
      "   Interactive: Guided step-by-step process\n",
      "   Time saved: ~20-25 minutes\n",
      "   Error reduction: Validation at each step\n"
     ]
    }
   ],
   "source": [
    "if configs:\n",
    "    # Set up output directory and filename\n",
    "    MODEL_CLASS = \"pytorch\"\n",
    "    service_name = \"AtoZ\"\n",
    "\n",
    "    config_dir = Path(current_dir) / \"pipeline_config\"\n",
    "    config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    config_file_name = f\"config_{region}.json\"\n",
    "    config_path = config_dir / config_file_name\n",
    "\n",
    "    print(f\"Saving configurations to: {config_path}\")\n",
    "\n",
    "    # Use the existing merge_and_save_configs utility\n",
    "    from cursus.steps.configs.utils import merge_and_save_configs\n",
    "\n",
    "    try:\n",
    "        merged_config = merge_and_save_configs(configs, str(config_path))\n",
    "\n",
    "        print(f\"\\nâœ… Configuration saved successfully!\")\n",
    "        print(f\"   File: {config_path}\")\n",
    "        print(f\"   Size: {config_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "        # Also save hyperparameters separately (for compatibility)\n",
    "        hyperparam_path = source_dir / \"hyperparams\" / f\"hyperparameters_{region}.json\"\n",
    "        with open(hyperparam_path, \"w\") as f:\n",
    "            json.dump(bimodal_hyperparams.model_dump(), f, indent=2, sort_keys=True)\n",
    "\n",
    "        print(f\"   Hyperparameters: {hyperparam_path}\")\n",
    "\n",
    "        print(f\"\\nðŸŽ‰ Interactive configuration complete!\")\n",
    "        print(f\"\\nðŸ“Š Comparison with legacy approach:\")\n",
    "        print(f\"   Legacy: 500+ lines of manual configuration\")\n",
    "        print(f\"   Interactive: Guided step-by-step process\")\n",
    "        print(f\"   Time saved: ~20-25 minutes\")\n",
    "        print(f\"   Error reduction: Validation at each step\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Failed to save configurations: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No configurations to save. Please generate configs first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if we can load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cursus.steps.configs.config_cradle_data_loading_step import CradleDataLoadingConfig\n",
    "from cursus.steps.configs.config_tabular_preprocessing_step import (\n",
    "    TabularPreprocessingConfig,\n",
    ")\n",
    "from cursus.steps.configs.config_pytorch_training_step import PyTorchTrainingConfig\n",
    "from cursus.steps.configs.config_pytorch_model_eval_step import PyTorchModelEvalConfig\n",
    "from cursus.steps.configs.config_model_calibration_step import ModelCalibrationConfig\n",
    "from cursus.steps.configs.config_percentile_model_calibration_step import (\n",
    "    PercentileModelCalibrationConfig,\n",
    ")\n",
    "from cursus.steps.configs.config_package_step import PackageConfig\n",
    "from cursus.steps.configs.config_payload_step import PayloadConfig\n",
    "from cursus.steps.configs.config_package_step import PackageConfig\n",
    "from cursus.steps.configs.config_payload_step import PayloadConfig\n",
    "from cursus.steps.configs.config_registration_step import RegistrationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cursus.steps.configs.utils import load_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_CLASSES = {\n",
    "    \"CradleDataLoadingConfig\": CradleDataLoadingConfig,\n",
    "    \"TabularPreprocessingConfig\": TabularPreprocessingConfig,\n",
    "    \"PyTorchTrainingConfig\": PyTorchTrainingConfig,\n",
    "    \"PyTorchModelEvalConfig\": PyTorchModelEvalConfig,\n",
    "    \"ModelCalibrationConfig\": ModelCalibrationConfig,\n",
    "    \"PercentileModelCalibrationConfig\": PercentileModelCalibrationConfig,\n",
    "    \"PackageConfig\": PackageConfig,\n",
    "    \"PayloadConfig\": PayloadConfig,\n",
    "    \"RegistrationConfig\": RegistrationConfig,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-20 22:37:19,647 - INFO - Loading configs from /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n",
      "2025-12-20 22:37:19,648 - INFO - Loading configuration from /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n",
      "2025-12-20 22:37:19,649 - WARNING - Could not find class CradleJobSpecificationConfig\n",
      "2025-12-20 22:37:19,649 - WARNING - Could not find class DataSourcesSpecificationConfig\n",
      "2025-12-20 22:37:19,650 - WARNING - Could not find class DataSourceConfig\n",
      "2025-12-20 22:37:19,650 - WARNING - Could not find class MdsDataSourceConfig\n",
      "2025-12-20 22:37:19,650 - WARNING - Could not find class DataSourceConfig\n",
      "2025-12-20 22:37:19,651 - WARNING - Could not find class EdxDataSourceConfig\n",
      "2025-12-20 22:37:19,651 - WARNING - Could not find class OutputSpecificationConfig\n",
      "2025-12-20 22:37:19,652 - WARNING - Could not find class TransformSpecificationConfig\n",
      "2025-12-20 22:37:19,652 - WARNING - Could not find class JobSplitOptionsConfig\n",
      "2025-12-20 22:37:19,652 - WARNING - Could not find class CradleJobSpecificationConfig\n",
      "2025-12-20 22:37:19,653 - WARNING - Could not find class DataSourcesSpecificationConfig\n",
      "2025-12-20 22:37:19,653 - WARNING - Could not find class DataSourceConfig\n",
      "2025-12-20 22:37:19,653 - WARNING - Could not find class MdsDataSourceConfig\n",
      "2025-12-20 22:37:19,654 - WARNING - Could not find class DataSourceConfig\n",
      "2025-12-20 22:37:19,654 - WARNING - Could not find class EdxDataSourceConfig\n",
      "2025-12-20 22:37:19,655 - WARNING - Could not find class OutputSpecificationConfig\n",
      "2025-12-20 22:37:19,655 - WARNING - Could not find class TransformSpecificationConfig\n",
      "2025-12-20 22:37:19,655 - WARNING - Could not find class JobSplitOptionsConfig\n",
      "2025-12-20 22:37:19,656 - INFO - Successfully loaded configuration from /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n",
      "2025-12-20 22:37:19,656 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json with 10 specific configs\n",
      "2025-12-20 22:37:19,659 - INFO - Creating additional config instance for CradleDataLoading_calibration (CradleDataLoadingConfig)\n",
      "2025-12-20 22:37:19,660 - INFO - Creating additional config instance for CradleDataLoading_training (CradleDataLoadingConfig)\n",
      "2025-12-20 22:37:19,661 - INFO - Creating additional config instance for Package (PackageConfig)\n",
      "2025-12-20 22:37:19,661 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,662 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,662 - INFO - Creating additional config instance for Payload (PayloadConfig)\n",
      "2025-12-20 22:37:19,663 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,664 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,664 - INFO - Creating additional config instance for PercentileModelCalibration_calibration (PercentileModelCalibrationConfig)\n",
      "2025-12-20 22:37:19,665 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,665 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,666 - INFO - Creating additional config instance for PyTorchModelEval_calibration (PyTorchModelEvalConfig)\n",
      "2025-12-20 22:37:19,667 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,667 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers\n",
      "2025-12-20 22:37:19,668 - INFO - Creating additional config instance for PyTorchTraining (PyTorchTrainingConfig)\n",
      "2025-12-20 22:37:19,669 - INFO - Creating additional config instance for Registration (RegistrationConfig)\n",
      "2025-12-20 22:37:19,669 - INFO - Creating additional config instance for TabularPreprocessing_calibration (TabularPreprocessingConfig)\n",
      "2025-12-20 22:37:19,670 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,671 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,671 - INFO - Creating additional config instance for TabularPreprocessing_training (TabularPreprocessingConfig)\n",
      "2025-12-20 22:37:19,672 - INFO - Package location discovery succeeded (bundled): /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,672 - INFO - Hybrid resolution completed successfully via Package Location Discovery: /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/dockers/scripts\n",
      "2025-12-20 22:37:19,673 - INFO - Successfully loaded configs from /home/ec2-user/SageMaker/BuyerAbuseModsTemplate/src/buyer_abuse_mods_template/atoz_bsm_pytorch/pipeline_config/config_NA.json\n"
     ]
    }
   ],
   "source": [
    "loaded_configs = load_configs(str(config_path), CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the **DAGConfigFactory** approach to pipeline configuration:\n",
    "\n",
    "### âœ… **Benefits Achieved**\n",
    "\n",
    "1. **Reduced Complexity**: From 500+ lines of manual config to guided workflow\n",
    "2. **Base Config Inheritance**: Set common fields once, inherit everywhere\n",
    "3. **Step-by-Step Guidance**: Clear requirements for each configuration step\n",
    "4. **Validation**: Comprehensive validation prevents configuration errors\n",
    "5. **Reusable DAG**: Pipeline structure defined once, reused across environments\n",
    "\n",
    "### ðŸ”„ **Workflow Comparison**\n",
    "\n",
    "| Aspect | Legacy Approach | Interactive Approach |\n",
    "|--------|----------------|---------------------|\n",
    "| **Lines of Code** | 500+ manual lines | Guided step-by-step |\n",
    "| **Time Required** | 30+ minutes | 10-15 minutes |\n",
    "| **Error Rate** | High (manual entry) | Low (validation) |\n",
    "| **Reusability** | Copy-paste heavy | DAG-driven |\n",
    "| **Maintenance** | Manual updates | Automatic inheritance |\n",
    "\n",
    "### ðŸš€ **Next Steps**\n",
    "\n",
    "The generated configuration file can now be used with the existing pipeline compiler:\n",
    "\n",
    "```python\n",
    "# Use with pipeline compiler (from demo_pipeline.ipynb)\n",
    "from cursus.core.compiler.dag_compiler import PipelineDAGCompiler\n",
    "\n",
    "dag_compiler = PipelineDAGCompiler(\n",
    "    config_path=config_path,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "# Compile DAG to pipeline\n",
    "template_pipeline, report = dag_compiler.compile_with_report(dag=dag)\n",
    "```\n",
    "\n",
    "The interactive configuration approach transforms the user experience from complex manual setup to an intuitive, guided workflow while maintaining full compatibility with the existing cursus infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
